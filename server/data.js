export default[
  {
    url: "https://www.youtube.com/watch?v=iSfrVNowJ9Y&t=756s",
    title:
      "How this student cracked both Google & J.PMorgan Internships?  Interview lessons with Shradha Ma'am",
    youtuber: "@ApnaCollegeOfficial",
    youtuber_md5: "0e53da42f217650527771ffef0a13171",
    video_url:
      "https://rr5---sn-po4vgoxucg51pa-4vge.googlevideo.com/videoplayback?expire=1756977007&ei=DwO5aNifMc6q9cYPg8fP6Aw&ip=177.84.79.58&id=o-AJiBvfEL-keCoQUIpHnbCKIZc3Cvh1yW9054r-tjGt62&itag=18&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1756955407%2C&mh=gY&mm=31%2C29&mn=sn-po4vgoxucg51pa-4vge%2Csn-pmcg-4vgs&ms=au%2Crdu&mv=m&mvi=5&pl=24&rms=au%2Cau&initcwndbps=1557500&bui=AY1jyLMYjzgokjt5hqWBmEnZqD5_mixO9WCxadvYR3DAapr_OuTzIJcJ05EG1kUFNJE29zhn4z7JEskj&spc=l3OVKWfWDVd3e6T6r87Y4kTDfxVLRrGXCWpawg-zRa3L5w68IQTswgzLRGbOjsTgiE5sGlkelnNuTUwW&vprv=1&svpuc=1&mime=video%2Fmp4&ns=2nUgG0gYmFLWLmTo2YCLZD0Q&rqh=1&gir=yes&clen=55059958&ratebypass=yes&dur=1242.871&lmt=1735416624699649&mt=1756954887&fvip=7&fexp=51355912%2C51552689%2C51565116%2C51565681%2C51580968&c=WEB&sefc=1&txp=4438434&n=Zd83182RtWNlHjEcKj&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AJfQdSswRgIhAKmDv4RbQcJfzh9On4PZdMJu9gtk2JE1BDej8Nu5NLciAiEAkfxQvLnBQodXmVwY22L_gXWMtIKNNxpUz2z9SWSZ6bc%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=APaTxxMwRQIhAJb4nBVuzhX4RJoRXzJcPx-GHTbu1F3NOyhuEcUm6VGrAiBTtldkQSMGOtp1R2yks3HA5MVzq3XYmTRDt59Ubn2Zeg%3D%3D",
    video_length: 1243,
    likes: 4091,
    views: 118552,
    date_posted: "2024-12-28T15:33:47.000Z",
    description:
      "Save time & study only what's needed for Placements\nNew Sigma 6.0 Link : https://www.apnacollege.in/course/sigma-6\n\n---------------------------------------------------------\nLink for International students : https://buy.stripe.com/14kaEQ9be3FsaB2bIW\n\nEligibility for Sigma 6.0 \n- B.Tech students preparing for Tech Placement/Internships. \n- start as early as possible, first 2 years are most important. \n- M.Tech/MCA/BCA who are preparing for Tech Placements/Internships\n\nClass Schedule : \n- Mentioned in video & on website. \n- Recorded Lectures will come on alternate days.\n- Lecture Timings : 8PM \n- Lecture duration : 1 - 1.5 Hour\n\n\nShradha Ma'am community \nInstagram : https://www.instagram.com/shradhakhapra\nLinkedIn : https://www.linkedin.com/in/shradha-khapra/\n\n00:00 Introduction \n01:11 Google Hiring process \n03:06 Parents' reaction \n03:31 Preparation \n05:52 Rejections\n07:02 DSA or Development \n07:29 CGPA\n08:00 Time Management \n09:20 CS Fundamentals \n09:39 Projects \n10:27 Communication skills \n11:06 Quantitative Aptitude \n11:23 Challenges \n11:57 Flipper Hackathon\n12:36 Mistakes made \n13:12 Advice for juniors \n14:36 Wow factor \n15:33 Placement scenario\n16:22 Role of college \n17:12 Tips\n17:55 Stipend details \n18:33 Mentorship sessions",
    num_comments: 249,
    subscribers: 7070000,
    video_id: "iSfrVNowJ9Y",
    channel_url: "https://www.youtube.com/@ApnaCollegeOfficial",
    preview_image: "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault.jpg",
    shortcode: "iSfrVNowJ9Y",
    verified: true,
    handle_name: "Apna College",
    avatar_img_channel:
      "https://yt3.ggpht.com/FEcjRtez5od8UowDo6tTt9WlE-MrIFEmcwPMTORmK9Swk6KCklOmA3xfIG9WuLWfNYfNThQE=s48-c-k-c0x00ffffff-no-rj",
    is_sponsored: false,
    related_videos: [
      "https://www.youtube.com/watch?v=vscu3i1_yxs",
      "https://www.youtube.com/watch?v=XvSJ0KvFGDY",
      "https://www.youtube.com/watch?v=TmFHuAxqF5k",
      "https://www.youtube.com/watch?v=nBJbB2q3jR0",
      "https://www.youtube.com/watch?v=mstrQbmKrFk",
      "https://www.youtube.com/watch?v=zNECfyqzXTw",
      "https://www.youtube.com/watch?v=64N1nNk0WuQ",
      "https://www.youtube.com/watch?v=Lp-F-NLc41g",
      "https://www.youtube.com/watch?v=iCZnZXYceAU",
      "https://www.youtube.com/watch?v=IOt3kQP93SY",
      "https://www.youtube.com/watch?v=hr-y4suNq6c",
      "https://www.youtube.com/watch?v=yjd-LXVRqDU",
      "https://www.youtube.com/watch?v=hgbEbEVGeoM",
      "https://www.youtube.com/watch?v=56SOLhXVS48",
      "https://www.youtube.com/watch?v=Jz1PQkZXkmo",
      "https://www.youtube.com/watch?v=eyCpWDRo154",
      "https://www.youtube.com/watch?v=nwlPIoFhNc0",
      "https://www.youtube.com/watch?v=opCURgV0p-o",
      "https://www.youtube.com/watch?v=UIlqn1AUJeI",
      "https://www.youtube.com/watch?v=UWtIGks_tHc",
    ],
    license: null,
    viewport_frames: "640x360 / -",
    current_optimal_res: "640x360@25 / 640x360@25",
    codecs: "avc1.42001E, mp4a.40.2 / mp4a.40.2",
    color: "bt709",
    quality: "hd1080",
    quality_label: "1080p50",
    post_type: "post",
    youtuber_id: "UCBwmMxybNva6P_5VmxjzwqA",
    transcript:
      "Introduction बेसिकली सीजीपीए एक्चुअली इज अ हिडन क्रिटेक जेबी मॉर्गन में था उन्होंने कहा था कि 88.5 प्लस सीजीपीए वाले सारे अलाउड है तो बहुत लोगों ने फॉर्म फिल कर दिया तो लाइक अगर लिमिट ज्यादा हो गया था तो उन्होंने 8.8 का क्राइटेरिया इंटरनली लगा दिया और 8.5 से 88.8 वालों को शॉर्टलिस्ट नहीं करा अच्छा ये बताओ अगर आपके कॉलेज के अंदर देयर आर 100 स्टूडेंट्स हु आर सेटिंग फॉर अ इंटर्नशिप इंटरव्यूज तो प्लेसमेंट सीजन के अंदर 100 में से कितने स्टूडेंट्स आपको लगते हैं जो सीरियसली टेक प्लेसमेंट्स की तैयारी करते हैं टेक इंटर्नशिप की तैयारी करते हैं बेसिकली आई वेस्टेड लाइक फोर टू फाइव डेज जस्ट थिंकिंग अबाउट कि लाइक ऑनलाइन असेसमेंट में नहीं हुआ तो क्या होगा microsoft's कंपनीज तो जानते हैं शिवम की पूरी टेक्निकल जर्नी के बारे में सो शिवम टेल अस अबाउट योरसेल्फ एक्चुअली माय नेम शिवम कुमार आई एम करेंटली अ थर्ड ईयर अंडर ग्रेजुएट एट नेशनल इंस्टिट्यूट ऑफ टेक्नोलॉजी जमशेदपुर फ्रॉम कंप्यूटर साइंस एंड इंजीनियरिंग ब्रांच तो यू गट Google Hiring process सिलेक्टेड फॉर एन इंटर्नशिप एट यर्स पोर्टल से हम तो लाइक उसके वन मंथ के बाद मेरे कॉलेज में भी उसमें दो क्वेश्चंस थे एक डीपी पे था और एक ऑयलर टूर पे था ीज का सो आई मैनेज टू सॉल्व वन ओनली सो लाइक अंडर कॉन्फिडेंट था कि होगा या नहीं होगा सो उसके बाद लाइक फोर टू फाइव डेज लेटर शॉर्ट लिस्टिंग में मेरी नाम आ गई सो उसके बाद फिर इंटरव्यू शेड्यूल्ड हुए थे उसके फोर टू फव मब 10 डेज का गैप था ओए और इंटरव्यूज के बीच में सो फर्स्ट राउंड हुआ फर्स्ट राउंड में बेसिकली प्रोजेक्ट्स पे डिस्कशन हुआ बेसिकली वन ही प्रोजेक्ट हुआ था जो मैंने कोड फॉर गुड है केथन जो पीएमसी होता है उसका प्रोजेक्ट पे डिस्कशन हुआ देन रिकजन का एक बेसिक सा सिंपल सा क्वेश्चन था ह देन देयर वाज अ क्वेश्चन व्हिच वाज बिट टफ बिकॉज ऑफ वेरियस कांसेप्ट इवॉल्व लाक प्रायोरिटी क्यूज मैप्स एंड रेंडमाइज सर्टिंग एल्बोज सो बेसिकली उस परे इंटरव्यू एंड हो गया फर्स्ट राउंड हम देन आफ्टर फोर टू फाइव डेज अगेन राउंड टू शेड्यूल्ड हुआ उसमें देयर वाज वन क्वेश्चन बेड ऑन बैकवर्ड डायनेमिक प्रोग्रामिंग एंड वन क्वेश्चन वाज लाइक इट वाज सिंपली डीपी बट लाइक इट इवॉल्व ऑप्टिमाइजेशन ऑ टू ओवन स्पेस बेसिकली डीडीपी को हम ओवन स्पेस में करना स सो इट वाज बिट ट्रिकी एंड देन सम थियोरेटिकल क्वेश्चंस अबाउट हाउ हाउ हैश ट वर्क्स ह एंड लाइक दिस ओनली सो देन उसके लाइक अबाउट 15 डेज के बाद रिजल्ट उसका आ गया देन आई गट शॉर्ट लिस्टेड तो रिजल्ट जब Parents' reaction आया आपने पेरेंट्स को बताया होगा व्हाट वाज देयर रिएक्शन बेसिकली दे वेर नॉट बिलीविंग एट मी एट ऑल सो बिकॉज मैंने कहा था मेरा इंटरव्यू इतना अच्छा नहीं गया तो वो कह रहे थे झूठ मत बोलो कॉलेज जिस दिन खुला था मतलब समर वेकेशन के बाद मैं कॉलेज आया था तो उसी दिन रिजल्ट आया था तो मैंने बोला तो मजाक मत करो ये तो उसके बाद फिर मैंने जब मेल दिखाया प्लेसमेंट सेल से आया था तो उसके बाद दे वर वेरी हैप्पी एंड ट ठीक ओ शिवम हाउ डिड यू स्टार्ट योर Preparation एंटायस मंथ्स की आपकी प्रिपरेशन रही होगी क्या-क्या आपने कोडिंग के अंदर चीजें सीखी बिफोर यू स्टार्टेड अप्लाइक 2022 में जब जे एडवांस मैंने दिया उसके बाद सोचा कि लाइक कोडिंग क्या होता है कुछ पता नहीं था तो उसके बाद मैंने भैया से अपने पूछा तो उन्होंने कहा जैसे हम लोग में लैंग्वेज बात करते वैसे कंप्यूटर को भी कुछ लैंग्वेज समझ आती है लाइक उसमें कोड करते हैं इसलिए लेमंड टर्म्स उ लोग समझा रहे थे सी जावा ये सब होती है हम तो मैंने पूछा कि मेरे को भी स्टार्ट कर नहीं तो कहां से करूं तो उन्होंने कहा सी सीख लो मदर ऑफ ऑल लैंग्वेज है ले मैंने सोचा चलो ठीक है लेकिन मैं youtube1 मंथ मैंने वही सारे लेक्चर देखा कि सबका सब क्या क्या हो रहा है क्या हो रहा है उसके बाद आपका लेक्चर भी देखा सबका देख उसके बाद ना आपका 1 नवंबर को अल्फा 2.2 बैच आया तो आपका मैंने उस टाइम तक लाइक 15 टू 16 लेक्चर देख रखे थे तो मैंने सोचा बैच लेके वहीं से प्रिपेयर करते हैं हम और कॉलेज खुलने में अ भी टाइम थी लाइक 30 डेज थी लगभग तो मैंने वहां से किया 30 डेज तक करा उसके बाद सब समझ आ रहा था उसके बाद फिर मेरा कॉलेज स्टार्ट हुआ तो थोड़ा इरेगुलेरिटी आ गया मेरे में तो लाइक फर्स्ट सेमेस्टर तो ना सीजीपीए पे ध्यान रहा ना किसी पे तो कॉलेज स्टार्ट होने से पहले आपने मैच लेया वहां से आपने पढ़ा एक महीने हां उसके बाद फिर इसमें पॉज आ गया तो लाइक सीजीपीए भी गिर गई ना कोडिंग आ रही थी सारे बैचमेट्स भी आगे जा रहे थे तो उसके बाद मैं वापस से लेक्चर देखना शुरू किए कंटिन्यू कंटिन्यू किया और लाइक सेकंड सेमेस्टर के में मेरा पूरा लेक्चर खत्म हो गया था हम सारे कोर्सेस उसके बाद मैंने सीधा प्रैक्टिस करने लगा लीड कोड पे उसके बाद फिर सब प्रोजेक्ट्स का बात आ रहा था कि प्रोजेक्ट्स बनाना पड़ेंगे तो फिर वेब डेवलपमेंट करा ऐसे धीरे-धीरे उसका फिर थोड़ा सा एमएल को भी करा उसका सेमेस्टर में भी हम लोग का एमएल आ गया तो हम मैंने एमएल पे फोकस करा ऐसे ऐसे करके तेते तो लाइक प्रोजेक्ट्स बनते गए ठीक है तो करीबन कितने मंथ्स का आपका टोटल प्रिपरेशन रहा होगा बिफोर इंटर्नशिप्स डेढ़ साल 1.5 इयर्स 1.5 इयर्स एंड वाज Rejections googlegroups.com बट यू वर नॉट सिलेक्टेड या फिर यू गट सिलेक्टेड फॉर माइक्रोसॉफ्ट में मैंने अप्लाई करा था बेसिकली वो जब google2 क्वेश्चन हो गए थे उसी के बीच मैंने माइक्रोसॉफ्ट का अप्लाई करा और एक दिन के अंदर ही मेरा रिज्यूमे रिजेक्ट हो गया रिजेक्शन मेल आ गया सो लाइक बहुत ज्यादा अंडर कॉन्फिडेंट फील हुआ कि यार एक तो फीलिंग ऑफ फीलिंग अंडर कॉन्फिडेंट बेसिकली मैंने सोच मैम आई थॉट कि मैं शुरू से वापस रीस्टार्ट करते हैं लाइक ऐसा था कि रिग्रेट हो रहा था कि मैंने क्यों ऑन कैंपस अप्लाई करा ऑफ कैंपस से सीधा इंटरव्यू कम से कम इंटरव्यू देने का अपॉर्चुनिटी मिलता तो लाइक मैं वापस से चालू कर दिया से क्वांट वगैरह रीजनिंग वगैरह कि अब जो दूसरी कंपनी आएगी वो क्वांट पूछेगी रीजनिंग पूछेगी उसके लिए मैंने अपना प्रैक्टिस करना शुरू कर दिया था तो बस ऐसे ऐसे करा उसके बाद अचानक से मेल आता है कि यू हैव सेड मतलब आपका राउंड वन में सिलेक्शन हो गया है सो देन वापस से इंटरव्यू के लिए डीएसए प्रैक्टिस करना चालू कर दि तो डीएसए और डेवलपमेंट दोनों DSA or Development में से आपको क्या लगता है किसका ज्यादा मेजर कंट्रीब्यूशन रहा टुवर्ड्स गेटिंग योर इंटर्नशिप बेसिकली मैम अगर रिज्यूमे के पर्सपेक्टिव से देखें तो रिज्यूमे के लिए डेवलपमेंट बहुत इंपोर्टेंट है बिकॉज क्वालिटी प्रोजेक्ट्स होते हैं तभी से शॉर्ट लिस्टिंग होती है रिज्यूमे की एंड इंटरव्यूज में मेरे से ज्यादातर लाइक 80 पर डीएस से ही पूछा गया प्रोजेक्ट पे बस नॉर्मल सा डिस्कशन हुआ था नॉट लाइक दैट सो बेसिकली डीएसए का इंपोर्टेंट रोल रहा था ठीक है अच्छा व्हाट वाज द इंपॉर्टेंस ऑफ CGPA सीजीपीए इन द एंटायस बेसिकली सीजीपीए एक्चुअली इज अ हिडन क्रिटी वो कोई बताता नहीं है वो बस अंदर से रहता है कि लाइक और जैसे कि जेबी मॉर्गन में था उन्होंने कहा था कि 88.5 प्लस सीजीपी वाले सारे अलाउड है ह तो बहुत लोगों ने फॉर्म फिल कर दिया तो लाइक अगर लिमिट ज्यादा हो गया था तो उन्होंने 8.8 का क्राइटेरिया इंटरनली लगा दिया और 8.5 से 88.8 वालों को शॉर्टलिस्ट नहीं करा सेम googlegroups.com 9.14 है सो हाउ डिड यू Time Management मैनेज योर एकेडमिक्स अलोंग विद योर टेक प्लेसमेंट प्रिपरेशन बेसिकली फर्स्ट सेमेस्टर में लाइक कुछ नहीं पढ़ा था तो उसमें सीजीपीए कम रही थी अब 8.6 8.7 थी 8.6 कम रही थी यस मैम सो बेसिकली सबकी ज्यादा थी मेरे से तो लाइक से फिर सेकंड सेमेस्टर में थोड़ा फोकस करा सीजीपी पर तो बड़ी उसका थर्ड सेमेस्टर में क्या हुआ कि लाइक डीएस एक पेपर आ गया डीएस का डेटा स्ट्रक्चर का एक डीए का एनालिसिस ऑफ एल्गोरिथम्स का और मैथ्स के दो पेपर आ गए और लाइक ये सब्जेक्ट मेरे फेवरेट था तो उसमें मेरी सीजी प बहुत हाई आ गई 9.6 आ गई जिसके कारण ओवरऑल पूरा सीजी मेंटेन हो गया उसका बाद फिर फोर्थ सेमेस्टर आया तो उसमें भी लाइक और 8.9 अराउंड इतनी सीजी थी तो बेसिकली उसके बाद से फिर मेंटेन नॉर्मल टाइम एक्चुअली 14 डेज पहले से मैं प्रिपेयर करता था एग्जाम का तो हो जाता था उससे ओके तो एग्जाम टाइम प आप सीजीपीए प फोकस करते थे तो टेक प्लेसमेंट प्रिपरेशन के लिए टाइम निकाला कैसे आपने पूरी तैयारी से बेसिकली कॉलेज को थोड़ा साइड करके अटेंडेंस वगैरह प्रॉक्सी बॉक्सी लगा के इस तरह से लाइक रूम प बैठ के करता था और एग्जाम टाइप पर एग्जाम का फोकस करता था जैसे बेसिकली टू मंथ के बाद हम लोग का मिड सेम होता है तो लाइक वन मंथ 15 डेज डीएसए करा 15 मंथ में इसका कर दिया प्रिपेयर उसका बाद फिर हॉलीडेज मिलती है मिड सेम के बाद उसमें भी अपना डीएसए वगैरह प्रोजेक्ट्स वगैरह बिल्ड किया फिर एंड सेम के 14 डेज पहले कर लिया प्रिपेयर ऐसे ऐसे करके ओके एंड व्हाट वाज द इंपोर्टेंस ऑफ CS Fundamentals कंप्यूटर साइंस फंडामेंटल्स बेसिकली लाइक कंप्यूटर साइंस फंडामेंटल्स इतना ग वगैरह में तो नहीं बट कोर कंपनी ज्यादा पूछ तो मैंने प्रिपेयर करने का सोचा था बट एक्चुअली लाइक सेमेस्टर के लिए जैसे-जैसे पढ़ते गए वैसे-वैसे सब प्रिपेयर होता गया तो उतना इंपोर्टेंट मेरे को नहीं लगा ठीक है कैन यू टेल अस मोर अबाउट योर Projects प्रोजेक्ट्स किस तरीके के प्रोजेक्ट्स आपने रेजूम के अंदर मेंशन किए थे बेसिकली वन इज माय द थन प्रोजेक्ट सो इट इज अ फुल स्टैक एप्लीकेशन कंसिस्टिंग ऑफ एआई मॉडल्स एंड टू एलएल एम्स वन इज लाइक अ फुल स्टैक प्रोजेक्ट व्हिच इज अ फूड डिलीवरी पप बेसिकली एंड वन इज अवर कोर्स प्रोजेक्ट व्हिच इज हिस्टोग्राम ऑफ ओरिएंटेड डिट्स बेसिकली इट इज अ एमएल मॉडल ट यूज टू एक्ट एक्सट्रैक्ट इमेजेस एंड आईडेंटिफाई इमेजेस बेसिकली एंड एज डिटेक्शन टू फुल स्टैक एंड व एमएल टू फुल स्टैक प्रोजेक्ट एंड वन एमल प्रोजेक्ट दो फुल स्टैक प्रोजेक्ट कौन से टेक्स स्टैक में बनाए आपने बेसिकली वन वन इज बिल्ट ऑन मन स्टैक एंड अदर इज लाइक इट इज अ मेगा प्रोजेक्ट लाइक जेपीएमसी व इट इज अ मेगा प्रोजेक्ट इट इज बिल्ट ऑन मन स्टक एंड आई यूज फ्लस ए अ बैक एंड इट हैज आल्सो एललम एंड जमना वेरियस एपीआई इंटीग्रेशन ओके व्हाट ड यू थिंक वास द Communication skills इंपोर्टेंट ऑफ कम्युनिकेशन स्किल्स इन इंटरव्यूज या बेसिकली कम्युनिकेशन स्किल प्ले अ वेरी वाइटल रोल सो लाइक अगर आप जो सोच रहे हैं उन इंटरव्यूअर को भी पता है कि आप क्या सोच रहे हैं अगर आप मन में ही सोचेंगे तो वो सोचेगा वो सोचेगा क्या लाइक ये सोच रहा है या नहीं सोच रहा है या हेजिन से जब टू वे कम्युनिकेशन रहेगा इंटरव्यू के अराउंड तो लाइक वो ज्यादा इंपैक्ट पड़ता है जैसे मैं कहीं भी फसता था तो मैं डायरेक्ट इंटरव्यू से पूछता था एम आई डूइंग राइट या ऐसे ही जाना चाहिए या कुछ और अप्रोच लगाओ तो ऐसे ऐसे करके टाइम कॉप्लेक्स टी भी जब एक्सप्लेन करने को बोलते हैं तो लाइक उनसे एक एक लाइन का टाइम कॉम्लेक्स टी बताइए और उनसे पूछिए कि आप सही बोल रहे हैं लाइक ये बहुत ज्यादा इंपॉर्टेंट है टू वे कम्युनिकेशन मेंटेन Quantitative Aptitude करना एंड व्हाट ड यू थिंक इज द इंपोर्टेंस ऑफ क्वांट एप्टीट्यूड इन प्लेसमेंट्स एंड इंटर्नशिप यसम इट इज वेरी इंपोर्टेंट फॉर सम कंपनीज बिकॉज ऑनलाइन असेसमेंट में कुछ कंपनीज गोल्डन सेक्स हो गई यह सब होती है ये सब सीधा क्वांट प पूछती है क्वेश्चन एप्टीट्यूड के क्वेश्चन रहेंगे 40 50 सो या इट इज इंपोर्टेंट अच्छा यू गट Challenges सिलेक्टेड फॉर ग एंड कैन यू टेल अस इन द एंटायस और द ओए प्रोसेस व्हाट वाज द मोस्ट चैलेंजिंग पार्ट फॉर यू बेसिकली द मोस्ट चैलेंजिंग पर्ट वाज क्लीयरिंग द ऑनलाइन असेसमेंट बिकॉज लाइक वो फ्रेश सबसे पहली कंपनी Flipper Hackathon गट ऑल इंडिया रैंक थ्री इन फ्लिपर कथन सो कैन यू टेल अस मोर अबाउट दिस कथन यस मैम बेसिकली इट वाज अ कथन कंडक्टेड बाय फ्लिपर एआई च इज अ स्टार्टअप सो बेसिकली दे दे टोल्ड अस टू बिल्ड अ सोशल मीडिया एप्लीकेशन सो बेसिकली सोशल मीडिया वी क्रिएटेडटेड लाइक लाइकिंग द पोस्ट सेव द पोस्ट लाइक दिस सो लाइक वी सरप्राइज्ड टू नो दैट व वी रिसीवड ऑल इंडि 9थ फर्स्ट वन वाज आईआईटी जोधपुर सेकंड वाज आईटी धनवाद एंड थर्ड वन वाज आर सो वी र वेरी सरप्राइज्ड टू नो दैट Mistakes made अच्छा अ लेट्स सपोज वी सेंड यू बैक टू योर फर्स्ट ईयर एंड यू हैड टू रिप्रेस फॉर योर googlegroups.com आई वुड फोकस मोर ऑन द सीजीपीए पार्ट हम एंड आल्सो द डीएसए लाइक आई वुड प्रैक्टिस मोर एंड मोर प्रॉब्लम्स एंड आल्सो आई वुड लव टू इंगेज इन ओपन सोर्स कंट्रीब्यूशन फ्रॉम द फर्स्ट ईयर इट सेल्फ सो इट क्रिएट अ ग्रेट इंपैक्ट ऑन आरसी अ लेट्स सपोज Advice for juniors देयर इज समबे इन देयर फर्स्ट ईयर एंड देर जस्ट अबाउट टू स्टार्ट देयर कोडिंग जर्नी सो डू यू हैव एनी एडवाइस फॉर देम या बेसिकली डोंट ट्राई टू मग अप एवरीथिंग लाइक डीएस इज नॉट अ वन मकिंग अप यू हैव टू जस्ट अंडरस्टैंड सम कांसेप्ट एंड देन लाइक अप्लाई इट बट डू नॉट मग अप एवरीथिंग लाइक जूनियर्स दे दे फॉलो सम सीट एंड दे मग अप ऑल द प्रॉब्लम्स दे डोंट ववर थिंक अबाउट द कॉन्सेप्ट्स एंड एनीथिंग बट इन द इंटरव्यू इन द टॉप पीवीसी इंटरव्यू बेसिकली लाइक google2 डू यू हैव एनी एडवाइस फॉर देम सो लाइक कंप्लीट डीएसए एंड लाइक या सो प्रोजेक्ट्स वगैरह अच्छे से बनाने चाहिए हम प्रोजेक्ट्स लाइक शड बी द रैंडम क्लोनस ऑफ एनीथिंग यू शुड बिल्ड समथिंग इनोवेटिव बिल्ड समथिंग न्यू आप सीखो का इससे क्लोन बनाओ बट उसके बाद आप खुद से इंप्लीमेंट करो और कुछ यूजफुल बनाओ हैथ में पाट लो लाइक हैथ में फर्स्ट ईयर से ही पाट लेना चाहिए जब आपको नहीं आता तब भी हैथ से पाट लो कुछ सीखो धीरे-धीरे धीरे-धीरे करते करते सीख जाएंगे एंड देन आल्सो कुछ कुछ ओ ओपन सोर्स प्रोग्राम होते है जैसे ओपन सोर्स सीखो धीरे-धीरे से इवेंचर लेवल और जैसे ही रिज्यूमे अच्छे बन जाएगा आपको खुद कॉन्फिडेंस आ जाएगा एंड देन प्रैक्टिस इज मस्ट सो व्हाट ड यू थिंक वाज द वाओ Wow factor फैक्टर इन योर रिज्यूमे जो शॉर्टलिस्ट कराने में जिसम सबसे ज्यादा हेल्प किया सो बेसिकली मैम रिज्यूमे मेरे लाइक देयर इज अ कॉमिनेशन ऑफ एवरीथिंग लाइक ऑल राउंड सो देयर वाज अ हैक अथन देयर वाज डीएसए देयर वाज कोडिंग प्रोफाइल्स ऑन कोड फोर्सेस लीड कोड कोड शफ देयर वाज ओपन सोर्स कंट्रीब्यूशन अक्रॉस अक्रस वेरियस प्लेटफॉर्म्स एंड आल्सो आई हैड वन एक्सपीरियंस अब ऑफ चिंग असिस्टेंट सो लाइक इट क्रिएटेडटेड यू एवर थिंक अबाउट पार्टिसिपेटिंग इन ओपन सोर्स प्रोग्राम्स लाइक जी सक डिड यू अप्लाई फॉर देम स बेसिकली सेकंड लाइक टिल द थर्ड ईयर आई डिडेंट न अबाउट दैट प्रोग्राम दिस प्रोग्राम लाइक जी सॉक एंड हम सो आफ्टर द कंप्लीशन ऑफ लाइक फोर्थ सेमेस्टर आई हर्ड अबाउट दैट जी सॉक इज समथिंग लाइक नेक्स्ट ईयर आई विल लाइक इन 2025 आई विल बी टारगेटिंग ग समर ऑफ कोल्ड ऑफ कोर्स ओके Placement scenario अच्छा ये बताओ अगर आपके कॉलेज के अंदर देयर आर 100 स्टूडेंट्स हु आर सेटिंग फॉर इंटर्नशिप इंटरव्यूज तो प्लेसमेंट सीजन के अंदर 100 में से कितने स्टूडेंट्स आपको लगता है जो सीरियसली टेक प्लेसमेंट्स की तैयारी करते हैं टेक इंटर्नशिप की तैयारी करते हैं बेसिकली सेकंड ईयर के बाद क्या होता है कि लाइक जब इंटर्नशिप सीजन आता है उस टाइम पे ज्यादा लोग प्रिपेयर नहीं होते हैं इंटर्नशिप के लिए क्योंकि उन्होंने वो कंपटीशन देखा नहीं हुआ रहता या उनको पता नहीं रहता बट जैसे जैसे इंटर्नशिप लगते जाता है लोगों का तो आपको खुद लगता है आप खुद पीछे फील करोगे कि उसका लग गया मेरा नहीं हम लोगों ने सेम जगह से स्टार्ट करा था सेम ब्रांच थी तब भी उसका लग रहा है मेरा नहीं मतलब उसने प्रैक्टिस करा तो शुरू शुरू में तो कंपटीशन बहुत कम रगा लेकिन धीरे-धीरे क्या होता है कि सब प्रैक्टिस करने लग जाते हैं सब सब कोई इंप्रूव सब कोई प्रोजेक्ट बना रहा है अच्छे-अच्छे ऐसा होता है कि सब लोग अपना इक्वली कैपेबल हो जाते हैं उसके लिए तो लाइक प्लेसमेंट के टाइम बहुत ज्यादा बढ़ जाता है वो हम लोग का कंपटीशन सो ठीक है Role of college डू यू थिंक इफ यू केम फ्रॉम अ टियर थ्री कॉलेज देन यू वुड हैव गोटन द सेम अपॉर्चुनिटी और यू वुड हैव गोटन सिलेक्टेड फॉर फॉर google3 यर से होता तो सीवी रेजू मेंे तो कॉलेज आई नो कॉलेज हैज सम इंपोर्टेंट ह बट एज माय रिज्यूमे गॉट सिलेक्टेड इन ऑफ कैंपस आल्सो सो बेसिकली वो जो 10 डेज का था ऑनलाइन असेसमेंट से राउंड वन वो वाली टेंशन कम हो जाती थोड़ी तो लाइक आई डोंट नो व्हाट द एग्जैक्ट आउटकम वुड बी बट लाइक जो अगर आपके पास स्किल्स है और आपके अच्छे-अच्छे प्रोजेक्ट्स बनाए हैं डीए से प्रैक्टिस करी है तो लाइक कोई कॉलेज से हो टियर वन टियर टू वो मैटर नहीं करता वो मैटर तभी करता है अगर आप आपको थोड़ा कम आता है और लाइक आपके जितने स्टूडेंट्स उसे ज्यादा कंपनीज आ रही है तब तो आपका सिलेक्शन हो जाएगा अगर आप टॉप यर्स हो नीचे हो तो आप अगर अच्छे से पिल्ड प्रोजेक्ट आपके प्रैक्टिस अच्छे है आपके कोडिंग प्रोफाइल्स अच्छे हैं देन नो वन कैन स्टॉप यू लाइक ठीक है इज देयर एनीथिंग Tips एल्स दैट यू वुड लाइक टू शेयर अबाउट योर जर्नी सो बेसिकली लाइक कभी भी अंडर कॉन्फिडेंट फील नहीं करना चाहिए बेसिकली आई वेस्टेड लाइक फोर टू फाइव डेज जस्ट थिंकिंग अबाउट की लाइक ऑनलाइन असेसमेंट में नहीं हुआ तो क्या होगा माइक्रोसॉफ्ट से रिजेक्शन आ गई तो अब क्या होगा अब कुछ अब कुछ नहीं कर सकते अब वापस से ये तो लाइक कंटिन्यूटी ब्रेक हो जाती है एक बार अगर आप कंटीन्यूअस हो तो आपका जो सीखने का कैपेबिलिटी वो बढ़ जाता है आपको जल्दी जल्दी समझ चीजें समझ आने लगती है आपको जल्दी-जल्दी याद होने लगती है चीजें तो लाइक बट अगर एक बार कंटिन्यूटी ब्रेक हो जाता है तो आपको वापस से रीस्टार्ट करने में कुछ टाइम लगता है तो टाइम वेस्ट होता है तो उसके बाद वो फिर आपका वो हैपर करता है तो लाइक आपको जो है कभी भी अगर आपको फेलियर मिले तो आपको सर पकड़ के नहीं बैठना आपको वही मेहनत करते रहनी है कभी ना कभी अगर आपने मेहनत करी होगी सही से तो किसी ना किसी रास्ते से मिली जाएगी जो Stipend details मिलना होगा ओके आर देयर एनी प्लांस टू डू समथिंग विद योर फर्स्ट इंटर्नशिप स्टेटमेंट जब आएगा बेसिकली लाइक मम्मी को घुमाना है बोली थी म ममी मम्मी ने कहा था कि लाइक जब अच्छा इंडिया में बहुत सारे जगह घूमना है उनको तो लाइक कुछ-कुछ जगह इंटर्नशिप टाइ बेंड से है ठीक है तो आपकी बैंगलोर के अंदर इंटर्नशिप है कहां पे है सस एम बैंगलोर बैंगलोर तो कब से कब तक है आपकी इंटर्नशिप टेंटेटिव डेट इज अराउंड 4 जून 4 जून एंड व्हाट इज द इंटर्नशिप स्टाइप फॉर google2 सो बेसिकली द कोर्स टाइप एंड लाइक द विदाउट रीलोकेशन इज 125000 ह एंड विथ लाइक रिय लोकेशन इट वड बी अराउंड 180000 तो मेंटरशिप सेशंस वगैरह Mentorship sessions अटेंड किए थे आपने बैच के अंदर यस माइन बैच वाज बेलमन फड बैच बेलमन फड थ्री कैम तो व्हाट वाज द एक्सपीरियंस कौन सा सेशन आपको लगता है सबसे ज्यादा उसने हेल्प किया बेसिकली रेजू में बल्डिंग सेक्शन क्योंकि उस सेशन से पहले मैं रेजू में पूरा खाली था बस नाम था कॉलेज के नाम थे बस प्रोजेक्ट वगैरह का मेरे को आइडिया क्योंकि मैं डीए से पढ़ रहा था तो उसका रेजूम बिल्डिंग सेशन में जब आपने रिज्यूमे दिखाया था डेमो रिज्यूमे बहुत सरा तब उसके बाद मेरा रेजूम भरना स्टार्ट नहीं तो ऐसे चार से पांच लाइन में रेजूम खत्म मैं 10थ के मार्कशीट अचीवमेंट्स में मैं एथ क्लास का अचीवमेंट लिख रहा था 10थ क्लास का उसका धीरे-धीरे कंटेस्ट देना स्टार्ट करा अचीवमेंट्स बिल्ड हुए फिर हैक अथन में पार्ट लेना स्टार्ट करा सो बेसिकली दे द मेंटरशिप सीजन लाइक रेजूम रिज्यूमे बिल्डिंग वाज बेस्ट वन उससे बहुत कुछ सीखने को मिला था ओके शिवम ठीक है तो हम रैप अप करते हैं इंटरव्यू तो आई होप कि शिवम की जर्नी से हमें कई सारी चीजें कई सारी इंस्पिरेशन भी साथ के साथ सीखने को मिली होगी शिवम के पूरे प्रोफाइल के अंदर द बेस्ट थिंग दैट आई लाइक्ड अबाउट इट वाज कि रिज्यूमे के अंदर देयर इज समथिंग अबाउट डीएसए एंड इनफैक्ट समथिंग नहीं देयर आर अ लॉट ऑफ डिफरेंट लिंक्स ऑफ डिफरेंट कोडिंग प्रोफाइल्स कि वो डीएससी की रेगुलरली प्रैक्टिस करते हैं उसके साथ में देयर आर आल्सो फुल स्टैक प्रोजेक्ट्स फुल स्टैक के साथ में उन्होंने एक मशीन लर्निंग प्रोजेक्ट के ऊपर भी काम किया है एंड साथ के साथ में देयर इज आल्सो ओपन सोर्स कंट्रीब्यूशन एक्सपीरियंस तो एक जो ओवरऑल अच्छी प्रोफाइल होती है टेक ओरिएंटेड प्रोफाइल होती है अलोंग विद गुड एकेडमिक स्कोर वो उन्होंने मेंटेन करने की कोशिश की है एंड आई वुड से दैट दिस इज वन ऑफ अर आइडियल जो एक रेजूमेक्स फाइल के लिए वो आइडियल रिज्यूमे के बहुत ही ज्यादा पास है या इनफैक्ट इट इज एन आइडियल रिज्यूमे व्हिच आई रियली लाइक्ड अबाउट हिज प्रोफाइल तो कई सारी चीजें हैं जो उनकी जर्नी से एक्स्ट्रा एडिशनल हमें सीखने को मिली डेफिनेटली इफ यू आर सबब जो डीएसए डेवलपमेंट एंड और एक्स्ट्रा चीजें जाकर सीख रहा है इट रिक्वायर्स अ लॉट ऑफ हार्ड वर्क इट रिक्वायर्स अ लॉट ऑफ डेडिकेशन जो शिवम की जर्नी से हमें डेफिनेटली देखने को मिल रहा है तो आई होप कि वो चीजें हम अपनी जर्नी के अंदर भी जाकर रिप्लिकेट करें तो आज के लिए इतना ही मिलते हैं नेक्स्ट इंटरव्यू के अंदर टिल देन कीप लर्निंग एंड कीप एक्सप्लो स्थ डीप फ्ला च फम टर्फ आई नेव स्विच साइ लाक इवन वन आई डा आ राड फ द स्क्वा ला टाय इ हर्स",
    formatted_transcript: [
      { start_time: 0, end_time: 71000, duration: 71000, text: "Introduction" },
      {
        start_time: 0,
        end_time: 2120,
        duration: 2120,
        text: "बेसिकली सीजीपीए एक्चुअली इज अ हिडन",
      },
      {
        start_time: 2120,
        end_time: 4440,
        duration: 2320,
        text: "क्रिटेक जेबी मॉर्गन में था उन्होंने कहा",
      },
      {
        start_time: 4440,
        end_time: 6520,
        duration: 2080,
        text: "था कि 88.5 प्लस सीजीपीए वाले सारे अलाउड",
      },
      {
        start_time: 6520,
        end_time: 8400,
        duration: 1880,
        text: "है तो बहुत लोगों ने फॉर्म फिल कर दिया तो",
      },
      {
        start_time: 8400,
        end_time: 9760,
        duration: 1360,
        text: "लाइक अगर लिमिट ज्यादा हो गया था तो",
      },
      {
        start_time: 9760,
        end_time: 11679,
        duration: 1919,
        text: "उन्होंने 8.8 का क्राइटेरिया इंटरनली लगा",
      },
      {
        start_time: 11679,
        end_time: 13679,
        duration: 2000,
        text: "दिया और 8.5 से 88.8 वालों को शॉर्टलिस्ट",
      },
      {
        start_time: 13679,
        end_time: 16320,
        duration: 2641,
        text: "नहीं करा अच्छा ये बताओ अगर आपके कॉलेज के",
      },
      {
        start_time: 16320,
        end_time: 18359,
        duration: 2039,
        text: "अंदर देयर आर 100 स्टूडेंट्स हु आर सेटिंग",
      },
      {
        start_time: 18359,
        end_time: 21279,
        duration: 2920,
        text: "फॉर अ इंटर्नशिप इंटरव्यूज तो प्लेसमेंट",
      },
      {
        start_time: 21279,
        end_time: 23480,
        duration: 2201,
        text: "सीजन के अंदर 100 में से कितने स्टूडेंट्स",
      },
      {
        start_time: 23480,
        end_time: 25119,
        duration: 1639,
        text: "आपको लगते हैं जो सीरियसली टेक",
      },
      {
        start_time: 25119,
        end_time: 26599,
        duration: 1480,
        text: "प्लेसमेंट्स की तैयारी करते हैं टेक",
      },
      {
        start_time: 26599,
        end_time: 28560,
        duration: 1961,
        text: "इंटर्नशिप की तैयारी करते हैं बेसिकली आई",
      },
      {
        start_time: 28560,
        end_time: 30240,
        duration: 1680,
        text: "वेस्टेड लाइक फोर टू फाइव डेज जस्ट",
      },
      {
        start_time: 30240,
        end_time: 31880,
        duration: 1640,
        text: "थिंकिंग अबाउट कि लाइक ऑनलाइन असेसमेंट",
      },
      {
        start_time: 31880,
        end_time: 34879,
        duration: 2999,
        text: "में नहीं हुआ तो क्या होगा",
      },
      {
        start_time: 56800,
        end_time: 59519,
        duration: 2719,
        text: "microsoft's कंपनीज तो जानते हैं शिवम की",
      },
      {
        start_time: 59519,
        end_time: 61800,
        duration: 2281,
        text: "पूरी टेक्निकल जर्नी के बारे में सो शिवम",
      },
      {
        start_time: 61800,
        end_time: 63840,
        duration: 2040,
        text: "टेल अस अबाउट योरसेल्फ एक्चुअली माय नेम",
      },
      {
        start_time: 63840,
        end_time: 65720,
        duration: 1880,
        text: "शिवम कुमार आई एम करेंटली अ थर्ड ईयर अंडर",
      },
      {
        start_time: 65720,
        end_time: 67280,
        duration: 1560,
        text: "ग्रेजुएट एट नेशनल इंस्टिट्यूट ऑफ",
      },
      {
        start_time: 67280,
        end_time: 69360,
        duration: 2080,
        text: "टेक्नोलॉजी जमशेदपुर फ्रॉम कंप्यूटर साइंस",
      },
      {
        start_time: 69360,
        end_time: 71159,
        duration: 1799,
        text: "एंड इंजीनियरिंग ब्रांच तो यू गट",
      },
      {
        start_time: 71000,
        end_time: 186000,
        duration: 115000,
        text: "Google Hiring process",
      },
      {
        start_time: 71159,
        end_time: 74640,
        duration: 3481,
        text: "सिलेक्टेड फॉर एन इंटर्नशिप एट",
      },
      {
        start_time: 89880,
        end_time: 93600,
        duration: 3720,
        text: "यर्स पोर्टल से हम तो लाइक उसके वन मंथ के",
      },
      {
        start_time: 93600,
        end_time: 96438,
        duration: 2838,
        text: "बाद मेरे कॉलेज में भी",
      },
      {
        start_time: 119920,
        end_time: 122000,
        duration: 2080,
        text: "उसमें दो क्वेश्चंस थे एक डीपी पे था और",
      },
      {
        start_time: 122000,
        end_time: 125280,
        duration: 3280,
        text: "एक ऑयलर टूर पे था ीज का सो आई मैनेज टू",
      },
      {
        start_time: 125280,
        end_time: 127719,
        duration: 2439,
        text: "सॉल्व वन ओनली सो लाइक अंडर कॉन्फिडेंट था",
      },
      {
        start_time: 127719,
        end_time: 129640,
        duration: 1921,
        text: "कि होगा या नहीं होगा सो उसके बाद लाइक",
      },
      {
        start_time: 129640,
        end_time: 131640,
        duration: 2000,
        text: "फोर टू फाइव डेज लेटर शॉर्ट लिस्टिंग में",
      },
      {
        start_time: 131640,
        end_time: 134200,
        duration: 2560,
        text: "मेरी नाम आ गई सो उसके बाद फिर इंटरव्यू",
      },
      {
        start_time: 134200,
        end_time: 136040,
        duration: 1840,
        text: "शेड्यूल्ड हुए थे उसके फोर टू फव मब 10",
      },
      {
        start_time: 136040,
        end_time: 138080,
        duration: 2040,
        text: "डेज का गैप था ओए और इंटरव्यूज के बीच में",
      },
      {
        start_time: 138080,
        end_time: 139640,
        duration: 1560,
        text: "सो फर्स्ट राउंड हुआ फर्स्ट राउंड में",
      },
      {
        start_time: 139640,
        end_time: 141200,
        duration: 1560,
        text: "बेसिकली प्रोजेक्ट्स पे डिस्कशन हुआ",
      },
      {
        start_time: 141200,
        end_time: 142640,
        duration: 1440,
        text: "बेसिकली वन ही प्रोजेक्ट हुआ था जो मैंने",
      },
      {
        start_time: 142640,
        end_time: 145200,
        duration: 2560,
        text: "कोड फॉर गुड है केथन जो पीएमसी होता है",
      },
      {
        start_time: 145200,
        end_time: 147800,
        duration: 2600,
        text: "उसका प्रोजेक्ट पे डिस्कशन हुआ देन रिकजन",
      },
      {
        start_time: 147800,
        end_time: 150239,
        duration: 2439,
        text: "का एक बेसिक सा सिंपल सा क्वेश्चन था ह",
      },
      {
        start_time: 150239,
        end_time: 152920,
        duration: 2681,
        text: "देन देयर वाज अ क्वेश्चन व्हिच वाज बिट टफ",
      },
      {
        start_time: 152920,
        end_time: 154920,
        duration: 2000,
        text: "बिकॉज ऑफ वेरियस कांसेप्ट इवॉल्व लाक",
      },
      {
        start_time: 154920,
        end_time: 156959,
        duration: 2039,
        text: "प्रायोरिटी क्यूज मैप्स एंड रेंडमाइज",
      },
      {
        start_time: 156959,
        end_time: 158840,
        duration: 1881,
        text: "सर्टिंग एल्बोज सो बेसिकली उस परे",
      },
      {
        start_time: 158840,
        end_time: 160959,
        duration: 2119,
        text: "इंटरव्यू एंड हो गया फर्स्ट राउंड हम देन",
      },
      {
        start_time: 160959,
        end_time: 163040,
        duration: 2081,
        text: "आफ्टर फोर टू फाइव डेज अगेन राउंड टू",
      },
      {
        start_time: 163040,
        end_time: 166200,
        duration: 3160,
        text: "शेड्यूल्ड हुआ उसमें देयर वाज वन क्वेश्चन",
      },
      {
        start_time: 166200,
        end_time: 168760,
        duration: 2560,
        text: "बेड ऑन बैकवर्ड डायनेमिक प्रोग्रामिंग एंड",
      },
      {
        start_time: 168760,
        end_time: 171640,
        duration: 2880,
        text: "वन क्वेश्चन वाज लाइक इट वाज सिंपली डीपी",
      },
      {
        start_time: 171640,
        end_time: 174040,
        duration: 2400,
        text: "बट लाइक इट इवॉल्व ऑप्टिमाइजेशन ऑ टू ओवन",
      },
      {
        start_time: 174040,
        end_time: 176120,
        duration: 2080,
        text: "स्पेस बेसिकली डीडीपी को हम ओवन स्पेस में",
      },
      {
        start_time: 176120,
        end_time: 177959,
        duration: 1839,
        text: "करना स सो इट वाज बिट ट्रिकी एंड देन सम",
      },
      {
        start_time: 177959,
        end_time: 180040,
        duration: 2081,
        text: "थियोरेटिकल क्वेश्चंस अबाउट हाउ हाउ हैश ट",
      },
      {
        start_time: 180040,
        end_time: 182760,
        duration: 2720,
        text: "वर्क्स ह एंड लाइक दिस ओनली सो देन उसके",
      },
      {
        start_time: 182760,
        end_time: 185280,
        duration: 2520,
        text: "लाइक अबाउट 15 डेज के बाद रिजल्ट उसका आ",
      },
      {
        start_time: 185280,
        end_time: 187680,
        duration: 2400,
        text: "गया देन आई गट शॉर्ट लिस्टेड तो रिजल्ट जब",
      },
      {
        start_time: 186000,
        end_time: 211000,
        duration: 25000,
        text: "Parents' reaction",
      },
      {
        start_time: 187680,
        end_time: 190040,
        duration: 2360,
        text: "आया आपने पेरेंट्स को बताया होगा व्हाट",
      },
      {
        start_time: 190040,
        end_time: 192680,
        duration: 2640,
        text: "वाज देयर रिएक्शन बेसिकली दे वेर नॉट",
      },
      {
        start_time: 192680,
        end_time: 194720,
        duration: 2040,
        text: "बिलीविंग एट मी एट ऑल सो बिकॉज मैंने कहा",
      },
      {
        start_time: 194720,
        end_time: 196680,
        duration: 1960,
        text: "था मेरा इंटरव्यू इतना अच्छा नहीं गया तो",
      },
      {
        start_time: 196680,
        end_time: 199440,
        duration: 2760,
        text: "वो कह रहे थे झूठ मत बोलो कॉलेज जिस दिन",
      },
      {
        start_time: 199440,
        end_time: 201360,
        duration: 1920,
        text: "खुला था मतलब समर वेकेशन के बाद मैं कॉलेज",
      },
      {
        start_time: 201360,
        end_time: 203080,
        duration: 1720,
        text: "आया था तो उसी दिन रिजल्ट आया था तो मैंने",
      },
      {
        start_time: 203080,
        end_time: 204840,
        duration: 1760,
        text: "बोला तो मजाक मत करो ये तो उसके बाद फिर",
      },
      {
        start_time: 204840,
        end_time: 207040,
        duration: 2200,
        text: "मैंने जब मेल दिखाया प्लेसमेंट सेल से आया",
      },
      {
        start_time: 207040,
        end_time: 209480,
        duration: 2440,
        text: "था तो उसके बाद दे वर वेरी हैप्पी एंड ट",
      },
      {
        start_time: 209480,
        end_time: 213879,
        duration: 4399,
        text: "ठीक ओ शिवम हाउ डिड यू स्टार्ट योर",
      },
      {
        start_time: 211000,
        end_time: 352000,
        duration: 141000,
        text: "Preparation",
      },
      {
        start_time: 215159,
        end_time: 218120,
        duration: 2961,
        text: "एंटायस मंथ्स की आपकी प्रिपरेशन रही होगी",
      },
      {
        start_time: 218120,
        end_time: 220040,
        duration: 1920,
        text: "क्या-क्या आपने कोडिंग के अंदर चीजें सीखी",
      },
      {
        start_time: 220040,
        end_time: 223400,
        duration: 3360,
        text: "बिफोर यू स्टार्टेड अप्लाइक 2022 में जब",
      },
      {
        start_time: 223400,
        end_time: 225760,
        duration: 2360,
        text: "जे एडवांस मैंने दिया उसके बाद सोचा कि",
      },
      {
        start_time: 225760,
        end_time: 227799,
        duration: 2039,
        text: "लाइक कोडिंग क्या होता है कुछ पता नहीं था",
      },
      {
        start_time: 227799,
        end_time: 229439,
        duration: 1640,
        text: "तो उसके बाद मैंने भैया से अपने पूछा तो",
      },
      {
        start_time: 229439,
        end_time: 230879,
        duration: 1440,
        text: "उन्होंने कहा जैसे हम लोग में लैंग्वेज",
      },
      {
        start_time: 230879,
        end_time: 232159,
        duration: 1280,
        text: "बात करते वैसे कंप्यूटर को भी कुछ",
      },
      {
        start_time: 232159,
        end_time: 234079,
        duration: 1920,
        text: "लैंग्वेज समझ आती है लाइक उसमें कोड करते",
      },
      {
        start_time: 234079,
        end_time: 235959,
        duration: 1880,
        text: "हैं इसलिए लेमंड टर्म्स उ लोग समझा रहे थे",
      },
      {
        start_time: 235959,
        end_time: 238640,
        duration: 2681,
        text: "सी जावा ये सब होती है हम तो मैंने पूछा",
      },
      {
        start_time: 238640,
        end_time: 240280,
        duration: 1640,
        text: "कि मेरे को भी स्टार्ट कर नहीं तो कहां से",
      },
      {
        start_time: 240280,
        end_time: 242560,
        duration: 2280,
        text: "करूं तो उन्होंने कहा सी सीख लो मदर ऑफ ऑल",
      },
      {
        start_time: 242560,
        end_time: 244400,
        duration: 1840,
        text: "लैंग्वेज है ले मैंने सोचा चलो ठीक है",
      },
      {
        start_time: 244400,
        end_time: 246799,
        duration: 2399,
        text: "लेकिन मैं",
      },
      {
        start_time: 258799,
        end_time: 261160,
        duration: 2361,
        text: "youtube1 मंथ मैंने वही सारे लेक्चर देखा",
      },
      {
        start_time: 261160,
        end_time: 262880,
        duration: 1720,
        text: "कि सबका सब क्या क्या हो रहा है क्या हो",
      },
      {
        start_time: 262880,
        end_time: 264680,
        duration: 1800,
        text: "रहा है उसके बाद आपका लेक्चर भी देखा सबका",
      },
      {
        start_time: 264680,
        end_time: 266520,
        duration: 1840,
        text: "देख उसके बाद ना आपका 1 नवंबर को अल्फा",
      },
      {
        start_time: 266520,
        end_time: 269960,
        duration: 3440,
        text: "2.2 बैच आया तो आपका मैंने उस टाइम तक",
      },
      {
        start_time: 269960,
        end_time: 272520,
        duration: 2560,
        text: "लाइक 15 टू 16 लेक्चर देख रखे थे तो मैंने",
      },
      {
        start_time: 272520,
        end_time: 274479,
        duration: 1959,
        text: "सोचा बैच लेके वहीं से प्रिपेयर करते हैं",
      },
      {
        start_time: 274479,
        end_time: 276560,
        duration: 2081,
        text: "हम और कॉलेज खुलने में अ भी टाइम थी लाइक",
      },
      {
        start_time: 276560,
        end_time: 278840,
        duration: 2280,
        text: "30 डेज थी लगभग तो मैंने वहां से किया 30",
      },
      {
        start_time: 278840,
        end_time: 280759,
        duration: 1919,
        text: "डेज तक करा उसके बाद सब समझ आ रहा था उसके",
      },
      {
        start_time: 280759,
        end_time: 282520,
        duration: 1761,
        text: "बाद फिर मेरा कॉलेज स्टार्ट हुआ तो थोड़ा",
      },
      {
        start_time: 282520,
        end_time: 284360,
        duration: 1840,
        text: "इरेगुलेरिटी आ गया मेरे में तो लाइक",
      },
      {
        start_time: 284360,
        end_time: 287080,
        duration: 2720,
        text: "फर्स्ट सेमेस्टर तो ना सीजीपीए पे ध्यान",
      },
      {
        start_time: 287080,
        end_time: 289639,
        duration: 2559,
        text: "रहा ना किसी पे तो कॉलेज स्टार्ट होने से",
      },
      {
        start_time: 289639,
        end_time: 292080,
        duration: 2441,
        text: "पहले आपने मैच लेया वहां से आपने पढ़ा एक",
      },
      {
        start_time: 292080,
        end_time: 294800,
        duration: 2720,
        text: "महीने हां उसके बाद फिर इसमें पॉज आ गया",
      },
      {
        start_time: 294800,
        end_time: 296520,
        duration: 1720,
        text: "तो लाइक सीजीपीए भी गिर गई ना कोडिंग आ",
      },
      {
        start_time: 296520,
        end_time: 299080,
        duration: 2560,
        text: "रही थी सारे बैचमेट्स भी आगे जा रहे थे तो",
      },
      {
        start_time: 299080,
        end_time: 301160,
        duration: 2080,
        text: "उसके बाद मैं वापस से लेक्चर देखना शुरू",
      },
      {
        start_time: 301160,
        end_time: 303400,
        duration: 2240,
        text: "किए कंटिन्यू कंटिन्यू किया और लाइक सेकंड",
      },
      {
        start_time: 303400,
        end_time: 305320,
        duration: 1920,
        text: "सेमेस्टर के में मेरा पूरा लेक्चर खत्म हो",
      },
      {
        start_time: 305320,
        end_time: 307880,
        duration: 2560,
        text: "गया था हम सारे कोर्सेस उसके बाद मैंने",
      },
      {
        start_time: 307880,
        end_time: 310000,
        duration: 2120,
        text: "सीधा प्रैक्टिस करने लगा लीड कोड पे उसके",
      },
      {
        start_time: 310000,
        end_time: 311919,
        duration: 1919,
        text: "बाद फिर सब प्रोजेक्ट्स का बात आ रहा था",
      },
      {
        start_time: 311919,
        end_time: 313240,
        duration: 1321,
        text: "कि प्रोजेक्ट्स बनाना पड़ेंगे तो फिर वेब",
      },
      {
        start_time: 313240,
        end_time: 315440,
        duration: 2200,
        text: "डेवलपमेंट करा ऐसे धीरे-धीरे उसका फिर",
      },
      {
        start_time: 315440,
        end_time: 317199,
        duration: 1759,
        text: "थोड़ा सा एमएल को भी करा उसका सेमेस्टर",
      },
      {
        start_time: 317199,
        end_time: 318759,
        duration: 1560,
        text: "में भी हम लोग का एमएल आ गया तो हम मैंने",
      },
      {
        start_time: 318759,
        end_time: 321479,
        duration: 2720,
        text: "एमएल पे फोकस करा ऐसे ऐसे करके तेते तो",
      },
      {
        start_time: 321479,
        end_time: 324120,
        duration: 2641,
        text: "लाइक प्रोजेक्ट्स बनते गए ठीक है तो करीबन",
      },
      {
        start_time: 324120,
        end_time: 326199,
        duration: 2079,
        text: "कितने मंथ्स का आपका टोटल प्रिपरेशन रहा",
      },
      {
        start_time: 326199,
        end_time: 329319,
        duration: 3120,
        text: "होगा बिफोर इंटर्नशिप्स डेढ़ साल 1.5",
      },
      {
        start_time: 329319,
        end_time: 333360,
        duration: 4041,
        text: "इयर्स 1.5 इयर्स एंड वाज",
      },
      {
        start_time: 352000,
        end_time: 422000,
        duration: 70000,
        text: "Rejections",
      },
      {
        start_time: 358639,
        end_time: 360759,
        duration: 2120,
        text: "googlegroups.com बट यू वर नॉट सिलेक्टेड",
      },
      {
        start_time: 360759,
        end_time: 363000,
        duration: 2241,
        text: "या फिर यू गट सिलेक्टेड फॉर माइक्रोसॉफ्ट",
      },
      {
        start_time: 363000,
        end_time: 366600,
        duration: 3600,
        text: "में मैंने अप्लाई करा था बेसिकली वो जब",
      },
      {
        start_time: 367919,
        end_time: 370479,
        duration: 2560,
        text: "google2 क्वेश्चन हो गए थे उसी के बीच",
      },
      {
        start_time: 370479,
        end_time: 371919,
        duration: 1440,
        text: "मैंने माइक्रोसॉफ्ट का अप्लाई करा और एक",
      },
      {
        start_time: 371919,
        end_time: 373479,
        duration: 1560,
        text: "दिन के अंदर ही मेरा रिज्यूमे रिजेक्ट हो",
      },
      {
        start_time: 373479,
        end_time: 376039,
        duration: 2560,
        text: "गया रिजेक्शन मेल आ गया सो लाइक बहुत",
      },
      {
        start_time: 376039,
        end_time: 377759,
        duration: 1720,
        text: "ज्यादा अंडर कॉन्फिडेंट फील हुआ कि यार एक",
      },
      { start_time: 377759, end_time: 379880, duration: 2121, text: "तो" },
      {
        start_time: 389759,
        end_time: 391960,
        duration: 2201,
        text: "फीलिंग ऑफ फीलिंग अंडर कॉन्फिडेंट बेसिकली",
      },
      {
        start_time: 391960,
        end_time: 394360,
        duration: 2400,
        text: "मैंने सोच मैम आई थॉट कि मैं शुरू से वापस",
      },
      {
        start_time: 394360,
        end_time: 397120,
        duration: 2760,
        text: "रीस्टार्ट करते हैं लाइक ऐसा था कि",
      },
      {
        start_time: 397120,
        end_time: 398560,
        duration: 1440,
        text: "रिग्रेट हो रहा था कि मैंने क्यों ऑन",
      },
      {
        start_time: 398560,
        end_time: 400720,
        duration: 2160,
        text: "कैंपस अप्लाई करा ऑफ कैंपस से सीधा",
      },
      {
        start_time: 400720,
        end_time: 402080,
        duration: 1360,
        text: "इंटरव्यू कम से कम इंटरव्यू देने का",
      },
      {
        start_time: 402080,
        end_time: 404880,
        duration: 2800,
        text: "अपॉर्चुनिटी मिलता तो लाइक मैं वापस से",
      },
      {
        start_time: 404880,
        end_time: 406800,
        duration: 1920,
        text: "चालू कर दिया से क्वांट वगैरह रीजनिंग",
      },
      {
        start_time: 406800,
        end_time: 408479,
        duration: 1679,
        text: "वगैरह कि अब जो दूसरी कंपनी आएगी वो",
      },
      {
        start_time: 408479,
        end_time: 410120,
        duration: 1641,
        text: "क्वांट पूछेगी रीजनिंग पूछेगी उसके लिए",
      },
      {
        start_time: 410120,
        end_time: 411599,
        duration: 1479,
        text: "मैंने अपना प्रैक्टिस करना शुरू कर दिया",
      },
      {
        start_time: 411599,
        end_time: 414080,
        duration: 2481,
        text: "था तो बस ऐसे ऐसे करा उसके बाद अचानक से",
      },
      {
        start_time: 414080,
        end_time: 416919,
        duration: 2839,
        text: "मेल आता है कि यू हैव सेड मतलब आपका राउंड",
      },
      {
        start_time: 416919,
        end_time: 419680,
        duration: 2761,
        text: "वन में सिलेक्शन हो गया है सो देन वापस से",
      },
      {
        start_time: 419680,
        end_time: 421599,
        duration: 1919,
        text: "इंटरव्यू के लिए डीएसए प्रैक्टिस करना",
      },
      {
        start_time: 421599,
        end_time: 424800,
        duration: 3201,
        text: "चालू कर दि तो डीएसए और डेवलपमेंट दोनों",
      },
      {
        start_time: 422000,
        end_time: 449000,
        duration: 27000,
        text: "DSA or Development",
      },
      {
        start_time: 424800,
        end_time: 426639,
        duration: 1839,
        text: "में से आपको क्या लगता है किसका ज्यादा",
      },
      {
        start_time: 426639,
        end_time: 428599,
        duration: 1960,
        text: "मेजर कंट्रीब्यूशन रहा टुवर्ड्स गेटिंग",
      },
      {
        start_time: 428599,
        end_time: 431199,
        duration: 2600,
        text: "योर इंटर्नशिप बेसिकली मैम अगर रिज्यूमे",
      },
      {
        start_time: 431199,
        end_time: 432759,
        duration: 1560,
        text: "के पर्सपेक्टिव से देखें तो रिज्यूमे के",
      },
      {
        start_time: 432759,
        end_time: 434840,
        duration: 2081,
        text: "लिए डेवलपमेंट बहुत इंपोर्टेंट है बिकॉज",
      },
      {
        start_time: 434840,
        end_time: 436680,
        duration: 1840,
        text: "क्वालिटी प्रोजेक्ट्स होते हैं तभी से",
      },
      {
        start_time: 436680,
        end_time: 438599,
        duration: 1919,
        text: "शॉर्ट लिस्टिंग होती है रिज्यूमे की एंड",
      },
      {
        start_time: 438599,
        end_time: 441240,
        duration: 2641,
        text: "इंटरव्यूज में मेरे से ज्यादातर लाइक 80",
      },
      {
        start_time: 441240,
        end_time: 443919,
        duration: 2679,
        text: "पर डीएस से ही पूछा गया प्रोजेक्ट पे बस",
      },
      {
        start_time: 443919,
        end_time: 446680,
        duration: 2761,
        text: "नॉर्मल सा डिस्कशन हुआ था नॉट लाइक दैट सो",
      },
      {
        start_time: 446680,
        end_time: 448879,
        duration: 2199,
        text: "बेसिकली डीएसए का इंपोर्टेंट रोल रहा था",
      },
      {
        start_time: 448879,
        end_time: 451319,
        duration: 2440,
        text: "ठीक है अच्छा व्हाट वाज द इंपॉर्टेंस ऑफ",
      },
      { start_time: 449000, end_time: 480000, duration: 31000, text: "CGPA" },
      {
        start_time: 451319,
        end_time: 454160,
        duration: 2841,
        text: "सीजीपीए इन द एंटायस बेसिकली सीजीपीए",
      },
      {
        start_time: 454160,
        end_time: 456599,
        duration: 2439,
        text: "एक्चुअली इज अ हिडन क्रिटी वो कोई बताता",
      },
      {
        start_time: 456599,
        end_time: 458800,
        duration: 2201,
        text: "नहीं है वो बस अंदर से रहता है कि लाइक और",
      },
      {
        start_time: 458800,
        end_time: 460360,
        duration: 1560,
        text: "जैसे कि जेबी मॉर्गन में था उन्होंने कहा",
      },
      {
        start_time: 460360,
        end_time: 462479,
        duration: 2119,
        text: "था कि 88.5 प्लस सीजीपी वाले सारे अलाउड",
      },
      {
        start_time: 462479,
        end_time: 464960,
        duration: 2481,
        text: "है ह तो बहुत लोगों ने फॉर्म फिल कर दिया",
      },
      {
        start_time: 464960,
        end_time: 466440,
        duration: 1480,
        text: "तो लाइक अगर लिमिट ज्यादा हो गया था तो",
      },
      {
        start_time: 466440,
        end_time: 468360,
        duration: 1920,
        text: "उन्होंने 8.8 का क्राइटेरिया इंटरनली लगा",
      },
      {
        start_time: 468360,
        end_time: 470400,
        duration: 2040,
        text: "दिया और 8.5 से 88.8 वालों को शॉर्टलिस्ट",
      },
      {
        start_time: 470400,
        end_time: 472960,
        duration: 2560,
        text: "नहीं करा सेम",
      },
      {
        start_time: 478440,
        end_time: 481319,
        duration: 2879,
        text: "googlegroups.com 9.14 है सो हाउ डिड यू",
      },
      {
        start_time: 480000,
        end_time: 560000,
        duration: 80000,
        text: "Time Management",
      },
      {
        start_time: 481319,
        end_time: 483560,
        duration: 2241,
        text: "मैनेज योर एकेडमिक्स अलोंग विद योर टेक",
      },
      {
        start_time: 483560,
        end_time: 485639,
        duration: 2079,
        text: "प्लेसमेंट प्रिपरेशन बेसिकली फर्स्ट",
      },
      {
        start_time: 485639,
        end_time: 487479,
        duration: 1840,
        text: "सेमेस्टर में लाइक कुछ नहीं पढ़ा था तो",
      },
      {
        start_time: 487479,
        end_time: 491240,
        duration: 3761,
        text: "उसमें सीजीपीए कम रही थी अब 8.6 8.7 थी",
      },
      {
        start_time: 491240,
        end_time: 494800,
        duration: 3560,
        text: "8.6 कम रही थी यस मैम सो बेसिकली सबकी",
      },
      {
        start_time: 494800,
        end_time: 497400,
        duration: 2600,
        text: "ज्यादा थी मेरे से तो लाइक से फिर सेकंड",
      },
      {
        start_time: 497400,
        end_time: 500000,
        duration: 2600,
        text: "सेमेस्टर में थोड़ा फोकस करा सीजीपी पर तो",
      },
      {
        start_time: 500000,
        end_time: 502240,
        duration: 2240,
        text: "बड़ी उसका थर्ड सेमेस्टर में क्या हुआ कि",
      },
      {
        start_time: 502240,
        end_time: 504319,
        duration: 2079,
        text: "लाइक डीएस एक पेपर आ गया डीएस का डेटा",
      },
      {
        start_time: 504319,
        end_time: 506199,
        duration: 1880,
        text: "स्ट्रक्चर का एक डीए का एनालिसिस ऑफ",
      },
      {
        start_time: 506199,
        end_time: 508759,
        duration: 2560,
        text: "एल्गोरिथम्स का और मैथ्स के दो पेपर आ गए",
      },
      {
        start_time: 508759,
        end_time: 510560,
        duration: 1801,
        text: "और लाइक ये सब्जेक्ट मेरे फेवरेट था तो",
      },
      {
        start_time: 510560,
        end_time: 513000,
        duration: 2440,
        text: "उसमें मेरी सीजी प बहुत हाई आ गई 9.6 आ गई",
      },
      {
        start_time: 513000,
        end_time: 515399,
        duration: 2399,
        text: "जिसके कारण ओवरऑल पूरा सीजी मेंटेन हो गया",
      },
      {
        start_time: 515399,
        end_time: 517680,
        duration: 2281,
        text: "उसका बाद फिर फोर्थ सेमेस्टर आया तो उसमें",
      },
      {
        start_time: 517680,
        end_time: 521440,
        duration: 3760,
        text: "भी लाइक और 8.9 अराउंड इतनी सीजी थी तो",
      },
      {
        start_time: 521440,
        end_time: 523959,
        duration: 2519,
        text: "बेसिकली उसके बाद से फिर मेंटेन नॉर्मल",
      },
      {
        start_time: 523959,
        end_time: 525680,
        duration: 1721,
        text: "टाइम एक्चुअली 14 डेज पहले से मैं",
      },
      {
        start_time: 525680,
        end_time: 527560,
        duration: 1880,
        text: "प्रिपेयर करता था एग्जाम का तो हो जाता था",
      },
      {
        start_time: 527560,
        end_time: 531320,
        duration: 3760,
        text: "उससे ओके तो एग्जाम टाइम प आप सीजीपीए प",
      },
      {
        start_time: 531320,
        end_time: 533560,
        duration: 2240,
        text: "फोकस करते थे तो टेक प्लेसमेंट प्रिपरेशन",
      },
      {
        start_time: 533560,
        end_time: 535839,
        duration: 2279,
        text: "के लिए टाइम निकाला कैसे आपने पूरी तैयारी",
      },
      {
        start_time: 535839,
        end_time: 539440,
        duration: 3601,
        text: "से बेसिकली कॉलेज को थोड़ा साइड करके",
      },
      {
        start_time: 539440,
        end_time: 542440,
        duration: 3000,
        text: "अटेंडेंस वगैरह प्रॉक्सी बॉक्सी लगा के इस",
      },
      {
        start_time: 542440,
        end_time: 544720,
        duration: 2280,
        text: "तरह से लाइक रूम प बैठ के करता था और",
      },
      {
        start_time: 544720,
        end_time: 546440,
        duration: 1720,
        text: "एग्जाम टाइप पर एग्जाम का फोकस करता था",
      },
      {
        start_time: 546440,
        end_time: 548959,
        duration: 2519,
        text: "जैसे बेसिकली टू मंथ के बाद हम लोग का मिड",
      },
      {
        start_time: 548959,
        end_time: 551000,
        duration: 2041,
        text: "सेम होता है तो लाइक वन मंथ 15 डेज डीएसए",
      },
      {
        start_time: 551000,
        end_time: 552800,
        duration: 1800,
        text: "करा 15 मंथ में इसका कर दिया प्रिपेयर",
      },
      {
        start_time: 552800,
        end_time: 554279,
        duration: 1479,
        text: "उसका बाद फिर हॉलीडेज मिलती है मिड सेम के",
      },
      {
        start_time: 554279,
        end_time: 555480,
        duration: 1201,
        text: "बाद उसमें भी अपना डीएसए वगैरह",
      },
      {
        start_time: 555480,
        end_time: 557399,
        duration: 1919,
        text: "प्रोजेक्ट्स वगैरह बिल्ड किया फिर एंड सेम",
      },
      {
        start_time: 557399,
        end_time: 559880,
        duration: 2481,
        text: "के 14 डेज पहले कर लिया प्रिपेयर ऐसे ऐसे",
      },
      {
        start_time: 559880,
        end_time: 562160,
        duration: 2280,
        text: "करके ओके एंड व्हाट वाज द इंपोर्टेंस ऑफ",
      },
      {
        start_time: 560000,
        end_time: 579000,
        duration: 19000,
        text: "CS Fundamentals",
      },
      {
        start_time: 562160,
        end_time: 564760,
        duration: 2600,
        text: "कंप्यूटर साइंस फंडामेंटल्स बेसिकली लाइक",
      },
      {
        start_time: 564760,
        end_time: 567680,
        duration: 2920,
        text: "कंप्यूटर साइंस फंडामेंटल्स इतना ग वगैरह",
      },
      {
        start_time: 567680,
        end_time: 569640,
        duration: 1960,
        text: "में तो नहीं बट कोर कंपनी ज्यादा पूछ तो",
      },
      {
        start_time: 569640,
        end_time: 572360,
        duration: 2720,
        text: "मैंने प्रिपेयर करने का सोचा था बट",
      },
      {
        start_time: 572360,
        end_time: 574079,
        duration: 1719,
        text: "एक्चुअली लाइक सेमेस्टर के लिए जैसे-जैसे",
      },
      {
        start_time: 574079,
        end_time: 576200,
        duration: 2121,
        text: "पढ़ते गए वैसे-वैसे सब प्रिपेयर होता गया",
      },
      {
        start_time: 576200,
        end_time: 578720,
        duration: 2520,
        text: "तो उतना इंपोर्टेंट मेरे को नहीं लगा ठीक",
      },
      {
        start_time: 578720,
        end_time: 580279,
        duration: 1559,
        text: "है कैन यू टेल अस मोर अबाउट योर",
      },
      {
        start_time: 579000,
        end_time: 627000,
        duration: 48000,
        text: "Projects",
      },
      {
        start_time: 580279,
        end_time: 581839,
        duration: 1560,
        text: "प्रोजेक्ट्स किस तरीके के प्रोजेक्ट्स",
      },
      {
        start_time: 581839,
        end_time: 584120,
        duration: 2281,
        text: "आपने रेजूम के अंदर मेंशन किए थे बेसिकली",
      },
      {
        start_time: 584120,
        end_time: 587200,
        duration: 3080,
        text: "वन इज माय द थन प्रोजेक्ट सो इट इज अ फुल",
      },
      {
        start_time: 587200,
        end_time: 589560,
        duration: 2360,
        text: "स्टैक एप्लीकेशन कंसिस्टिंग ऑफ एआई मॉडल्स",
      },
      {
        start_time: 589560,
        end_time: 592959,
        duration: 3399,
        text: "एंड टू एलएल एम्स वन इज लाइक अ फुल स्टैक",
      },
      {
        start_time: 592959,
        end_time: 594720,
        duration: 1761,
        text: "प्रोजेक्ट व्हिच इज अ फूड डिलीवरी पप",
      },
      {
        start_time: 594720,
        end_time: 596800,
        duration: 2080,
        text: "बेसिकली एंड वन इज अवर कोर्स प्रोजेक्ट",
      },
      {
        start_time: 596800,
        end_time: 598560,
        duration: 1760,
        text: "व्हिच इज हिस्टोग्राम ऑफ ओरिएंटेड डिट्स",
      },
      {
        start_time: 598560,
        end_time: 601800,
        duration: 3240,
        text: "बेसिकली इट इज अ एमएल मॉडल ट यूज टू एक्ट",
      },
      {
        start_time: 601800,
        end_time: 604160,
        duration: 2360,
        text: "एक्सट्रैक्ट इमेजेस एंड आईडेंटिफाई इमेजेस",
      },
      {
        start_time: 604160,
        end_time: 606839,
        duration: 2679,
        text: "बेसिकली एंड एज डिटेक्शन टू फुल स्टैक एंड",
      },
      {
        start_time: 606839,
        end_time: 609360,
        duration: 2521,
        text: "व एमएल टू फुल स्टैक प्रोजेक्ट एंड वन एमल",
      },
      {
        start_time: 609360,
        end_time: 611160,
        duration: 1800,
        text: "प्रोजेक्ट दो फुल स्टैक प्रोजेक्ट कौन से",
      },
      {
        start_time: 611160,
        end_time: 613800,
        duration: 2640,
        text: "टेक्स स्टैक में बनाए आपने बेसिकली वन वन",
      },
      {
        start_time: 613800,
        end_time: 616680,
        duration: 2880,
        text: "इज बिल्ट ऑन मन स्टैक एंड अदर इज लाइक इट",
      },
      {
        start_time: 616680,
        end_time: 618560,
        duration: 1880,
        text: "इज अ मेगा प्रोजेक्ट लाइक जेपीएमसी व इट",
      },
      {
        start_time: 618560,
        end_time: 620200,
        duration: 1640,
        text: "इज अ मेगा प्रोजेक्ट इट इज बिल्ट ऑन मन",
      },
      {
        start_time: 620200,
        end_time: 623640,
        duration: 3440,
        text: "स्टक एंड आई यूज फ्लस ए अ बैक एंड इट हैज",
      },
      {
        start_time: 623640,
        end_time: 626360,
        duration: 2720,
        text: "आल्सो एललम एंड जमना वेरियस एपीआई",
      },
      {
        start_time: 626360,
        end_time: 628800,
        duration: 2440,
        text: "इंटीग्रेशन ओके व्हाट ड यू थिंक वास द",
      },
      {
        start_time: 627000,
        end_time: 666000,
        duration: 39000,
        text: "Communication skills",
      },
      {
        start_time: 628800,
        end_time: 630680,
        duration: 1880,
        text: "इंपोर्टेंट ऑफ कम्युनिकेशन स्किल्स इन",
      },
      {
        start_time: 630680,
        end_time: 633399,
        duration: 2719,
        text: "इंटरव्यूज या बेसिकली कम्युनिकेशन स्किल",
      },
      {
        start_time: 633399,
        end_time: 637440,
        duration: 4041,
        text: "प्ले अ वेरी वाइटल रोल सो लाइक अगर आप जो",
      },
      {
        start_time: 637440,
        end_time: 639000,
        duration: 1560,
        text: "सोच रहे हैं उन इंटरव्यूअर को भी पता है",
      },
      {
        start_time: 639000,
        end_time: 640279,
        duration: 1279,
        text: "कि आप क्या सोच रहे हैं अगर आप मन में ही",
      },
      {
        start_time: 640279,
        end_time: 642480,
        duration: 2201,
        text: "सोचेंगे तो वो सोचेगा वो सोचेगा क्या लाइक",
      },
      {
        start_time: 642480,
        end_time: 645240,
        duration: 2760,
        text: "ये सोच रहा है या नहीं सोच रहा है या",
      },
      {
        start_time: 645240,
        end_time: 647680,
        duration: 2440,
        text: "हेजिन से जब टू वे कम्युनिकेशन रहेगा",
      },
      {
        start_time: 647680,
        end_time: 649600,
        duration: 1920,
        text: "इंटरव्यू के अराउंड तो लाइक वो ज्यादा",
      },
      {
        start_time: 649600,
        end_time: 651040,
        duration: 1440,
        text: "इंपैक्ट पड़ता है जैसे मैं कहीं भी फसता",
      },
      {
        start_time: 651040,
        end_time: 652720,
        duration: 1680,
        text: "था तो मैं डायरेक्ट इंटरव्यू से पूछता था",
      },
      {
        start_time: 652720,
        end_time: 654800,
        duration: 2080,
        text: "एम आई डूइंग राइट या ऐसे ही जाना चाहिए या",
      },
      {
        start_time: 654800,
        end_time: 657200,
        duration: 2400,
        text: "कुछ और अप्रोच लगाओ तो ऐसे ऐसे करके टाइम",
      },
      {
        start_time: 657200,
        end_time: 658600,
        duration: 1400,
        text: "कॉप्लेक्स टी भी जब एक्सप्लेन करने को",
      },
      {
        start_time: 658600,
        end_time: 660279,
        duration: 1679,
        text: "बोलते हैं तो लाइक उनसे एक एक लाइन का",
      },
      {
        start_time: 660279,
        end_time: 661920,
        duration: 1641,
        text: "टाइम कॉम्लेक्स टी बताइए और उनसे पूछिए कि",
      },
      {
        start_time: 661920,
        end_time: 664360,
        duration: 2440,
        text: "आप सही बोल रहे हैं लाइक ये बहुत ज्यादा",
      },
      {
        start_time: 664360,
        end_time: 666120,
        duration: 1760,
        text: "इंपॉर्टेंट है टू वे कम्युनिकेशन मेंटेन",
      },
      {
        start_time: 666000,
        end_time: 683000,
        duration: 17000,
        text: "Quantitative Aptitude",
      },
      {
        start_time: 666120,
        end_time: 668120,
        duration: 2000,
        text: "करना एंड व्हाट ड यू थिंक इज द इंपोर्टेंस",
      },
      {
        start_time: 668120,
        end_time: 670600,
        duration: 2480,
        text: "ऑफ क्वांट एप्टीट्यूड इन प्लेसमेंट्स एंड",
      },
      {
        start_time: 670600,
        end_time: 672480,
        duration: 1880,
        text: "इंटर्नशिप यसम इट इज वेरी इंपोर्टेंट फॉर",
      },
      {
        start_time: 672480,
        end_time: 674519,
        duration: 2039,
        text: "सम कंपनीज बिकॉज ऑनलाइन असेसमेंट में कुछ",
      },
      {
        start_time: 674519,
        end_time: 677600,
        duration: 3081,
        text: "कंपनीज गोल्डन सेक्स हो गई यह सब होती है",
      },
      {
        start_time: 677600,
        end_time: 679279,
        duration: 1679,
        text: "ये सब सीधा क्वांट प पूछती है क्वेश्चन",
      },
      {
        start_time: 679279,
        end_time: 681600,
        duration: 2321,
        text: "एप्टीट्यूड के क्वेश्चन रहेंगे 40 50 सो",
      },
      {
        start_time: 681600,
        end_time: 683720,
        duration: 2120,
        text: "या इट इज इंपोर्टेंट अच्छा यू गट",
      },
      {
        start_time: 683000,
        end_time: 717000,
        duration: 34000,
        text: "Challenges",
      },
      {
        start_time: 683720,
        end_time: 687440,
        duration: 3720,
        text: "सिलेक्टेड फॉर ग एंड कैन यू टेल अस इन द",
      },
      {
        start_time: 687440,
        end_time: 690760,
        duration: 3320,
        text: "एंटायस और द ओए प्रोसेस व्हाट वाज द मोस्ट",
      },
      {
        start_time: 690760,
        end_time: 693240,
        duration: 2480,
        text: "चैलेंजिंग पार्ट फॉर यू बेसिकली द मोस्ट",
      },
      {
        start_time: 693240,
        end_time: 695040,
        duration: 1800,
        text: "चैलेंजिंग पर्ट वाज क्लीयरिंग द ऑनलाइन",
      },
      {
        start_time: 695040,
        end_time: 697680,
        duration: 2640,
        text: "असेसमेंट बिकॉज लाइक वो फ्रेश सबसे पहली",
      },
      { start_time: 697680, end_time: 700000, duration: 2320, text: "कंपनी" },
      {
        start_time: 717000,
        end_time: 756000,
        duration: 39000,
        text: "Flipper Hackathon",
      },
      {
        start_time: 719519,
        end_time: 723120,
        duration: 3601,
        text: "गट ऑल इंडिया रैंक थ्री इन फ्लिपर कथन सो",
      },
      {
        start_time: 723120,
        end_time: 725480,
        duration: 2360,
        text: "कैन यू टेल अस मोर अबाउट दिस कथन यस मैम",
      },
      {
        start_time: 725480,
        end_time: 728839,
        duration: 3359,
        text: "बेसिकली इट वाज अ कथन कंडक्टेड बाय फ्लिपर",
      },
      {
        start_time: 728839,
        end_time: 732480,
        duration: 3641,
        text: "एआई च इज अ स्टार्टअप सो बेसिकली दे दे",
      },
      {
        start_time: 732480,
        end_time: 734240,
        duration: 1760,
        text: "टोल्ड अस टू बिल्ड अ सोशल मीडिया",
      },
      {
        start_time: 734240,
        end_time: 738720,
        duration: 4480,
        text: "एप्लीकेशन सो बेसिकली सोशल मीडिया वी",
      },
      {
        start_time: 742519,
        end_time: 744760,
        duration: 2241,
        text: "क्रिएटेडटेड",
      },
      {
        start_time: 744760,
        end_time: 748040,
        duration: 3280,
        text: "लाइक लाइकिंग द पोस्ट सेव द पोस्ट लाइक",
      },
      {
        start_time: 748040,
        end_time: 750320,
        duration: 2280,
        text: "दिस सो लाइक वी सरप्राइज्ड टू नो दैट व वी",
      },
      {
        start_time: 750320,
        end_time: 752240,
        duration: 1920,
        text: "रिसीवड ऑल इंडि 9थ फर्स्ट वन वाज आईआईटी",
      },
      {
        start_time: 752240,
        end_time: 754320,
        duration: 2080,
        text: "जोधपुर सेकंड वाज आईटी धनवाद एंड थर्ड वन",
      },
      {
        start_time: 754320,
        end_time: 756720,
        duration: 2400,
        text: "वाज आर सो वी र वेरी सरप्राइज्ड टू नो दैट",
      },
      {
        start_time: 756000,
        end_time: 792000,
        duration: 36000,
        text: "Mistakes made",
      },
      {
        start_time: 756720,
        end_time: 759600,
        duration: 2880,
        text: "अच्छा अ लेट्स सपोज वी सेंड यू बैक टू योर",
      },
      {
        start_time: 759600,
        end_time: 762079,
        duration: 2479,
        text: "फर्स्ट ईयर एंड यू हैड टू रिप्रेस फॉर योर",
      },
      {
        start_time: 762079,
        end_time: 765079,
        duration: 3000,
        text: "googlegroups.com",
      },
      {
        start_time: 779320,
        end_time: 782199,
        duration: 2879,
        text: "आई वुड फोकस मोर ऑन द सीजीपीए पार्ट हम",
      },
      {
        start_time: 782199,
        end_time: 784399,
        duration: 2200,
        text: "एंड आल्सो द डीएसए लाइक आई वुड प्रैक्टिस",
      },
      {
        start_time: 784399,
        end_time: 786839,
        duration: 2440,
        text: "मोर एंड मोर प्रॉब्लम्स एंड आल्सो आई वुड",
      },
      {
        start_time: 786839,
        end_time: 788800,
        duration: 1961,
        text: "लव टू इंगेज इन ओपन सोर्स कंट्रीब्यूशन",
      },
      {
        start_time: 788800,
        end_time: 790720,
        duration: 1920,
        text: "फ्रॉम द फर्स्ट ईयर इट सेल्फ सो इट क्रिएट",
      },
      {
        start_time: 790720,
        end_time: 792839,
        duration: 2119,
        text: "अ ग्रेट इंपैक्ट ऑन आरसी अ लेट्स सपोज",
      },
      {
        start_time: 792000,
        end_time: 876000,
        duration: 84000,
        text: "Advice for juniors",
      },
      { start_time: 792839, end_time: 795160, duration: 2321, text: "देयर इज" },
      {
        start_time: 795160,
        end_time: 797959,
        duration: 2799,
        text: "समबे इन देयर फर्स्ट ईयर एंड देर जस्ट",
      },
      {
        start_time: 797959,
        end_time: 800079,
        duration: 2120,
        text: "अबाउट टू स्टार्ट देयर कोडिंग जर्नी सो डू",
      },
      {
        start_time: 800079,
        end_time: 802279,
        duration: 2200,
        text: "यू हैव एनी एडवाइस फॉर देम या बेसिकली",
      },
      {
        start_time: 802279,
        end_time: 804839,
        duration: 2560,
        text: "डोंट ट्राई टू मग अप एवरीथिंग लाइक डीएस",
      },
      {
        start_time: 804839,
        end_time: 806880,
        duration: 2041,
        text: "इज नॉट अ वन मकिंग अप यू हैव टू जस्ट",
      },
      {
        start_time: 806880,
        end_time: 808560,
        duration: 1680,
        text: "अंडरस्टैंड सम कांसेप्ट एंड देन लाइक",
      },
      {
        start_time: 808560,
        end_time: 811120,
        duration: 2560,
        text: "अप्लाई इट बट डू नॉट मग अप एवरीथिंग लाइक",
      },
      {
        start_time: 811120,
        end_time: 813480,
        duration: 2360,
        text: "जूनियर्स दे दे फॉलो सम सीट एंड दे मग अप",
      },
      {
        start_time: 813480,
        end_time: 815279,
        duration: 1799,
        text: "ऑल द प्रॉब्लम्स दे डोंट ववर थिंक अबाउट द",
      },
      {
        start_time: 815279,
        end_time: 817720,
        duration: 2441,
        text: "कॉन्सेप्ट्स एंड एनीथिंग बट इन द इंटरव्यू",
      },
      {
        start_time: 817720,
        end_time: 821680,
        duration: 3960,
        text: "इन द टॉप पीवीसी इंटरव्यू बेसिकली लाइक",
      },
      {
        start_time: 834720,
        end_time: 837880,
        duration: 3160,
        text: "google2 डू यू हैव एनी एडवाइस फॉर देम सो",
      },
      {
        start_time: 837880,
        end_time: 841120,
        duration: 3240,
        text: "लाइक कंप्लीट डीएसए एंड लाइक या सो",
      },
      {
        start_time: 841120,
        end_time: 843000,
        duration: 1880,
        text: "प्रोजेक्ट्स वगैरह अच्छे से बनाने चाहिए",
      },
      {
        start_time: 843000,
        end_time: 845519,
        duration: 2519,
        text: "हम प्रोजेक्ट्स लाइक शड बी द रैंडम क्लोनस",
      },
      {
        start_time: 845519,
        end_time: 847600,
        duration: 2081,
        text: "ऑफ एनीथिंग यू शुड बिल्ड समथिंग इनोवेटिव",
      },
      {
        start_time: 847600,
        end_time: 849600,
        duration: 2000,
        text: "बिल्ड समथिंग न्यू आप सीखो का इससे क्लोन",
      },
      {
        start_time: 849600,
        end_time: 851279,
        duration: 1679,
        text: "बनाओ बट उसके बाद आप खुद से इंप्लीमेंट",
      },
      {
        start_time: 851279,
        end_time: 853639,
        duration: 2360,
        text: "करो और कुछ यूजफुल बनाओ हैथ में पाट लो",
      },
      {
        start_time: 853639,
        end_time: 855639,
        duration: 2000,
        text: "लाइक हैथ में फर्स्ट ईयर से ही पाट लेना",
      },
      {
        start_time: 855639,
        end_time: 857440,
        duration: 1801,
        text: "चाहिए जब आपको नहीं आता तब भी हैथ से पाट",
      },
      {
        start_time: 857440,
        end_time: 859279,
        duration: 1839,
        text: "लो कुछ सीखो धीरे-धीरे धीरे-धीरे करते",
      },
      {
        start_time: 859279,
        end_time: 861600,
        duration: 2321,
        text: "करते सीख जाएंगे एंड देन आल्सो कुछ कुछ ओ",
      },
      {
        start_time: 861600,
        end_time: 864920,
        duration: 3320,
        text: "ओपन सोर्स प्रोग्राम होते है जैसे",
      },
      {
        start_time: 869120,
        end_time: 872120,
        duration: 3000,
        text: "ओपन सोर्स सीखो धीरे-धीरे से इवेंचर लेवल",
      },
      {
        start_time: 872120,
        end_time: 873680,
        duration: 1560,
        text: "और जैसे ही रिज्यूमे अच्छे बन जाएगा आपको",
      },
      {
        start_time: 873680,
        end_time: 875320,
        duration: 1640,
        text: "खुद कॉन्फिडेंस आ जाएगा एंड देन प्रैक्टिस",
      },
      {
        start_time: 875320,
        end_time: 877880,
        duration: 2560,
        text: "इज मस्ट सो व्हाट ड यू थिंक वाज द वाओ",
      },
      {
        start_time: 876000,
        end_time: 933000,
        duration: 57000,
        text: "Wow factor",
      },
      {
        start_time: 877880,
        end_time: 880199,
        duration: 2319,
        text: "फैक्टर इन योर रिज्यूमे जो शॉर्टलिस्ट",
      },
      {
        start_time: 880199,
        end_time: 882480,
        duration: 2281,
        text: "कराने में जिसम सबसे ज्यादा हेल्प किया सो",
      },
      {
        start_time: 882480,
        end_time: 884720,
        duration: 2240,
        text: "बेसिकली मैम रिज्यूमे मेरे लाइक देयर इज अ",
      },
      {
        start_time: 884720,
        end_time: 886839,
        duration: 2119,
        text: "कॉमिनेशन ऑफ एवरीथिंग लाइक ऑल राउंड सो",
      },
      {
        start_time: 886839,
        end_time: 889720,
        duration: 2881,
        text: "देयर वाज अ हैक अथन देयर वाज डीएसए देयर",
      },
      {
        start_time: 889720,
        end_time: 891519,
        duration: 1799,
        text: "वाज कोडिंग प्रोफाइल्स ऑन कोड फोर्सेस लीड",
      },
      {
        start_time: 891519,
        end_time: 893639,
        duration: 2120,
        text: "कोड कोड शफ देयर वाज ओपन सोर्स",
      },
      {
        start_time: 893639,
        end_time: 895639,
        duration: 2000,
        text: "कंट्रीब्यूशन अक्रॉस अक्रस वेरियस",
      },
      {
        start_time: 895639,
        end_time: 898000,
        duration: 2361,
        text: "प्लेटफॉर्म्स एंड आल्सो आई हैड वन",
      },
      {
        start_time: 898000,
        end_time: 900079,
        duration: 2079,
        text: "एक्सपीरियंस अब ऑफ चिंग असिस्टेंट सो लाइक",
      },
      { start_time: 900079, end_time: 900959, duration: 880, text: "इट" },
      {
        start_time: 900959,
        end_time: 903560,
        duration: 2601,
        text: "क्रिएटेडटेड यू एवर थिंक अबाउट",
      },
      {
        start_time: 903560,
        end_time: 905560,
        duration: 2000,
        text: "पार्टिसिपेटिंग इन ओपन सोर्स प्रोग्राम्स",
      },
      {
        start_time: 905560,
        end_time: 907600,
        duration: 2040,
        text: "लाइक जी सक डिड यू अप्लाई फॉर देम स",
      },
      {
        start_time: 907600,
        end_time: 909880,
        duration: 2280,
        text: "बेसिकली सेकंड लाइक टिल द थर्ड ईयर आई",
      },
      {
        start_time: 909880,
        end_time: 911320,
        duration: 1440,
        text: "डिडेंट न अबाउट दैट प्रोग्राम दिस",
      },
      {
        start_time: 911320,
        end_time: 914079,
        duration: 2759,
        text: "प्रोग्राम लाइक जी सॉक एंड हम सो आफ्टर द",
      },
      {
        start_time: 914079,
        end_time: 916199,
        duration: 2120,
        text: "कंप्लीशन ऑफ लाइक फोर्थ सेमेस्टर आई हर्ड",
      },
      {
        start_time: 916199,
        end_time: 920000,
        duration: 3801,
        text: "अबाउट दैट जी सॉक इज समथिंग लाइक",
      },
      {
        start_time: 928959,
        end_time: 931120,
        duration: 2161,
        text: "नेक्स्ट ईयर आई विल लाइक इन 2025 आई विल",
      },
      {
        start_time: 931120,
        end_time: 933600,
        duration: 2480,
        text: "बी टारगेटिंग ग समर ऑफ कोल्ड ऑफ कोर्स ओके",
      },
      {
        start_time: 933000,
        end_time: 982000,
        duration: 49000,
        text: "Placement scenario",
      },
      {
        start_time: 933600,
        end_time: 936120,
        duration: 2520,
        text: "अच्छा ये बताओ अगर आपके कॉलेज के अंदर",
      },
      {
        start_time: 936120,
        end_time: 938759,
        duration: 2639,
        text: "देयर आर 100 स्टूडेंट्स हु आर सेटिंग फॉर",
      },
      {
        start_time: 938759,
        end_time: 941279,
        duration: 2520,
        text: "इंटर्नशिप इंटरव्यूज तो प्लेसमेंट सीजन के",
      },
      {
        start_time: 941279,
        end_time: 943360,
        duration: 2081,
        text: "अंदर 100 में से कितने स्टूडेंट्स आपको",
      },
      {
        start_time: 943360,
        end_time: 945319,
        duration: 1959,
        text: "लगता है जो सीरियसली टेक प्लेसमेंट्स की",
      },
      {
        start_time: 945319,
        end_time: 947160,
        duration: 1841,
        text: "तैयारी करते हैं टेक इंटर्नशिप की तैयारी",
      },
      {
        start_time: 947160,
        end_time: 949600,
        duration: 2440,
        text: "करते हैं बेसिकली सेकंड ईयर के बाद क्या",
      },
      {
        start_time: 949600,
        end_time: 951759,
        duration: 2159,
        text: "होता है कि लाइक जब इंटर्नशिप सीजन आता है",
      },
      {
        start_time: 951759,
        end_time: 953240,
        duration: 1481,
        text: "उस टाइम पे ज्यादा लोग प्रिपेयर नहीं होते",
      },
      {
        start_time: 953240,
        end_time: 955519,
        duration: 2279,
        text: "हैं इंटर्नशिप के लिए क्योंकि उन्होंने वो",
      },
      {
        start_time: 955519,
        end_time: 957360,
        duration: 1841,
        text: "कंपटीशन देखा नहीं हुआ रहता या उनको पता",
      },
      {
        start_time: 957360,
        end_time: 959680,
        duration: 2320,
        text: "नहीं रहता बट जैसे जैसे इंटर्नशिप लगते",
      },
      {
        start_time: 959680,
        end_time: 961360,
        duration: 1680,
        text: "जाता है लोगों का तो आपको खुद लगता है आप",
      },
      {
        start_time: 961360,
        end_time: 963519,
        duration: 2159,
        text: "खुद पीछे फील करोगे कि उसका लग गया मेरा",
      },
      {
        start_time: 963519,
        end_time: 964880,
        duration: 1361,
        text: "नहीं हम लोगों ने सेम जगह से स्टार्ट करा",
      },
      {
        start_time: 964880,
        end_time: 966600,
        duration: 1720,
        text: "था सेम ब्रांच थी तब भी उसका लग रहा है",
      },
      {
        start_time: 966600,
        end_time: 968279,
        duration: 1679,
        text: "मेरा नहीं मतलब उसने प्रैक्टिस करा तो",
      },
      {
        start_time: 968279,
        end_time: 969959,
        duration: 1680,
        text: "शुरू शुरू में तो कंपटीशन बहुत कम रगा",
      },
      {
        start_time: 969959,
        end_time: 971319,
        duration: 1360,
        text: "लेकिन धीरे-धीरे क्या होता है कि सब",
      },
      {
        start_time: 971319,
        end_time: 972920,
        duration: 1601,
        text: "प्रैक्टिस करने लग जाते हैं सब सब कोई",
      },
      {
        start_time: 972920,
        end_time: 974160,
        duration: 1240,
        text: "इंप्रूव सब कोई प्रोजेक्ट बना रहा है",
      },
      {
        start_time: 974160,
        end_time: 975680,
        duration: 1520,
        text: "अच्छे-अच्छे ऐसा होता है कि सब लोग अपना",
      },
      {
        start_time: 975680,
        end_time: 977600,
        duration: 1920,
        text: "इक्वली कैपेबल हो जाते हैं उसके लिए तो",
      },
      {
        start_time: 977600,
        end_time: 979399,
        duration: 1799,
        text: "लाइक प्लेसमेंट के टाइम बहुत ज्यादा बढ़",
      },
      {
        start_time: 979399,
        end_time: 982160,
        duration: 2761,
        text: "जाता है वो हम लोग का कंपटीशन सो ठीक है",
      },
      {
        start_time: 982000,
        end_time: 1032000,
        duration: 50000,
        text: "Role of college",
      },
      {
        start_time: 982160,
        end_time: 984560,
        duration: 2400,
        text: "डू यू थिंक इफ यू केम फ्रॉम अ टियर थ्री",
      },
      {
        start_time: 984560,
        end_time: 986560,
        duration: 2000,
        text: "कॉलेज देन यू वुड हैव गोटन द सेम",
      },
      {
        start_time: 986560,
        end_time: 988720,
        duration: 2160,
        text: "अपॉर्चुनिटी और यू वुड हैव गोटन सिलेक्टेड",
      },
      { start_time: 988720, end_time: 991040, duration: 2320, text: "फॉर फॉर" },
      {
        start_time: 991639,
        end_time: 995160,
        duration: 3521,
        text: "google3 यर से होता तो सीवी रेजू मेंे तो",
      },
      {
        start_time: 995160,
        end_time: 998000,
        duration: 2840,
        text: "कॉलेज आई नो कॉलेज हैज सम इंपोर्टेंट ह बट",
      },
      {
        start_time: 998000,
        end_time: 999920,
        duration: 1920,
        text: "एज माय रिज्यूमे गॉट सिलेक्टेड इन ऑफ",
      },
      {
        start_time: 999920,
        end_time: 1002319,
        duration: 2399,
        text: "कैंपस आल्सो सो बेसिकली वो जो 10 डेज का",
      },
      {
        start_time: 1002319,
        end_time: 1004160,
        duration: 1841,
        text: "था ऑनलाइन असेसमेंट से राउंड वन वो वाली",
      },
      {
        start_time: 1004160,
        end_time: 1006959,
        duration: 2799,
        text: "टेंशन कम हो जाती थोड़ी तो लाइक आई डोंट",
      },
      {
        start_time: 1006959,
        end_time: 1009240,
        duration: 2281,
        text: "नो व्हाट द एग्जैक्ट आउटकम वुड बी बट लाइक",
      },
      {
        start_time: 1009240,
        end_time: 1011319,
        duration: 2079,
        text: "जो अगर आपके पास स्किल्स है और आपके",
      },
      {
        start_time: 1011319,
        end_time: 1013199,
        duration: 1880,
        text: "अच्छे-अच्छे प्रोजेक्ट्स बनाए हैं डीए से",
      },
      {
        start_time: 1013199,
        end_time: 1015519,
        duration: 2320,
        text: "प्रैक्टिस करी है तो लाइक कोई कॉलेज से हो",
      },
      {
        start_time: 1015519,
        end_time: 1017480,
        duration: 1961,
        text: "टियर वन टियर टू वो मैटर नहीं करता वो",
      },
      {
        start_time: 1017480,
        end_time: 1019480,
        duration: 2000,
        text: "मैटर तभी करता है अगर आप आपको थोड़ा कम",
      },
      {
        start_time: 1019480,
        end_time: 1021720,
        duration: 2240,
        text: "आता है और लाइक आपके जितने स्टूडेंट्स उसे",
      },
      {
        start_time: 1021720,
        end_time: 1023399,
        duration: 1679,
        text: "ज्यादा कंपनीज आ रही है तब तो आपका",
      },
      {
        start_time: 1023399,
        end_time: 1025480,
        duration: 2081,
        text: "सिलेक्शन हो जाएगा अगर आप टॉप यर्स हो",
      },
      {
        start_time: 1025480,
        end_time: 1027558,
        duration: 2078,
        text: "नीचे हो तो आप अगर अच्छे से पिल्ड",
      },
      {
        start_time: 1027559,
        end_time: 1028839,
        duration: 1280,
        text: "प्रोजेक्ट आपके प्रैक्टिस अच्छे है आपके",
      },
      {
        start_time: 1028839,
        end_time: 1031199,
        duration: 2360,
        text: "कोडिंग प्रोफाइल्स अच्छे हैं देन नो वन",
      },
      {
        start_time: 1031199,
        end_time: 1033319,
        duration: 2120,
        text: "कैन स्टॉप यू लाइक ठीक है इज देयर एनीथिंग",
      },
      { start_time: 1032000, end_time: 1075000, duration: 43000, text: "Tips" },
      {
        start_time: 1033319,
        end_time: 1035480,
        duration: 2161,
        text: "एल्स दैट यू वुड लाइक टू शेयर अबाउट योर",
      },
      {
        start_time: 1035480,
        end_time: 1037720,
        duration: 2240,
        text: "जर्नी सो बेसिकली लाइक कभी भी अंडर",
      },
      {
        start_time: 1037720,
        end_time: 1040038,
        duration: 2318,
        text: "कॉन्फिडेंट फील नहीं करना चाहिए बेसिकली",
      },
      {
        start_time: 1040039,
        end_time: 1041918,
        duration: 1879,
        text: "आई वेस्टेड लाइक फोर टू फाइव डेज जस्ट",
      },
      {
        start_time: 1041919,
        end_time: 1043640,
        duration: 1721,
        text: "थिंकिंग अबाउट की लाइक ऑनलाइन असेसमेंट",
      },
      {
        start_time: 1043640,
        end_time: 1045160,
        duration: 1520,
        text: "में नहीं हुआ तो क्या होगा माइक्रोसॉफ्ट",
      },
      {
        start_time: 1045160,
        end_time: 1047120,
        duration: 1960,
        text: "से रिजेक्शन आ गई तो अब क्या होगा अब कुछ",
      },
      {
        start_time: 1047120,
        end_time: 1049240,
        duration: 2120,
        text: "अब कुछ नहीं कर सकते अब वापस से ये तो",
      },
      {
        start_time: 1049240,
        end_time: 1050960,
        duration: 1720,
        text: "लाइक कंटिन्यूटी ब्रेक हो जाती है एक बार",
      },
      {
        start_time: 1050960,
        end_time: 1054000,
        duration: 3040,
        text: "अगर आप कंटीन्यूअस हो तो आपका जो सीखने का",
      },
      {
        start_time: 1054000,
        end_time: 1055640,
        duration: 1640,
        text: "कैपेबिलिटी वो बढ़ जाता है आपको जल्दी",
      },
      {
        start_time: 1055640,
        end_time: 1057160,
        duration: 1520,
        text: "जल्दी समझ चीजें समझ आने लगती है आपको",
      },
      {
        start_time: 1057160,
        end_time: 1059160,
        duration: 2000,
        text: "जल्दी-जल्दी याद होने लगती है चीजें तो",
      },
      {
        start_time: 1059160,
        end_time: 1060799,
        duration: 1639,
        text: "लाइक बट अगर एक बार कंटिन्यूटी ब्रेक हो",
      },
      {
        start_time: 1060799,
        end_time: 1062440,
        duration: 1641,
        text: "जाता है तो आपको वापस से रीस्टार्ट करने",
      },
      {
        start_time: 1062440,
        end_time: 1064360,
        duration: 1920,
        text: "में कुछ टाइम लगता है तो टाइम वेस्ट होता",
      },
      {
        start_time: 1064360,
        end_time: 1066520,
        duration: 2160,
        text: "है तो उसके बाद वो फिर आपका वो हैपर करता",
      },
      {
        start_time: 1066520,
        end_time: 1068200,
        duration: 1680,
        text: "है तो लाइक आपको जो है कभी भी अगर आपको",
      },
      {
        start_time: 1068200,
        end_time: 1069840,
        duration: 1640,
        text: "फेलियर मिले तो आपको सर पकड़ के नहीं",
      },
      {
        start_time: 1069840,
        end_time: 1071679,
        duration: 1839,
        text: "बैठना आपको वही मेहनत करते रहनी है कभी ना",
      },
      {
        start_time: 1071679,
        end_time: 1073400,
        duration: 1721,
        text: "कभी अगर आपने मेहनत करी होगी सही से तो",
      },
      {
        start_time: 1073400,
        end_time: 1075200,
        duration: 1800,
        text: "किसी ना किसी रास्ते से मिली जाएगी जो",
      },
      {
        start_time: 1075000,
        end_time: 1113000,
        duration: 38000,
        text: "Stipend details",
      },
      {
        start_time: 1075200,
        end_time: 1078200,
        duration: 3000,
        text: "मिलना होगा ओके आर देयर एनी प्लांस टू डू",
      },
      {
        start_time: 1078200,
        end_time: 1079919,
        duration: 1719,
        text: "समथिंग विद योर फर्स्ट इंटर्नशिप",
      },
      {
        start_time: 1079919,
        end_time: 1082960,
        duration: 3041,
        text: "स्टेटमेंट जब आएगा बेसिकली लाइक मम्मी को",
      },
      {
        start_time: 1082960,
        end_time: 1085080,
        duration: 2120,
        text: "घुमाना है बोली थी म ममी मम्मी ने कहा था",
      },
      {
        start_time: 1085080,
        end_time: 1086799,
        duration: 1719,
        text: "कि लाइक जब अच्छा इंडिया में बहुत सारे",
      },
      {
        start_time: 1086799,
        end_time: 1088760,
        duration: 1961,
        text: "जगह घूमना है उनको तो लाइक कुछ-कुछ जगह",
      },
      {
        start_time: 1088760,
        end_time: 1090600,
        duration: 1840,
        text: "इंटर्नशिप टाइ बेंड से है ठीक है तो आपकी",
      },
      {
        start_time: 1090600,
        end_time: 1092880,
        duration: 2280,
        text: "बैंगलोर के अंदर इंटर्नशिप है कहां पे है",
      },
      {
        start_time: 1092880,
        end_time: 1095880,
        duration: 3000,
        text: "सस एम बैंगलोर बैंगलोर तो कब से कब तक है",
      },
      {
        start_time: 1095880,
        end_time: 1098200,
        duration: 2320,
        text: "आपकी इंटर्नशिप टेंटेटिव डेट इज अराउंड 4",
      },
      {
        start_time: 1098200,
        end_time: 1101120,
        duration: 2920,
        text: "जून 4 जून एंड व्हाट इज द इंटर्नशिप",
      },
      {
        start_time: 1101120,
        end_time: 1104919,
        duration: 3799,
        text: "स्टाइप फॉर google2 सो बेसिकली द कोर्स",
      },
      {
        start_time: 1104919,
        end_time: 1107520,
        duration: 2601,
        text: "टाइप एंड लाइक द विदाउट रीलोकेशन इज",
      },
      {
        start_time: 1107520,
        end_time: 1111480,
        duration: 3960,
        text: "125000 ह एंड विथ लाइक रिय लोकेशन इट वड",
      },
      {
        start_time: 1111480,
        end_time: 1114960,
        duration: 3480,
        text: "बी अराउंड 180000 तो मेंटरशिप सेशंस वगैरह",
      },
      {
        start_time: 1113000,
        end_time: 1243000,
        duration: 130000,
        text: "Mentorship sessions",
      },
      {
        start_time: 1114960,
        end_time: 1117320,
        duration: 2360,
        text: "अटेंड किए थे आपने बैच के अंदर यस माइन",
      },
      {
        start_time: 1117320,
        end_time: 1120799,
        duration: 3479,
        text: "बैच वाज बेलमन फड बैच बेलमन फड थ्री कैम",
      },
      {
        start_time: 1120799,
        end_time: 1123640,
        duration: 2841,
        text: "तो व्हाट वाज द एक्सपीरियंस कौन सा सेशन",
      },
      {
        start_time: 1123640,
        end_time: 1125799,
        duration: 2159,
        text: "आपको लगता है सबसे ज्यादा उसने हेल्प किया",
      },
      {
        start_time: 1125799,
        end_time: 1127600,
        duration: 1801,
        text: "बेसिकली रेजू में बल्डिंग सेक्शन क्योंकि",
      },
      {
        start_time: 1127600,
        end_time: 1129320,
        duration: 1720,
        text: "उस सेशन से पहले मैं रेजू में पूरा खाली",
      },
      {
        start_time: 1129320,
        end_time: 1132120,
        duration: 2800,
        text: "था बस नाम था कॉलेज के नाम थे बस",
      },
      {
        start_time: 1132120,
        end_time: 1133440,
        duration: 1320,
        text: "प्रोजेक्ट वगैरह का मेरे को आइडिया",
      },
      {
        start_time: 1133440,
        end_time: 1135000,
        duration: 1560,
        text: "क्योंकि मैं डीए से पढ़ रहा था तो उसका",
      },
      {
        start_time: 1135000,
        end_time: 1136720,
        duration: 1720,
        text: "रेजूम बिल्डिंग सेशन में जब आपने रिज्यूमे",
      },
      {
        start_time: 1136720,
        end_time: 1138520,
        duration: 1800,
        text: "दिखाया था डेमो रिज्यूमे बहुत सरा तब उसके",
      },
      {
        start_time: 1138520,
        end_time: 1140200,
        duration: 1680,
        text: "बाद मेरा रेजूम भरना स्टार्ट नहीं तो ऐसे",
      },
      {
        start_time: 1140200,
        end_time: 1141919,
        duration: 1719,
        text: "चार से पांच लाइन में रेजूम खत्म मैं 10थ",
      },
      {
        start_time: 1141919,
        end_time: 1143480,
        duration: 1561,
        text: "के मार्कशीट अचीवमेंट्स में मैं एथ क्लास",
      },
      {
        start_time: 1143480,
        end_time: 1145039,
        duration: 1559,
        text: "का अचीवमेंट लिख रहा था 10थ क्लास का उसका",
      },
      {
        start_time: 1145039,
        end_time: 1146720,
        duration: 1681,
        text: "धीरे-धीरे कंटेस्ट देना स्टार्ट करा",
      },
      {
        start_time: 1146720,
        end_time: 1148280,
        duration: 1560,
        text: "अचीवमेंट्स बिल्ड हुए फिर हैक अथन में",
      },
      {
        start_time: 1148280,
        end_time: 1150640,
        duration: 2360,
        text: "पार्ट लेना स्टार्ट करा सो बेसिकली दे द",
      },
      {
        start_time: 1150640,
        end_time: 1152520,
        duration: 1880,
        text: "मेंटरशिप सीजन लाइक रेजूम रिज्यूमे",
      },
      {
        start_time: 1152520,
        end_time: 1154840,
        duration: 2320,
        text: "बिल्डिंग वाज बेस्ट वन उससे बहुत कुछ",
      },
      {
        start_time: 1154840,
        end_time: 1157919,
        duration: 3079,
        text: "सीखने को मिला था ओके शिवम ठीक है तो हम",
      },
      {
        start_time: 1157919,
        end_time: 1160679,
        duration: 2760,
        text: "रैप अप करते हैं इंटरव्यू तो आई होप कि",
      },
      {
        start_time: 1160679,
        end_time: 1163400,
        duration: 2721,
        text: "शिवम की जर्नी से हमें कई सारी चीजें कई",
      },
      {
        start_time: 1163400,
        end_time: 1165760,
        duration: 2360,
        text: "सारी इंस्पिरेशन भी साथ के साथ सीखने को",
      },
      {
        start_time: 1165760,
        end_time: 1168840,
        duration: 3080,
        text: "मिली होगी शिवम के पूरे प्रोफाइल के अंदर",
      },
      {
        start_time: 1168840,
        end_time: 1171080,
        duration: 2240,
        text: "द बेस्ट थिंग दैट आई लाइक्ड अबाउट इट वाज",
      },
      {
        start_time: 1171080,
        end_time: 1173360,
        duration: 2280,
        text: "कि रिज्यूमे के अंदर देयर इज समथिंग अबाउट",
      },
      {
        start_time: 1173360,
        end_time: 1176240,
        duration: 2880,
        text: "डीएसए एंड इनफैक्ट समथिंग नहीं देयर आर अ",
      },
      {
        start_time: 1176240,
        end_time: 1178039,
        duration: 1799,
        text: "लॉट ऑफ डिफरेंट लिंक्स ऑफ डिफरेंट कोडिंग",
      },
      {
        start_time: 1178039,
        end_time: 1179679,
        duration: 1640,
        text: "प्रोफाइल्स कि वो डीएससी की रेगुलरली",
      },
      {
        start_time: 1179679,
        end_time: 1181720,
        duration: 2041,
        text: "प्रैक्टिस करते हैं उसके साथ में देयर आर",
      },
      {
        start_time: 1181720,
        end_time: 1183799,
        duration: 2079,
        text: "आल्सो फुल स्टैक प्रोजेक्ट्स फुल स्टैक के",
      },
      {
        start_time: 1183799,
        end_time: 1185360,
        duration: 1561,
        text: "साथ में उन्होंने एक मशीन लर्निंग",
      },
      {
        start_time: 1185360,
        end_time: 1187159,
        duration: 1799,
        text: "प्रोजेक्ट के ऊपर भी काम किया है एंड साथ",
      },
      {
        start_time: 1187159,
        end_time: 1188720,
        duration: 1561,
        text: "के साथ में देयर इज आल्सो ओपन सोर्स",
      },
      {
        start_time: 1188720,
        end_time: 1191320,
        duration: 2600,
        text: "कंट्रीब्यूशन एक्सपीरियंस तो एक जो ओवरऑल",
      },
      {
        start_time: 1191320,
        end_time: 1193440,
        duration: 2120,
        text: "अच्छी प्रोफाइल होती है टेक ओरिएंटेड",
      },
      {
        start_time: 1193440,
        end_time: 1195640,
        duration: 2200,
        text: "प्रोफाइल होती है अलोंग विद गुड एकेडमिक",
      },
      {
        start_time: 1195640,
        end_time: 1198039,
        duration: 2399,
        text: "स्कोर वो उन्होंने मेंटेन करने की कोशिश",
      },
      {
        start_time: 1198039,
        end_time: 1200360,
        duration: 2321,
        text: "की है एंड आई वुड से दैट दिस इज वन ऑफ अर",
      },
      {
        start_time: 1200360,
        end_time: 1201919,
        duration: 1559,
        text: "आइडियल जो एक",
      },
      {
        start_time: 1201919,
        end_time: 1204919,
        duration: 3000,
        text: "रेजूमेक्स फाइल के लिए वो आइडियल रिज्यूमे",
      },
      {
        start_time: 1204919,
        end_time: 1206840,
        duration: 1921,
        text: "के बहुत ही ज्यादा पास है या इनफैक्ट इट",
      },
      {
        start_time: 1206840,
        end_time: 1208840,
        duration: 2000,
        text: "इज एन आइडियल रिज्यूमे व्हिच आई रियली",
      },
      {
        start_time: 1208840,
        end_time: 1210640,
        duration: 1800,
        text: "लाइक्ड अबाउट हिज प्रोफाइल तो कई सारी",
      },
      {
        start_time: 1210640,
        end_time: 1212400,
        duration: 1760,
        text: "चीजें हैं जो उनकी जर्नी से एक्स्ट्रा",
      },
      {
        start_time: 1212400,
        end_time: 1214720,
        duration: 2320,
        text: "एडिशनल हमें सीखने को मिली डेफिनेटली इफ",
      },
      {
        start_time: 1214720,
        end_time: 1216880,
        duration: 2160,
        text: "यू आर सबब जो डीएसए डेवलपमेंट एंड और",
      },
      {
        start_time: 1216880,
        end_time: 1218799,
        duration: 1919,
        text: "एक्स्ट्रा चीजें जाकर सीख रहा है इट",
      },
      {
        start_time: 1218799,
        end_time: 1220440,
        duration: 1641,
        text: "रिक्वायर्स अ लॉट ऑफ हार्ड वर्क इट",
      },
      {
        start_time: 1220440,
        end_time: 1222880,
        duration: 2440,
        text: "रिक्वायर्स अ लॉट ऑफ डेडिकेशन जो शिवम की",
      },
      {
        start_time: 1222880,
        end_time: 1224760,
        duration: 1880,
        text: "जर्नी से हमें डेफिनेटली देखने को मिल रहा",
      },
      {
        start_time: 1224760,
        end_time: 1227200,
        duration: 2440,
        text: "है तो आई होप कि वो चीजें हम अपनी जर्नी",
      },
      {
        start_time: 1227200,
        end_time: 1229400,
        duration: 2200,
        text: "के अंदर भी जाकर रिप्लिकेट करें तो आज के",
      },
      {
        start_time: 1229400,
        end_time: 1230720,
        duration: 1320,
        text: "लिए इतना ही मिलते हैं नेक्स्ट इंटरव्यू",
      },
      {
        start_time: 1230720,
        end_time: 1233240,
        duration: 2520,
        text: "के अंदर टिल देन कीप लर्निंग एंड कीप",
      },
      {
        start_time: 1233240,
        end_time: 1235600,
        duration: 2360,
        text: "एक्सप्लो",
      },
      {
        start_time: 1235600,
        end_time: 1239200,
        duration: 3600,
        text: "स्थ डीप फ्ला च फम टर्फ आई नेव स्विच साइ",
      },
      {
        start_time: 1239200,
        end_time: 1242080,
        duration: 2880,
        text: "लाक इवन वन आई डा आ राड फ द स्क्वा ला टाय",
      },
      {
        start_time: 1242080,
        end_time: 1244760,
        duration: 2680,
        text: "इ हर्स",
      },
    ],
    hashtags: [],
    tags: [
      "C++",
      "C++ coding",
      "C++ full course",
      "C++ placement course",
      "how to code",
      "programming",
      "college placement course",
      "C++ language",
      "java",
      "java language",
      "java full course",
      "java placement",
      "java code",
      "java coding",
    ],
    next_recommended_videos: [
      {
        url: "https://www.youtube.com/channel/UCBwmMxybNva6P_5VmxjzwqA",
        title: "Apna College, channel",
        thumbnail:
          "https://yt3.ggpht.com/FEcjRtez5od8UowDo6tTt9WlE-MrIFEmcwPMTORmK9Swk6KCklOmA3xfIG9WuLWfNYfNThQE=s400-c-k-c0x00ffffff-no-rj",
        startMs: 1237800,
        endMs: 1242800,
        style: "CHANNEL",
      },
      {
        url: "https://www.youtube.com/watch?v=u3y1MqX4egE&list=PLfqMhTWNBTe2oN3YJHWS-ouKybo8Gp1YO",
        title:
          "37 videos, Apna College RESULTS & Placements (Interview lessons of our students)",
        thumbnail: "https://i.ytimg.com/vi/u3y1MqX4egE/maxresdefault.jpg",
        startMs: 1237800,
        endMs: 1242800,
        style: "PLAYLIST",
      },
    ],
    recommended_videos: [
      {
        url: "https://www.youtube.com/watch?v=vscu3i1_yxs",
        title:
          "How this student got Amazon via Off-Campus Hackathon | from Tier 2/3 | Interview lessons with Ma'am",
        thumbnail:
          "https://i.ytimg.com/vi/vscu3i1_yxs/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLArZtG7-RnqQMGs7-eF1sqUfxgNoQ",
      },
      {
        url: "https://www.youtube.com/watch?v=XvSJ0KvFGDY",
        title:
          "How she cracked Google Summer of Code in First year in 1 month! 🚀 | GSoC Guide",
        thumbnail:
          "https://i.ytimg.com/vi/XvSJ0KvFGDY/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLCLU1mv0i3tOsKld3I3UR4koCC0mg",
      },
      {
        url: "https://www.youtube.com/watch?v=TmFHuAxqF5k",
        title:
          "How he cracked Off-Campus Goldman Sachs? Interview lessons with Shradha Ma'am",
        thumbnail:
          "https://i.ytimg.com/vi/TmFHuAxqF5k/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLCt88qV_LybbikbL3plCLsRRswSDg",
      },
      {
        url: "https://www.youtube.com/watch?v=nBJbB2q3jR0",
        title: "Tier 3 to Google 40LPA | 2024 Batch Pass Out",
        thumbnail:
          "https://i.ytimg.com/vi/nBJbB2q3jR0/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLDCXWGj7AILAY7P1_8rtlFSl569ng",
      },
      {
        url: "https://www.youtube.com/watch?v=mstrQbmKrFk",
        title:
          "How this student cracked Internship at Salesforce ? Interview lessons with Shradha Khapra Ma'am",
        thumbnail:
          "https://i.ytimg.com/vi/mstrQbmKrFk/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLDwf7uXFUqXUP579fCnbHpGYN6nUQ",
      },
      {
        url: "https://www.youtube.com/watch?v=zNECfyqzXTw",
        title: "How to Get Over AI Guilt (And How to Break It)",
        thumbnail:
          "https://i9.ytimg.com/vi/zNECfyqzXTw/hqdefault_custom_3.jpg?sqp=CIiG5MUG-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLBW_wyBCiwXqhpJcFBsdX1636ZbCA",
      },
      {
        url: "https://www.youtube.com/watch?v=64N1nNk0WuQ",
        title:
          "Tier 3 to Off Campus Google & Microsoft | How did this student crack both Internships?",
        thumbnail:
          "https://i.ytimg.com/vi/64N1nNk0WuQ/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLCkM7n4M33Gr-8ckF9luzLr0JTdmg",
      },
      {
        url: "https://www.youtube.com/watch?v=Lp-F-NLc41g&pp=0gcJCcYJAYcqIYzv",
        title:
          "How this student cracked DE Shaw & Co ? Interview lessons with Shradha Khapra Ma'am",
        thumbnail:
          "https://i.ytimg.com/vi/Lp-F-NLc41g/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLCh4DBbOHTZnNdItwxUBNGWg1bLWg",
      },
      {
        url: "https://www.youtube.com/watch?v=iCZnZXYceAU",
        title:
          "How she cracked Google and Meta London | 1.5cr+ Salar | london Jobs, Salary, Living Expenses more! 🚀",
        thumbnail:
          "https://i.ytimg.com/vi/iCZnZXYceAU/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLD9BmixJ6D1GJaBrXOeudcfz6W2tw",
      },
      {
        url: "https://www.youtube.com/watch?v=IOt3kQP93SY",
        title:
          "How this student got double Internship offers at Microsoft & JP Morgan - Interview lessons",
        thumbnail:
          "https://i.ytimg.com/vi/IOt3kQP93SY/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLDqe8Lfl92-QwIhlosbuRrQzSc4xA",
      },
      {
        url: "https://www.youtube.com/watch?v=hr-y4suNq6c",
        title:
          "3rd year student cracks Samsung Internship & PPO | Interview Lessons with Shradha Ma'am",
        thumbnail:
          "https://i.ytimg.com/vi/hr-y4suNq6c/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLBSEyToWN4Z0PvjKP9_-XXXNlw1Ew",
      },
      {
        url: "https://www.youtube.com/watch?v=yjd-LXVRqDU&pp=0gcJCcYJAYcqIYzv",
        title:
          "Shradha Didi BRUTALLY Honest for 40 Minutes Straight! Aman Dhattarwal, Wedding, Coding, Apna College",
        thumbnail:
          "https://i.ytimg.com/vi/yjd-LXVRqDU/hqdefault.jpg?sqp=-oaymwEnCNACELwBSFryq4qpAxkIARUAAIhCGAHYAQHiAQoIGBACGAY4AUAB&rs=AOn4CLBCIdry-v9XwZemK6ZIsABNoNdy1Q",
      },
    ],
    transcript_language: [
      { language: "Hindi (auto-generated)", auto_translate: true },
    ],
    chapters: [
      {
        title: "Introduction",
        time_stamp: null,
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_1933.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAR887w3z5iDGryO0ONlOw2lihH0Q",
      },
      {
        title: "Google Hiring process",
        time_stamp: "71000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_71433.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBudjJhItkkjh_wUB35qxYGDzh85Q",
      },
      {
        title: "Parents' reaction",
        time_stamp: "186000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_196066.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLDczub-luO2wbl4VIeAnxtrdgTeaw",
      },
      {
        title: "Preparation",
        time_stamp: "211000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_233066.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLDoTr9sI8C5yuIJLzEFWb4B2s7aKg",
      },
      {
        title: "Rejections",
        time_stamp: "352000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_361766.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBapVdG2nTCik7pB0_z7PT8OJddBg",
      },
      {
        title: "DSA or Development",
        time_stamp: "422000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_422866.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAUTijD00LeLdxW3U6GNzpkll5Zag",
      },
      {
        title: "CGPA",
        time_stamp: "449000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_472933.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLC3Pi_EPFDVCR1H8epapjAYdGxGag",
      },
      {
        title: "Time Management",
        time_stamp: "480000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_494133.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLC4PW4Tcn3XSDi1cLlCEfhktRV2hA",
      },
      {
        title: "CS Fundamentals",
        time_stamp: "560000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_578033.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLD7wW_NEf1DZ8YVGMlB9_8eMBg8Wg",
      },
      {
        title: "Projects",
        time_stamp: "579000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_603966.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBX8KpWlLNoF1P00p3C3Qe3vc5Yug",
      },
      {
        title: "Communication skills",
        time_stamp: "627000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_652633.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLDc9pTK7ViIVOH0VXzQiv3nLiYg-g",
      },
      {
        title: "Quantitative Aptitude",
        time_stamp: "666000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_682066.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLC00SsIH2E6MNkAWgDZ1fRXyrEuBw",
      },
      {
        title: "Challenges",
        time_stamp: "683000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_696033.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBW7ywGH_63fxLuaS0FJ3hojWUI_g",
      },
      {
        title: "Flipper Hackathon",
        time_stamp: "717000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_726033.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBQzEX1JLJJw-IUbdbXqKOapGopBQ",
      },
      {
        title: "Mistakes made",
        time_stamp: "756000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_777400.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCHGPLAzXUnYbZVXE4c_dtZ5wYhOg",
      },
      {
        title: "Advice for juniors",
        time_stamp: "792000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_821000.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLDFRswe6A71deH-LW5Yl0ZAxyRZ-w",
      },
      {
        title: "Wow factor",
        time_stamp: "876000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_901266.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAn3DzlW-4OzehwnuQQ-Pq53i88ew",
      },
      {
        title: "Placement scenario",
        time_stamp: "933000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_948933.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLDH1_BT-4Xp5Zi8kO3M0qNGwYpEDw",
      },
      {
        title: "Role of college",
        time_stamp: "982000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_1005933.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLACJzXSbyM-J7dt5CISP7JrxYIp6A",
      },
      {
        title: "Tips",
        time_stamp: "1032000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_1036933.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCUOoIvFHxTCHQHFF8X606bIaaDUw",
      },
      {
        title: "Stipend details",
        time_stamp: "1075000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_1081833.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLDDhpUd3o_k8L70aLN78hp0tv8v1A",
      },
      {
        title: "Mentorship sessions",
        time_stamp: "1113000",
        image:
          "https://i.ytimg.com/vi/iSfrVNowJ9Y/hqdefault_1120233.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCIE3MvpEzjSO9G9-9BAC88hoo5vw",
      },
    ],
    transcription_language: null,
    is_age_restricted: false,
    timestamp: "2025-09-04T03:10:21.412Z",
    input: {
      url: "https://www.youtube.com/watch?v=iSfrVNowJ9Y&t=756s",
      country: "",
      transcription_language: "",
    },
  },
  {
    url: "https://www.youtube.com/watch?v=kEtGm75uBes&t=808s",
    title: "Build a Full Stack RAG System with React, Langchain & Node.js",
    youtuber: "@notjustdev",
    youtuber_md5: "22b02a77e45db13832ec986839e835cf",
    video_url:
      "https://rr11---sn-42u-i5olr.googlevideo.com/videoplayback?expire=1756977002&ei=CgO5aObuIIeJ1d8P_Mu1wQc&ip=42.118.51.52&id=o-AIoU3SCb3i2q5jHKnQkSDT0YCvJ4mxp2guMTXm63umru&itag=18&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1756955402%2C&mh=N1&mm=31%2C26&mn=sn-42u-i5olr%2Csn-oguesnds&ms=au%2Conr&mv=m&mvi=11&pl=24&rms=au%2Cau&initcwndbps=2885000&bui=AY1jyLMmkEjDQadHdtlQdNTZ3G5xrieo1LYEu5f2-cNApsKu54GW0PuaxeZNfK6A6ipc87o82O0yTjyF&spc=l3OVKW_jU5jsZo55hWfDZwWbQBozQjW1hJhFEi03wWI-5Q6qCKHZ3xliDvRFXKrJGrctWWqWXlKeaNYb&vprv=1&svpuc=1&mime=video%2Fmp4&ns=QE5A1rgwQ_PXjJyg0wvibrAQ&rqh=1&gir=yes&clen=325443515&ratebypass=yes&dur=12712.414&lmt=1742624782154020&mt=1756954887&fvip=1&fexp=51355912%2C51552689%2C51565115%2C51565682%2C51580968&c=WEB&sefc=1&txp=7209224&n=lw2KY7n8nGzR4j-TdW&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AJfQdSswRAIgRt2CDEq-IRCOXJqBObDYrleV4KlBLkVZULe-ig-82IMCIGNEbDxq7EZ8lPbGXizHBoHkEJHvisSDTuzVAkDjRiy2&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=APaTxxMwRgIhAL0oXa1BCceZUjzpLNhT69A7A2WdCm2XBH8WQHA3N1WXAiEAwJI7XSXDJRPjLzX-gGxEbCPdqoAcz0peBnF7TTtqM9s%3D",
    video_length: 12712,
    likes: 286,
    views: 8689,
    date_posted: "2025-03-22T06:26:40.000Z",
    description:
      "✨ Want to scrape data like a pro? Get $15 in free credits here: https://brdta.com/notjustdev\n✨ Try Genezio today to simplify scaling and deploying your API. Sign up for free here: https://bit.ly/41LCDzh\n\n📚 Get the step-by-step guide: https://assets.notjust.dev/youtube-chat\n\nWant to chat with any YouTube video using AI? 🤖 In this tutorial, you’ll learn how to build a full-stack Retrieval-Augmented Generation (RAG) system that lets you ask questions about YouTube content and get accurate, AI-generated answers. You’ll learn how to scrape video transcripts using BrightData, process them with Langchain, and connect to powerful LLMs like OpenAI and Anthropic—all deployed with Genezio. 🤖 🚀\n\n❗️ React Native Mastery is the ONLY course you need to Master mobile development with React Native & Expo 🚀\nEnroll here: https://www.notjust.dev/react-native-mastery\n\n📝 This video includes a lot of tools and technologies, providing an excellent opportunity to learn:\n👉 How to scrape YouTube video transcripts using BrightData\n👉 How to build a NodeJS and Express backend for a RAG system\n👉 How to process YouTube transcripts and generate embeddings with Langchain\n👉 How to query OpenAI and Anthropic models for context-aware answers\n👉 How to store and retrieve embeddings from a PostgreSQL vector database\n👉 How to create a React web app to chat with YouTube videos in real time\n👉 How to deploy a full-stack AI app seamlessly using Genezio\n.. and MORE!\n\n💡 Have an idea for a future tutorial? Share it on our Idea Board: https://github.com/orgs/notJust-dev/discussions\n\n💬 Join the notJust Development gang and let's build together:\nTwitter: https://twitter.com/VadimNotJustDev\nInstagram: https://www.instagram.com/VadimNotJustDev\nFacebook: https://www.facebook.com/notjustdev\nLinkedIn: https://www.linkedin.com/in/vadimsavin\nDiscord: https://discord.gg/VpURUN2\n\n#notjustdev #langchain #react",
    num_comments: 9,
    subscribers: 133000,
    video_id: "kEtGm75uBes",
    channel_url: "https://www.youtube.com/@notjustdev",
    preview_image: "https://i.ytimg.com/vi/kEtGm75uBes/hqdefault.jpg",
    shortcode: "kEtGm75uBes",
    verified: false,
    handle_name: "notJust․dev",
    avatar_img_channel:
      "https://yt3.ggpht.com/VdNMLGk6QNH3gRusX4H3drUDqTb0NxbQp9NLU7tOVY1U_Qy0ah8TK1NviXBwYyikhl89Zzg3=s48-c-k-c0x00ffffff-no-rj",
    is_sponsored: false,
    related_videos: [
      "https://www.youtube.com/watch?v=jfKfPfyJRdk",
      "https://www.youtube.com/watch?v=_1P0Uqk50Ps",
      "https://www.youtube.com/watch?v=sVcwVQRHIc8",
      "https://www.youtube.com/watch?v=7VAs22LC7WE",
      "https://www.youtube.com/watch?v=T-D1OfcDW1M",
      "https://www.youtube.com/watch?v=Jfb_tnngFFI",
      "https://www.youtube.com/watch?v=G26wQhm23Gw",
      "https://www.youtube.com/watch?v=wm5gMKuwSYk",
      "https://www.youtube.com/watch?v=h5HE0Lu1--U",
      "https://www.youtube.com/watch?v=TA7vQYbr7kQ",
      "https://www.youtube.com/watch?v=3UdCyXoeDEQ",
      "https://www.youtube.com/watch?v=4xDzrJKXOOY",
      "https://www.youtube.com/watch?v=l_TR-sJNDtI",
      "https://www.youtube.com/watch?v=GUgUU4MicbE",
      "https://www.youtube.com/watch?v=JljlsOJmlCA",
      "https://www.youtube.com/watch?v=E4l91XKQSgw",
      "https://www.youtube.com/watch?v=dZbVOQhf2Xk",
      "https://www.youtube.com/watch?v=iYX-3hCVmK8",
      "https://www.youtube.com/watch?v=p0FERNkpyHE",
      "https://www.youtube.com/watch?v=YLagvzoWCL0",
    ],
    license: null,
    viewport_frames: "640x360 / -",
    current_optimal_res: "640x360@30 / 640x360@30",
    codecs: "avc1.42001E, mp4a.40.2 / mp4a.40.2",
    color: "bt709",
    quality: "hd1080",
    quality_label: "1080p60",
    post_type: "post",
    youtuber_id: "UCYSa_YLoJokZAwHhlwJntIA",
    transcript:
      "what's up Noz developers welcome back to another live tutorial today we're going to have another AI agent tutorial and our AI tutorial that is going to help and teach you how to build an AI agent from scratch using langra as with an aspect of rag today we're going to learn more about all of these terms what we mean and I'm so excited about everything that is happening right now in the AI world like what's possible to build what powerful tools we have available at our fingertips and how easy it is to actually Implement them after we understand how they work and the goal of these tutorials is to help you make sense of everything that is going on out there and to give this ideas of what is possible so make sure to follow along this tutorial by the end and I promise you that you're going to know more about AI agents and how to build them know more about rag system and how to build them and by then you're actually going to have an system an AI agent with an interface with backend deployed and accessible by anyone that can uh answer questions about YouTube videos so the project that we're going to build today is the AI chat with YouTube videos and what do I mean by that let me give you a little context that one of the most powerful applications of llm nowadays is to build this sophisticated um question answering Bots that have knowledge about a very particular area because we most probably all have already experienced uh general purpose llms uh such as the chbt let's say from open AI that is exceptionally good at understanding human language and generating text answering questions or continuing uh text generation however the general purpose AI models they do not know very specific information so while it's a very good generalist when it comes to specializing in a very specific topic it's not very good it doesn't have most up-to-date information out of a box um so for example if we ask a question about a documentation or about like a document a law or something like that it can get a little bit lost however if we as developers give the right information to the llm the llm can use that information to generate an accurate and upto-date anware which makes this system so powerful this system of injecting uh context into llm is called Rag and that's what we are going to use today and in our project our system is going to get information is going to get a YouTube video we're going to do some magic there to scrape that transcript of that YouTube video so we know what's being talked in that YouTube video and then our AI chat is going to be able to answer questions very specific to that YouTube video such as what is the main topic of a podcast how much money did for example he invest in Beast games like very specific of what being discussed there and what's going to happen is our AI system is going to go ahead and get the part that is most relevant to this question and based on that part of the interview is going to generate an answer or for example it can take an eight hour tutorial from our Channel and you can ask questions like what tools didim use there he's going to look for the video uh transcript is going to find the information there and is going to give you an answer or uh maybe you can use it like I get an error did I miss anything and again it's going to use the brain power of an nlm with the context of a video to give you the right answer and this is actually how I came up to this idea I was thinking about building an agent that can answer questions based on our videos for example you might be searching for um a tool and you want to know in which video we implemented you can use this agent to ask and it's going to go and knowing all the information about our videos is going to answer where that is happening there are a lot of applications of this kind of powerful Bots uh from uh analyzing public data like on YouTube chatting with long TXS with long loss uh with blog posts with podcasts and much much much more so if we talked about rag let me quickly discuss more about that so what is rag rag is stands for retrieval augmented generation and in simple terms generation means the part of an llm that generates text you give it some text usually let's say a question and how it works it generates what is the most probable next part of a text that comes after that usually an answer for example retrieval augmented means that it first Reves context that it needs and it augments it improves the generation part using the information retrieved so in our case with YouTube it first will retrieve information about the video about the transcript and then using that information is going to uh generate the answer rag has usually two parts in it and the first part is in the pipeline is a indexing pipeline this usually happens offline um not when the user requests something but beforehand and that usually happens in following steps first we have to load the data this can be documents this can be HTML Json URLs PDFs we need to get the data that we uh want to work with after we get the data we have to split it into manageable chunks because uh if we have like thousands of uh characters into a document it's going to be harder to um there is a limit to how much context we can give it an llm and it would be better to split it and then when we have a question only get the chunks the pieces of data that are relevant to that question after we split the documents into small chunks what we do is we embed embeddings um in simple words means we take take a bunch of text we put it through a system and in the end we get an vector and a vector is basically an array of numbers array of numbers that represents a vector uh in a very multi multi-dimensional space to think about a vector very simple one would be a two-dimensional Vector that is an arrow pointing into One Direction and having this vector later we can compare it with other vectors to know how similar they are that's basically how similarity search in this system works we take a text we generate a vector which is a numerical representation of that text after that we take a in The Next Step we're going to see how we find the similarity so after we generate this embeddings and again it's important to understand the concept of it it's not very important to understand how this is happening because it's a matter of calling an AI model that is built for generating this embeddings so think about it as a function we give it text it gives us back an array of numbers which represents a vector having this Vector we need to store it somewhere and we need to store it in a database that can support querying based on Vector similarity basically saying give me documents that are very similar to this document based on these numbers after we have a store data there we are ready for the next step the next step is retrieve and generate this usually happens when the user interacts with our system when it asks a question so the user asks a normal question in a very human readable language it can have mistakes and so on but llm is smart enough to embed it and based on the embedding of a question which is the same process as here we are finding the documents that are related to that question that are very similar to that question then we see which of these documents are the most relevant document to this question most relevant pieces of do parts of our text relevant to the question we retrieve it from the database and we put it as context in the prompt then this prompt we send it to a normal llm such as open AI um models and then we get an answer back but the answer has the context so it's very specific to the data that we gave let me know if that is um that is clear um but we're going to understand it and I'm going to explain it again and again as we Implement all of these steps let's talk a little bit about the architecture of application that we're going to build today so first we're going to have a chat interface we're going to build that with react the chat interface uh is going to interact with our AI agent which is going to be um in in our backend we're going to build our back end with no GS I'm a JavaScript developer so I must rather I I feel more comfortable building with JavaScript but if you're python developer langra is also available for Python and I know a lot of people prefer python in this in this situations over JavaScript but I think it's perfectly fine with GS as well so the backend is in our case is going to be an API that is going to contain multiple Parts one of them is going to be our AI agent and the AI agent in this case like is a simple abstraction on top of an llm the large language model provided by either anthropic or open Ai and these uh providers like entropic and open AI they are very uh interchangeable so use the one that you uh feel best um in this situation we're going to have a simple chat chatting application such as CH that we can ask a question it can answer us back nothing more than that it not doesn't yet have context about YouTube videos but we need our chat interface to know and to talk about the YouTube videos that we want to talk about for that we're going to have to index our YouTube videos to build this rag system so if we look at the uh flow we have to load the data first how we're going to load the data well the data we're going to get it from YouTube uh and we're going to do that using the web scraper provided by bright data if you don't know about bright data this is the best uh tool to scrape and get access to public data uh on the internet uh they run on a very powerful proxy Network and are implementing a lot of features of unblocking the web for you like solving capturas or rotating IPS and basically you can think about like okay I need data I don't know and I don't want to care about how to get it just going to go on bright data and there you're most probably will find an API pre-build for scraping this data for you if not you can use the scraping browser and implement this yourself and in the world of AI with bright data you can give basically access to any data on the web to your AI because the power of our AI models is depends on the power of the data that we provide or give it access to so with combining bright data with AI models I think this is a very good combination and Powerful one to that unlocks you so much possibilities so we're going to use Bri data to scrape YouTube videos specifically the transcriptions the captions and then we're going to need to uh if we looking back into this one we need to split and embed it for that we're going to use an l M such as open AI that is uh and specifically an embedding model not a generation model embedding means we give you text you give me back a vector after we have a vector we need to store it somewhere we will store it in a vector database so it should be a database that can do these queries on vectors like similarity queries and pogress has a PG vector that is an extension uh allowing to do this kind of uh similarity search on postgress data so we're going to do that as well we're going to create a database we're going to store the data there and that is the first step done for the next step when the user ask a question we need to retrieve this data and generate it so that's where our AI agent we're going to have to give it access to our vector database to retrieve the information that it needs to generate the answer so finally we're going to deploy everything to jio both the front end and our back end for the AI agent and the API and if you don't know about genesio this is the best way to deploy web applications they support a lot of Frameworks both front end and backend and that's what I like about it because I can use jio to deploy both the front end and the back end of our application and we're going to have it everything up and running very very fast and I would like to say thank you to janio and to Bri data for making this video possible very excited uh if you are also excited I think we can get started let's roll the [Music] intro all all right so I want to mention that the step-by-step guide as usually is in the link in the description below so if you go ahead on the under the video where is it uh and open it here you're going to see the guide so go ahead open it up uh go to site leave your name email and you're going to receive access to the uh to the guide to the notion guide so let me copy the URL as well to open it up here with you and here you're going to have like more step by step and I left here a little bit more resources where you can learn more um so we're going to use a lot the blog from linkchain because we're going to use l chain to build our AI agent and we have here a two-part block log however not everything from here is super applicable to our case so I would recommend you read here to know more or follow what we are going to do and we're going to do everything step by step for that let's go ahead and open a terminal and get started I cannot wait to to get started I'm going to zoom in here let's navigate to our project YouTube 0320 like this and let's create a directory let's call it chat with YouTube uh let's call it AI chat with YouTube let's go ahead and open this folder in our editor of choice I'm going to open it with cursor you can open it with Visual Studio code uh or any other editor of your choice in my case using cursor is going to speed up a little bit the the development process because nowadays I feel more and more often using um AI Co code generation to to speed up my my process today I'm going to use it only in specific cases where it's going to save us time but when it comes to learning the AI agent we're going to try to write everything ourself um so being in this folder in this project we're going to create uh first one folder called server and this folder I open up terminal and did mkd server where you can simply do new folder here and let's go ahead and do CD server in our terminal and initialize our noj project I'm going to do that with npm in need- Y and in our server we have package.json while we are here maybe we can even do here type module um to be able to use like normal import statements and for now that's it in a second we're going to install dependencies here but for now let's go ahead and simply create the agent. GS here because the first step in our case is is going to build our agent here let's just do console log hello world in our package.json H maybe I don't need it I will just go ahead in the terminal inside being inside the server I'm going to do node agent. GS and if I do that we're going to see Hello World so that's how we're going going to start initially testing it we're going to Simply execute this agent file later we're going to put it inside um behind an API uh so we can fetch and integrate it from the client side from the front end perfect let's go ahead and um there is also a blog post which I did two weeks ago around building AI agents with lra that one is really a step by step uh implementation of how to build this kind of agents and I will open it up because there I showed you how to get started with that what I want to do is I want to First install these dependencies I will install Leng chain L graph length chain Das core and L chain entropic because I'm going to use entropic for the llm for the completion model and then also Zod we're going to see why we need Zod in a moment so let's copy this command from here I'm by the way also going to add it uh here in the steps actually it's you can go in the steps and take it from there and being inside the server here let's go ahead and install L chain langra where is it langra and Zod now we need to create thatv file where we're going to write the um how is it called we need the environment variable with entropic key to get the entropic key go ahead on entopic anthropic doc go ahead and uh do build with CLA do learn more start building and in your uh after signing in in your account you're going to be able to generate an API Key by the way entropic is not the only way to do that you can easily integrate with open AI as well however I tried with open Ai and I didn't really like the performance like how it behaved there so I don't know maybe I didn't try the right model from open AI but we're still going to use open AI in the next step for something else so in the embedding what we need to do in the EnV we need to provide here the API key actually let me go ahead and uh entropic console. entropic to generate a new key that we can easily remove later uh I need the de how is it called console entropic do don't remember the the account that I used okay here it is so what I'm going to do is I'm going to go into the API keys I'm going to click read key and I'm going to see say here chat with YouTube Key let's do add I'm going to copy it I'm going to also delete it later don't worry and here let's put it into an an Tropic come on un Tropic API key and let's put the API key here let's also go ahead and add a new file here dogit ignore with without dasg ignore and add the. EnV file V because we don't want to commit the uh private key of our models to our git while we're ve we can also put the node modules perfect now that we have entropic key here uh we are going going to have access to it through process.env but what we're going to do is we are going to use it to create the the entropic chat client so in our agent what we need is first we need to do to import chat entropic from L chain entropic then we need to say hey our llm is going to be a new chat entropic where you can also specify here the model that you want to use for example 3.5 like this or maybe you can even do latest or now we can do 3.7 if we want you can also provide here the API key but if you don't provide B injected as entropic aior key with this name it's going to automatically take it from there so we're going to see like if it it if it has it next we will create a react agent react not from react GS that we use on to build uh interfaces uh it's from uh it stands for uh reason and act so it's going to be an agent that can reason and use tools for us uh we just give it like what's possible and it's going to decide how to to uh execute everything to provide the the answer we're going to see in a second like what I mean by that to create one we're going to import uh create agent from L chair uh L chain core let me see where from length chain slash length graph slash prebuild if I'm not mistaken now we can say that hey our agent is going to be this agent and an agent needs first of all the llm the llm which is going to be how is going to complete stuff but it also needs let's set of tools in our casee we do not have tools yet so we're going to give an empty array in this case this agent is really dump it's a simple llm but later we can add tools so it can do more stuff let's go ahead and uh test it out by saying Hey I want to do an invocation of this agent with was the capital of the Moon that's very interesting question let's see the result and to test it out I'm going to to Simply uh execute this agent. GS if I do node agent. GS we're going to see an error seeing that uh What uh the create agent right at Lang chain d l graph D prebuild isn't it from there oh create react agent I forgot that so yeah create react agent so in this case it's not input but it's what uh I think it should be messages right messages let's see how to invoke it properly what is the capital of a moon I don't know it says uh it has a red warning here but I think it's going to work maybe we'll see we'll see ah no I don't think it will so it's actually should be we need to give it an array of messages and one message will be will have role user and content what is the capital of a moon very similar to how um a chat interface will look like you have an array of messages the last one is from the user and the result is going to contain the list of messages and what we are interested in is actually the the last message but let's see if it will work like this if I do node agent what we see is the API key entropic API key not found that's because even though we set it up here in the EnV when we executed node agent. GS uh we should also provide the EnV file equal EnV so we need to load the environments from that file before executing the file the agent and just like that we have the answer we have messages we have a human message and we have an AI message this is ID content the moon doesn't have a capital city because it doesn't have permanent and so on so cool that's basically uh our list of messages so to get the last one usually what we do is we say results at minus one to take the last message from that array and then we look at the message do content and if I execute it again we should see just the answer no oh it's results. messages dot content so results. messages there's the array we take the last one and we display the content if I run the file we see a simple answer like this perfect let me know what do you think we should do next do we connect this simple llm because at the moment this is a simple llm like like we called it agent and we used like an agent but this doesn't make it a true agent why because an agent needs a set of tools and the agent is going to receive an input for example a prompt and it's going to first create a plan for itself by calling different tools by govering different data it's going to create a plan and it will do that over and over again until the llm is happy and said said like okay this is answer this is a good answer and it's going to answer it so for that to happen it needs list access to tools we're going to do that later and one of the tools is going to be to retrieve information about like videos but for now our agent is a simple llm we can give it a question it will give us an answer using the cloud 3.7 from anthropic nothing too fancy now the question is do you want us to build first the rug system here in a server environment and test it with calling this function or do you want us to build the interface first and connect it with our server so we can interact from the from the client side from the interface what first maybe maybe maybe I know but let's see what do you think uh and by the way hello everyone who is joining us live how are you doing guys I'm using L chain in production want to try yam index I haven't tried yam index yet uh what's the benefit of uh of it over L chain or what's the difference I'm also learning a lot like about this AI lately and I'm so excited what what the possibilities are hello um Joshy hello roio hello blender music how are you guys uh Hey man you're doing a great job just finished your react na8 hour videos what a Content thank you so much thank you I appreciate it is it possible to persist data between each agent tool calls yes it's possible and uh between uh agent tool calls yes yes and we are going to do it we're going to persist the the history of the of the chat so that you you can ask ask followup questions okay let me see um so I think we go rag first I also believe so because rag is the topic the the Hye part of this video and I want to explain it well because client side um is just the interface so first we're going to interact it with this like this later we're going to put it into an API and connect it to the client side so we're going to do both of them but first let's go ahead and build the the rag system oky dokie so again um uh if you go into the where is it well first of all uh in our presentation if we look at the steps the first one is going to be loading again our plan for loading the data was to use bright data to scrape the transcript of YouTube videos from YouTube let's go ahead and manually do that together with PR data and uh get some very specific data of how this is going to look in the next step for that uh and by the way this part of the video of scraping is sponsoring by Bri data so thank you very much our partners from Bri data for um enabling us to build such amazing applications and to unlock any data on the web so go to follow the link in the description below or go to bata.com com uh and if you go to your dashboard we're going to use their web data U where is it the web scrapers so go ahead open web scrapers and if we go into the web scraper Library these are pre-built webs scrapers that give you access to data in a similar way as you would fetch an API but actually that data is uh scraped in real time from the websites in a very secure and scalable way so you can you can scale your project without any limitations there are a lot of sources data sources like LinkedIn Instagram Facebook uh and so on uh even like Ecommerce like from Amazon and so on what I'm interested in is YouTube data so so if I search Here YouTube we're going to see that there are actually eight scrapers for YouTube and the one that I need is uh video posts by URL so let's go ahead and click on video posts by URL there is also a link in our guide scraper API let's do next in the documentation of this API we say that we just give a YouTube url we can give also a country where to look from and in as a response we are going to get the data about that YouTube such as the title the video URL likes views date posted description and so on but what's cool is that we're also going to um scrape the transcript the transcript both in raw format like the whole transcript like this and also if you scroll down below the transcript formatted with a duration similar to how it appears on the video so we're going to use this transcript from Bri data in our system to provide information to our rag system to be able to answer questions about that video giving information to the llm like what's happening in that video let's go ahead in the API request Builder and see how we would interact with Bri data to give us this data for example we're going to give inputs and we can do batch request so we can do multiple inputs per request and here it's a simple URL of a YouTube video for example uh let me do two YouTube videos that I'm interested in I'm going to do one short one and one a bit bigger let's do where is it I'm going to do a short video to be able to to see like what's happening and later I'm going to also do a bigger one give me one second or maybe we should actually do my video like some some some of my videos yeah let's do that for example h which one I'm going to do a live stream that one is going to be like huge but maybe yeah we're we're going to test it with a huge video as well let me just grab for example this one so I'm going to give a 7 Minutes video from Formula 1 about today's Sprint col ification I haven't watched it yet because I'm preparing but I'm very interested I'm going to go into the Bri data API where it is here and the first input is going to be this one and the second one is going to be a longer video like a 4our videos from our Channel about building with react native and reanimated let's copy this URL as well send it as the second one and what do we see here are some configurations to include errors if they happen we can provide a URL where to send notifications and I'm going to exclude this delivery to external storages if I do that and copy this Cur command and go into a terminal and open it up like this and paste the command here also make sure to add the API token here from your account like go ahead and first create an API token and added here and it's going to automatically be added to the command what we're going to see back is a snapshot ID a snapshot ID basically means that a job for scraping the data started usually scraping data takes some time it's not instant because it has to actually simulate opening a browser and navigating to that page and interacting like a user would do so if we look in the logs here we see that a new job with this snapshot that we just copy from the console log we see it here what we can do is we can click download to Json and we're going to have a Json file let me take the Json file and bring it in our server as come on I'm going to bring it here and I'm going to call it data let's call itgs to easier import it I'm going to click save to format it and I'm going to add at the top export default so what we see inde the is an array with two objects the first one and then the second one we see that this is the title of the video Sprint qualifying we see this is the transcript and then we see if we scroll down through this transcript formatted we're going going to see the second video as well oh come on the second video is this one and the transcript is what'sapp not just developers so now that we have this data later we're going to automate how we uh start and how we get this data for now let's just import it from data.js let's import it in our agent GS and say hey import data from data GS and let's say video one equal to data at position zero or video yeah let's do video one because this is an array we're going to look at the first video Perfect here is the data The Next Step that we have to do is we loaded the data now we have to split it let me uh splitting we can do that in a very ourself by simply looking at the transcript of that video and splitting it into chunks of 1,000 characters however L chain provides some pre-build Splitters that are a little bit more sophisticated that is improving how this splitting Works to not lose some context one of these Splitters is called re recursive character text Splitter from length chain text is it at L chain isn't it like this uh like this and probably I need to install it right npm install yes let's install length chain SL text splitters so here we're going to do split the video into chunks for that we're going to have to define a splitter using new recursive character splitter and provide here some options as we can see the default ones that are recommended here for me is chunk size and chunk overlap so what does it mean chunk size means how large should the chunks of data be here we say it should be 1,000 characters and chck overlap is going to Simply uh repeat the last 200 characters from this Chunk in the next one as well in this way if there is important context between these splits we're not going to lose it so even vaa is going to lead to a little bit more data because it repeats 200 characters at the beginning at end it's going to allow to give enough context and not lose it now um splitter like this at yeah uh is going to work oh wait splitter by calling split uh not text we can do split text as well yeah I think we can do split text but we should actually work a better way would be to work with documents um so we're going to call split documents for that we need to have a list of documents let's call them docs I'm going to Define them a little bit here to the top saying that the docs is going to be an array an array where we create one of these documents with our video one let's say that the document needs page content and the page content is what is inside that document inside that document we're going to use the video one. transcript which if we look into the data video one is this object and the transcript is this long text so this is going to be the page content the new document that document should be imported from L chain core documents now if we take the documents and split the documents here we have chunks let's see what are these chunks console.log chunks if I open it up and run the do node agent we're going to see what entropic key not found yeah because we need to do withv file so what we see here is that this chunks is an array with bunch of texts the first 1,000 characters then the next one and these all are documents documents documents documents if we look at the last part I'm going to even copy it and search for it we're going to see that it's both here and both here because the text overlaps and that works with v end as well if I'm going to copy it it's going to be both here and both here because the last part might be important information for this chunk but it also can be important information for for this chunk now we see that these uh documents also have this metadata this is a great place to write additional data about those documents so if I look into where we Define this document here we can def find the metadata here as well and one of the important metadata Parts here is what video is this content transcripts about because later we're going to have a lot of videos so we need to know like what where is it coming from we can call it video ID and say that the video ID is coming from video one. uh video ID because if we look into the data there is a video ID property here now if I will execute this one again we're going to see that in metadata we have video ID later we can also filter only the documents that are related to this video perfect so the splitting Parts is done the next step is embedding and embedding if we look into the length chain here um this is what L graph I'm going to find this one uh as you can see for the chat model basically the model that will generate text we can use these kind of available models uh grop open Ai entropic and so on and actually more but for the embedding we need to use a model that is specific for embeddings uh as I see entropic doesn't have an embedding model so that's why it's not here for that we can use open AI you can see that open AI embeddings you're going to see that that maybe on their site or the documentation is that they have this kind of models where you give as we input some text and it get back the embedding as an array of numbers the vector of that text so let's go ahead and say that we are going to use um open AI as our embedding model so let's go ahead and first install length chain - open AI in our application let's do make sure you are inside the server and install the open Ai and what we're going to need to do is we're going to import the first we need the open AI key inside ourv go ahead sign up for open AI get to a key and I'm going to get it here here let me do it like this and I added it to the EnV now we are ready to use open AI what we need is to import open AI embeddings in our agent open AI embeddings from L chain open AI after splitting what we are going to do let's do here embed chunks to embed chunks we need the embeddings using the new create or how is it open Ai embeddings and you can also specify the model here I'm pretty sure is like uh default one if you don't specify but know that you can specify what exact model we're going to use the embedding free large that is going to produce a specific like the model uh produces a specific amount of um the size of a vector so a large model not mistaken should be around I don't know 2,000 or something like that um dimensions of that Vector so the more Dimensions the more nuances it can detect in the text but at the same time it's more data to store larger it's more consuming okay so the thing is that now that we have this model that can generate embeddings we need a store somewhere to store that embedding that data with embeddings what we can do if we look in the documentation we need to pick a vector store we need a storage solution that can store these vectors not only they can store it but they can optimally query based on similarity I'm going to start with memory because this is going to be the easiest one it simply stores them in memory and to get started that's totally fine for us let's go ahead and import memory Vector store from Vector store memory at the top um and let's create the vector store where we have our embeddings so this is the vector store new memory Vector store and we send this embedding model finally finally what we need to do give me one second is to um Let me let me think like how to to introduce this one slowly okay so what we need to do is say hey await Vector store add documents and we're going to add the chunks that we generated here as simple as that um how to visualize it that's another question because yeah let's try right now like vector store let's try to Simply run our project with no DMV file we see a problem package Json reader cannot find L chain input imported I think uh we also need to install length chain like this without ad npmi length chain okay perfect let's now try to invoke the agent again and we don't see any errors that means that everything went fine uh which chunks should be should have been embedded and wrote to the database but we do not have like we do not see it like how can we visualize what's happening there well that's because we have simply done the first step of indexing loading the data splitting generating embeddings and storing the data the next part is the retrieving and generating let's go ahead and see how we can retrieve documents from our database that are similar to a question to do that let's go ahead and say here uh retrieve the most relevant chunks so what we are going to do is we're going to say a docs equal a wait Vector store we're going to work with this Vector store we're going to do a similarity search a similarity search uh because we index the table the the data from qualifying let's do what season is this Sprint in I'm going to ask send a question relative similar to the context of a video and I'm going to do a similarity search meaning that I'm going to find the chunks that are more similar to this question so let's see what is going to be the answer uh dogs we already have it right so retrieved docs let's do it like this and we say give me five docs if I run the agent again what we're going to see is the documents where at the top is the most most similar one I was expecting to see also the actual similarity because here how do I prove you that it's working what if I something from the end [Music] what was the finish time of Norris uh and I'm going to select one and before that I'm going to console log the chunks and here I'm going to console log this one but I'm also going to have like so that we see let's go ahead and try to run it again initially the documents are in chronological order from the beginning uh the first one is personal best through the sector and so one and at the end we do a similarity search for for the question what is the Norris end time and we see that here it's the document that is most related to the the the finish time of Norris so we can use this text to try to answer that question by move putting it through an llm uh again this is the similarity search uh let me see if I can actually get query filter call backs yeah it doesn't give us the exact like uh similarity value but that's good it at least does the similarity search so what can we do here now that we can having a query a question if we can find similar part similar transcripts from the video we can use them put them through uh the llm here in the agent so that it's going to use it to create the answer for example if my my question here is going to be what was the finished time of Norris it's not going to be able to to give me a proper result uh answer because this llm the agent does not yet have access to our Vector database or not provide the information I have so let's go ahead and build a tool that can use the vector store to retrieve the right information building a tool is also greatly documented and explained in our previous tutorial build and deploy your first AI agent with langra um yeah this is the tool so what we need to do is import this tool at the top let's import the tool and we are going to create it maybe here retrieval tool const retrieve tool is equal to Tool and we create it like this we're going to have an async and it should return something a tool has two two parameters the first one is the actual function that is going to run the second one is going to be some metadata about the to Tool let's call give it a name retrieve and we need to also give it a description description is very important because that's how the llm will know what is this tool supposed to do and when should it be used uh here retrieve most relevant uh relevant chunks of text from the transcript of a YouTube video something like that it's also important to provide here a schema a schema we are going to Define it with Zod so let's go at the top and import Z from Zod and Zod is a tool that can create help us create schemas of how object should look like and a tool needs a schema so that the llm knows what inputs what data to send there let's say that the schema is going to be an object and there will be a query and the query is going to be a string this query now that we added it here is going to be accessible through the tool execution function so we can have query and here we can say hey console console oh come on console.log retrieve dogs for the query console log query I'm not going to do a similarity search yet let's just return an empty string noris was first finishing in uh 33 seconds which is impossible but it's a way for us to test if this tool was invoked or not now if we take this tool and we give it to our agent inside the tools here the agent will know that hey I have a tool that has this description it can retrieve the most relevant chunks of text from the video transcript it will say that it's a question that might benefit from this information it's going to look at the schema and it's going to create a query and it's going to call this tool then is going to get back result and we'll analyze and see what to do next let's go ahead and see what actually is happening now I'm going to maybe comment out the logs that we did before and I'm going to invoke our agent that was bad so what do we see based on the transcript information I found noris finished in 33 seconds and was first place that's exactly what we kind of said like it's not the right information but where is it our question to our agent was what was the finish time of Norris you see this is what we are asking then LM analyze this question and is invoking the retrieve tool and in the retrieve tool we are doing here console log query the query is already different because the llm was smart enough to change it in a way to get the data that it needs so it simply changed it to noris finished time that's what an agent that's how an agent improves a rag system because the question is can you build an rag system without an agent invance is totally yes you can build a normal um uh flow AI flow for an Rec system without this agent inside it's simply doing it step by step in a sequence first get data when generate embeddings then get similarities then create the prompt and then send it to the llm a lot of things can be done manually and in sequence but having an llm here we see the first benefit is that the question that we ask is going to actually be transformed to something that is going to make a lot more sense for the AI to get the data and we see that we faked some data here so in the retrieval tool we just said no resource first and finish in 33 seconds and then having this information llm generated the final answer that we see here in their response perfect but let's go ahead and having this query let's do this retrieval of docs because we have a query we have a vector store we can use the query inside a similarity search we can search how many chunks are do you think would be Rel let's do three chunks maybe it's going to to be in three different places at the same time the llm can call this over and over again for to get all the response so F3 or maybe F5 probably is going to be enough so now that we retrieve the docks um let's put the them in a Ser alized dogs meaning let's merge them together and what I'm going to do is I'm going to do retrieve dock so for every doc let's return I don't know content doc. page content do Doc Page content and at the end I'm going to put up dashn to say that it's the end or maybe I'll simply do let's let's simplify it so I'm going to map for the documents I'm going to leave an array of Simply the content and I'm going to do a DOT join with a dashn basically what I'm doing here is I'm taking five or three docs that we get and put them in one single text and I can take the serialized docs and return it here uh to back to the llm now if I'm going to go ahead and execute the same query again it's supposed to base its answer from the transcript that we actually fetched so this is the query that our tool received and we see based on the information retrieve from the video transcript L is finish in six position in what appears to be a Sprint qualifying session the transcript mentions Hamilton versus upb cler Russell Norris in six we listening the order of drivers so you see it generated an answer based on the transcript so that's in a way our whole rag AI agent complete uh if we look at this we started with indexing first and now we have this retrieval and generation having a question from a user we provide a tool that can retrieve relevant information from transcripts from our Vector database and then using an llm like entropic we are generating the answer here perfect now let me go ahead um and initialize a git so you're going to have access because this is the base but we are just getting started guys let's do get add git commit uh basic AI agent with rag um what's happening let me check the the live chat if you have any questions feel free to to ask them I'm going to stop from time to time to answer them I'm already building a project like this amazing I had not started to do the video file pipeline yet so this is perfect this is a video file uh we are not working with video files we're working with transcripts of the videos Sprint but you said spring not sure when oh it uses transcript that's how my project currently works yeah perfect what is rag rag as I was explaining earlier is so we have an llm an llm is great at generating text that's how it answers questions you give it some text which can be a question and it tries to predict what should be the next part of a text meaning an answer it's very good at understanding language and at predicting what comes next and it's very good at general information but it's not very good at very specific information that either my not be public or it can be information that is super up to date like what is today's we in AI llm will not have that information so what we are doing is we are giving AI access to a data source that we can uh index on the similarity based on a search term for example you have a documentation website and you want to build a chatbot that users can write how to initialize a new project the chatbot will first look through all the the documentation pages and will find the documentation pages that are more relevant to the question how to initialize a project it might find two to three very relevant documentations it's going to use the information from V it's going to put it through the llm back saying hey this is what user is asking this is what documentations we have provide an answer to that question so this part of injecting this data retrieving the data is the what makes it a rag system and allows it to be powerful in order to know like more data more relevant data that you that you might need for specific use cases so llm we access to additional data have you figure out how to prompt cash how to prompt cash with transcripts in this setup what do you mean by that prompt prompt C cash let me know okay so we have our agent that where is it at current is doing a lot of stuff it's loading data from from our dam data there it's splitting it it's uh adding it to a vector database by embedding so a lot of things are happening here behind the scene behind this line documents it's not simply inserting it to the database but it's first generating these embeddings using the open AI model uh because having them inside a vector store we can later retrieve them based on a similarity search basically hey having this text what is the most similar document for for for that text and similar in in terms of context so we build a tool and we build an agent we give that agent V tool that can retrieve documents perfect in The Next Step we're going to clean it up a bit and start thinking about like how to move it closer to a production R application and system that that can run on autopilot with multiple um with multiple videos with a proper database because right now we are using the memory Vector store in memory Vector store storing this data in memory and as soon as I stop the the server it's lost so for AI there is prom caching where the llm will cache your input so it can be can be reused so like with Claude your cached input is like if the input is $1 the cached input will be 115 but then you send the same thing again into cash so the input is like 20 cents yeah not sure not sure how this is going to work here I would have to look into that okayy dokie okay uh one second guys let me think about something um next let me show you a small problem and fix it together with you for example we are asking the first question let's do it like this uh console log q1 is going to be this one and what if we go ahead and ask the question two which is going to be what is the finish time of very stop and I don't know finish time or position or no let's do it in another way let's do what about ver stopen and here what was the uh finish position and time what I'm trying to do here and let's do results two and here results two is I'm trying to simulate asking a follow-up question a followup question might not have all the context I mean a good chat AI agent will REM will understand that a question like this what about stopen is not is is connected with a previous question so it should be something like finish position over stoen in order for that to happen our agent should have short-term memory knowing uh or actually long-term memory uh having context about like previous messages in the Fred because if I do that right now if I'm not mistaken uh let me do CD ser server let's do node and invoke it it should answer correctly the first the question one what is the finished position it failed to actually invoke the tool there and in the cute question two about your stomping why did it ask about Norris wait a second that's a bit weird because when I asked about ver St and it started doing about noris uh oh oh oh oh oh oh oh because I'm stupid let's do what about we're stopping here I left literally the same question based on video transcript let's try again so for this question it invokes the tool it asks for noris finish time it doesn't like the response it invokes it again nor is final time position oh no no no it understand that it this question finish position and time it split automatically in two requests one is noris finish time and another one noris final time position result amazing and then by invoking by by retrieving two sets of data it was able to say that yeah there is no specific time there in numerical format and here what about verstappen and what it says I'd be happy to help you find information about m versten however I need to search for YouTube video transfer for could you please clarify what specific aspect about ma Sten you're interested in so here we understand that when we asked second time a follow-up question what about resten it did not connect it with a first question and he did not understand that we mean like finish position in time it's not clear here it's for us it's clear that the AI doesn't connect the two questions together that it's the same interaction for that to happen we need to provide here to the agent a long-term memory a checkpoint so again in the previous tutorial I have here adding memory to our agent and we can do that by importing memory from linkchain L graph at the top and somewhere here where we create the agent we can say a memory saver and we're going to give it here as if I'm not mistaken is check pointer memory saver check pointer memory saver or if you want to save on some characters you can call it here checkpoint and remove a duplicated because it's the same name now because it has a checkpoint we are not going to be able to invoke it like this and if we do if I'm not mistaken we're going to have an error saying that now you have a checkpoint we need to provide them um a configuration with a Fred ID so using a Fred ID we're going to know like what other previous messages to connect it with and that is going to happen when we call agent. invoke uh after the whole invocation we are going to have here a conf configurable options with configurable and here we're going to have Fred ID let's say like I don't know Fred number one I'm going to take this options and I'm going to add it to the second invocation as well that way connecting them together and pay attention where I am adding them this is actually after the object that has a messages it's not besides it so it's two different objects now if I'm going to send the same request here what I expect is that the second question will understand that it's a follow up for the first one so it will understand that I'm asking about finish time and position for where stoping and we see that indeed it understood so it's doing a search query in our tool forward stop and finish time and position results uh finished second place right behind Lou Hamilton amazing so that's uh not amazing that he finished second uh not a big fan but amazing that it's working so just by simply adding this checkpoint that's what we managed to do adding like more configuration here um another thing that we can do here uh when we invoke in the configurable we can send more metadata things like let's say the video ID that we are querying for video uncore ID is going to be equal to let's go into the data and say that we are working with with this video ID the first one Sprint qualifying we can take this video ID and in the configure we say that in this thread hey we are talking about this video again it depends on how you want to uh architect the the experience but if you want one thread to be specific to one video that would be a good configuration later we can think about like how maybe we can send a channel ID here or we can let the AI agent understand magically how what video we are talking about but this is a good way to send data so I'm going to send it through configurable here I will remove a second one because we we had it just for testing thing and I'm going to take this video ID and what where we going to receive it I need to receive it somehow here in the retrieve tool to receive it in the retrieve tool this is the input of the tool but here we get the options of the invocation and we can go ahead and get access to the Fred ID where in this case I need the video uncore ID so if I do here uh query console log video ID let's see if in our tool we get access to the video ID from our invocation if I call this one here we see that ID here it's still going to work the same because we just simply do this but what we can do here is we can use the video ID for the similarity search I'm going to show you the documentation where you can find it just Google L graph uh Vector store and the JavaScript for example if I'm not mistaken here and you're going to see that L graph Vector l l chain Vector store GS so in the documentation you're going to see some options that you can use I need options yeah I'm pretty sure like you can you you'll find here like maybe I'm going to leave a link in the guide here so you can have access to it but what I mean there is that when we do Vector store. similarity search the first one is query the second one is how many items we want to receive but the next one is the filtering in the filter can be uh a filter on the metadata so so we can say that I want only the dog dogs or maybe I need filter here let me double check that no it shouldn't be filter it should be simply video ID so this is the filter that is being applied and is being applied on the metadata of our documents and if we look in the metadata of our documents we store the video ID here later when we add the database we're going to be able to see visually what I mean there and now let's go ahead and see maybe um console log retrieve docs to see what document docs did it receive for that query I'm going to go ahead and ask the invoke the this one with a question what is the finished position of Nores it knows that is this video ID because we specified it it's going to ask norish finish time and it will say the apolog but it seems there is a technical issue with the retrieval function in order to provide more with accurate information basically it says that there is no items with this ID and why is that happening something wrong with here with a video ID video ID did I call it video uncore ID here metadata video ID and let me look in the database video uncore ID Vore ID filter this is Vector store similarity search I'm wondering if this uh is not going to work for the inmemory vector databases but only for the for the postgress databases uh because as I see the retrieve docks right retrieve docks for query it doesn't even get here so it must fail completely it doesn't get retrieve docks so let's try to do a try catch just to to see why it's not working it's it's hopefully it's going to to show me but yeah as I'm saying maybe uh this kind of filtering doesn't work on the inmemory filter is not a function okay so for the in memory maybe filter should be a function let's try let's try saying that hey Doc is a function and we're going to return true if doc do metadata. video ID is equal to video uh video video ID that you're looking for again uh this is going to be a bit different later but now for in memory database I think it expects a function for filtering and let's uh let's try to maybe remove a TR catch and invoke it again okay we see that and we see retrieve documents V documents cool if for example I'm going to make a mistake and say give me we are working with video ID one 2 three this video ID is not in our database and it's supposed to filter out like other documents in the database we see retrieve docs as an empty um array saying that meaning that our filtering is working correctly now what we can do is we can load the other video as well let me go ahead and maybe split up a little bit the logic of of generating this embeddings because I would like to already clean up a little bit here this file is getting a little bit out of hand and it um is responsible for different pipelines different layers uh it's both for indexing and adding to the database and it's also about the agent I want agent to be only specific to agent [Music] um so let's go ahead and create here in the server a new file called embeddings edings hopefully I wrote it correctly maybe not is it with double d embeddings maybe and from the agent move stuff related to embeddings where what stuff do I mean well first of all I want to move the gener uh creating the open Ai embeddings and the vector store I will copy them from here I will cut them actually and move them here I want to import what we need here and we have here what export Vector store maybe I'm going to do export const Vector store so that other files can import this storage I'll also do export const add documents to Vector store function uh or not documents but let's do add YouTube video to Vector store let's say we're going to get video data and we need to do something with it what do we need to do in order to add it to to the vector store well we already have it in the logic in the agent AI if we look here well first we have to Define the split or actually with docs so I'm going to copy creating with documents creating with splitter generating the chunks and finally doing Vector store at documents I'm going to copy all of this into embeddings because this is part of adding a YouTube video data to Vector store so for the document we need to import uh document from linkchain core documents page content is going to be video data. transcript metadata is going to be video data video ID or we can do it easily here destructuring and video ID is going to be like this because it has the same name and title we need to import the recursive character text splitter from L chain text splitter here we're going to leave the same configuration we're going to remove this console log and we are adding it to the vector store that we created at the top Vector store add documents chunks perfect so now this file is responsible for setting up the vector store and adding for example YouTube videos to Vector store let's go ahead back and clean up a little bit here uh we'll leave a retrieve tool here I don't know I don't need the video one or maybe I need do I need it I think I don't yeah I need it because it's still going to be here that I want to add this video to our database so for that we need to import Vector store and add YouTube video to Vector store from embeddings and I want to call here a wait add YouTube video to Vector store so I still want to add it here later we're going to think where to do it for now I just want to I move a code in another file and call it from here I'm still going to have a retrieve tool that needs access to the vector store so that's why we exported and we import it here the same access to the same database and everything else is related to this one I can clean up a little bit here the Imports of what we do not need anymore leaving only things that we need like this and what else cleaning up a little bit the console logs here as well checkpoint or video ID okay this one is also going to go away in a second but it's testing the agent perfect so let's double check if it still works I'm going to invoke the agent. GS uh question was the position of Norris come on uh based on I can provide with more details Hamilton vers yeah like it we we understand that it's working it's using the transcript data uh what I want you to do now is let's try to add two videos to the store and see that in that case it can f filter out with transcripts related to one specific video for example I'm going to do a same await video add YouTube video to Vector store and I'm going to say that we want to add the data at position one here I can do data position zero and data position one if I'm going to go ahead and um ask the question about this video ID about Norris I think it's going to be fine because it's going to look only at the transcripts for that user at the same time it took a little bit of time to to add the embeddings but it's very fast like it's super fast let's see what's happening now uh I don't see a specific time for Norris mentioned that Norris racing that is going quickly through the middle part of a lap by 800 milliseconds however if I'm going to go into the data and take the idea of my second video let's find it with Vore ID and the second one is this one if I'm going to say it hey now this same question what is the finish time of Norris is going to be on a different video what I expect to see is I expect the model not to know how to answer because it doesn't have that information we gave it information from a different video let's see um based on the transcript I don't see any information about nor is the transcript appear to be discussing programming Concepts so that's exactly true because we are filtering out only data from our Vector store for this video ID if I will go ahead and transform change the question to what uh will people learn from this video Let's see what that answer is going to to look like because remember this video with this ID is a tutorial from my channel uh about Apple invite application so if we look at the response it doesn't understand that it needs to call the tool so let's see what will people learn from uh the video based on it's it's transcript it's still sometimes doesn't know that but it has this capabilities so maybe I need to inform it like hey at any moment you have information about video you just need to call the Tool uh but with a better question I think it's going to work better now as we can see it's thinking and we see based on the the video tutorial about building a mobile application how to create custom auto scrolling component Marquee building and boarding screens with animation implementing UI react development Concepts and so on so perfect now our AA agent can work with multiple videos it can store his data in a database but when asked it's going to look at only specific information for a specific video Perfect let me go ahead and do a git add git CIT agent with rag I'm going to bring some water and the next step for us is going to be to change from a memory Vector store to an actual database so that this data is not going to be lost and we're not going to have to generate the embeddings always we're going to store and cash them so that next time when we ask the same question about the same video we don't have to get the data again and again so that's our going to be our next step give me one second hello uh perfect so as I was saying the next step is going to be to transform to a proper database for our Vector store and that's one thing that I like about Lang chain is how everything um is abstract in different layers and you're going to see how easy is going to be to swap from a memory to we postgress database we just have to create it and change here how we connect it and everything else is going to remain the same without us having to do much changes for the database uh we need a postgress database with pogress SQL We There is a PG Vector extension that enables us to do similarity searches and index database based on vectors perfect for our in Bings so we need a pogress database you can run it locally you can use pogress with a Docker to run it locally that's totally fine but I think it's a little bit more technical uh and maybe not everyone has the environment set up to run postgress locally what you can do is you can use for example ne. Tech uh and with neon tack it's it's actually super fast and easy to to get a post database up and running uh and I think they also have a good free tier for up to 10 projects let's go ahead sign up and in your profile go ahead and do a new project I'm going to call it you AI YouTube chat and let's do create here uh we need to enable postgress uh database so what we have to do is we are going to enable it by running a query in the SQL editor the query I don't remember how it was but let's do enable PG Vector neon and that is going to be a query called create extension Vector so if I go into the SQL editor of my database on new one and write this command create extensions vector and do run it didn't like why it didn't like second time statement executed successfully so maybe it was not ready yet yet now it executed successfully so I enable this Vector uh extension on our database so our tables here will be able to have like vector um columns columns and index and search based on their similarity the next step is to Simply connect to this project from our uh application I'm going to go here and I'm going to copy the connection string let's go ahead and put it into that EnV file and let's call um DB URL and let's space the the connection string that we got from here make sure connection pooling is enabled and the next step is to go and double check with with where with uh with length chain under P your vector store I'm going to select PG Vector what I need to do is do npm install at L chain Community let's do that first and then we can create this Vector SC store like this so from our Bings files at the top we import PG vector and we create it instead of using memory Vector we create it using PG Vector store. initialize we give the same embeddings model there but we need to provide here some configuration configuration uh such as postgress connection options and the connection options you can either use a connection string the easiest way or you can have like Port host database name and so on but the easiest one is just to provide connection string as process. EnV DB URL that we added here in our environment variables and then we are not done yet with the configuration we need to give a table name the table name what is going to be the table name for this tour let's do transcript transcripts let's do transcripts um columns we can have ID column name come on columns the ID column name let's do it ID let's do the embedding column name you can specify what should be the name of the embedding you can do embedding or vector for example what I don't have text column name content column name this is the content of that embedding and there is also metadata column name name metadata I think you can leave them out as well but because it's going to be default but know that you can adjust them is it embeddings or vector oh it's Vector column name sorry Vector column name vector and besides columns you can also have a distance strategy and this is a little bit more technical basically meaning what uh function to use to calculate uh the similarity there is cosine uh there is uh whatever yeah there are other methods as well like inner product or Ean as well but cosine is default so you can leave it like this or you can even leave it out as well anyway now if I restart my application the vector store should automatically connect with this uh database with this configuration I don't need to change anything else the vector store will have the same ad documents and stuff like that and it should automatically handle the database creation for me if I go into new one under tables we don't have any tables yet but if I'm going to go ahead and restart or run our agent uh if everything is successful it's going to connect and store information in postgress we see that we cannot find the PG uh package because for that we need to do npm install PG this is for postgress so it's a pure dependency uh let's try to run it again we see Vector store from embeddings dogs does not provide an export member I forgot to do export Vector store if I do it again how many tabs open in that browser I don't know a lot and that's not even enough uh what will people learn from the video like now at this point if I go to the tables we see a new table called transcripts if you go into the options here and enable table RW count we see that we have around 167 chunks of data so this is not 167 videos but because my video one of them is 4 hours long it divided in in that many chunks so we see that the first ones is about L stroll and so one fastest ahead Louis Hamilton definitely uh transcript from uh Formula 1 videos but if you scroll down a bit we see that what information about the Bol text and react native and so on so this is the second video in the metadata there is the metadata about video ID so this is how the filtering is supposed to work and let's double check if filtering is working in a second and there is this Vector which as you can see is a bunch of numbers if I will I don't know I can copy it maybe I don't but you're going to see that it's simply a bunch of numbers so this is a better way because now it is stored in the database so we can we don't have to embed and generate them every time we can build a huge cache of this data to later interact with this is the information and again let me double check in the agent in that tool for retrieval we have here the function but as we can see now that our Vector store is a database it would be better to provide here a filter object and that filter object if I'm not mistaken is going to be added on the database layer so it's going to completely ignore those items when it does we SQL query so this is the filter to retrieve documents based on the video IDE perfect now I will [Music] do like this and at this moment we are still adding like that those items in the database so most probably we're going to have duplicated items we had 150 now we have 334 uh but it works here like this time it didn't call the tool but anyway or maybe it's a problem maybe it call the tool I'm going to comment out this wait add YouTube videos to the vector store because we're already there and I'm going to run it again to see if the filtering is working correctly because it's I not calling tool where the tool is not doing yeah I see information so that means that it's working correctly Perfecto amazing so this is our G ad database uh pogress for the vector database I think in the next step we are kind of ready to integrate the the chat interface and before we do that I want our server to be an restful API so that we later can interact with it by sending HTTP requests at the moment our agent we interact with it by literally calling agent. invoke and invoking that um executing this file but what I want want to do is I want to create an API that I can send this question as a post request and I can invoke this agent and get back the answer for that let's go ahead in the server and create the index do GS file and our server is going to be an HTTP server we're going to create using Express so let's install Express maybe course and types SL Express and let's start by creating a simple uh import Express from Express import course from course we create the express application we add course which is you don't have if you don't know like it's not a big deal here just add it because it's going to later help us send requests from different from our front end to our back end when we will be deployed and what I can do is I can say simply add a get request to the slash that will return hello world and start listening at P 3,000 for example or maybe we can do here const Port equal process. env. port or 3,000 if it's not provided I'll take Port here and the call back is going to be executed when we the server started listening this is a very basic barebone uh HTTP server what I can do with it is I can do node maybe with EnV file and I'm going to execute not agent but index.js if I do that we see Server is listening on Port 3,000 because this is a get request I can simply go to uh in the browser and do Local Host 3,000 and we see the hello world the hello world that was sent from here usually we are going to send this requests maybe we're going to be Coral request uh post request so we can also use the coral command in the in the terminal to send these requests okay good um what what I'm going to add now is not a get request but a post request to the endpoint maybe generator query or yeah let's do generate my generate is going to be like question and answer I send a question and I expect back an answer the query itself I expect it from the body and let's do console log query and return send like this now because this is a post requ actually I did some changes so I need to stop the server and run it again or I can do I can add come on to my node I can add here at d-w watch so that is going to watch any changes if I'm going to change something here it's going to restart so I don't have to think about restarting it always perfect now that our server has restarted we can send a post request to/ generate to do that in a new terminal I'm going to do coral Dash um that is a header let me try uh send a post request using curl to slash generate with a query data uh let's see what the AI will tell me yeah it's the dash X that I was looking for it should be here so I'm trying to send a post request to Local H Local Host 3000 SL generate with the data this query what will people learn from this video and this video ID maybe I will take video ID as well if I send this query we see something we don't know what exactly but we see some errors and an error here as well canot distract your property query from requestbody that's because we didn't um add quite important part which is the here as a middleware we can add a express. Json that will automatically transform our request body to Json because without that the request body is not a Json format if I simply add that one I can use it as adjacent and D structure the inputs like this now if making sure that the server is running if I send the same request again we see hello world because that's what we send but in the server we see that the query is this one and the video ID is this one meaning that I can go ahead and import the agent here from our agent. JS let's make sure that in our agent. GS we do export const a agent we no longer interact with it directly so I can remove this part all together or maybe I'm not going to remove it let me actually copy paste it in our index inside the generate I'm going to put it here I'm going to come to it in a second but I need to change how we import the agent we need to destructure it when importing because we are expor in it as a constant so we have agent here from agent. JS and when there is a request to SL generate we get the query we get the video ID uh and we have the interaction with agent as we had before I'm going to do some changes we no longer need this video ID because it's going to come from the request body I'm not going to have his console log I'm going to have agent. invoke and roll user and the content is going to be query not this hardcoded one but the query that we receive for configuration we have Fred ID so maybe we're also going to send the Fred ID here so let's do Fred ID and video ID then we take the result and we return it back as results maybe I can do it like this let's see return that Json to send it as a Json and I'm going to send the last message maybe it's going to be too much information but let's see what's going to happen now our server has restarted and we can send the same request but we need to change it slightly to add in this um- D I'm going to add a comma here I'm going to do a is it an enter come on it's a bit hard to to edit them but I can I'll do it like this I'm going to add it here I'm going to comment it out PR ID one I'm going to uncomment it copy it and comment it back and I'm going to leave it here for you to also be able to test this endpoint easily I'm going to go into the terminal and I'm going to send this request it's going to already work with this query and with this video ID and we see a lot of things but we also see the content and I'm thinking should I just return the content is anything else important here for the front end where is cash and so on in response metadata ID model let me simplify it and just say rest. send Das content so I'm simply going to send the content there and if I send it again it's going just to give me the content you can adjust it like depending on what information you want to send to the to the front end perfect it works and I think that is it for our first step into creating a restful and a server for our AI agent so that in the next step our front end is going to be able to interact with this server when the user write something in an input box for now let's do go ahead and do G status git add get commit um add rest API for our backend and for the agent perfect now it is time to already instead of instead of doing it for C request it is time to integrate the the frontend the client side application from which we're going to be able to interact with our our AI agent I don't want to spend a lot of time building it uh and for that reason I'm going to show you I'm going to leave in the in the guide let me think yeah if we look into the tutorial build AI agent with lra for the front end what I did is I simply created this prompt and I use entropic to build the front end for me so I told it build a simple UI interface for an AI chat up with this structure with this styling with this and that and that and in then we got like this AI chat interface and I think it's pretty good for us uh and because I don't want to focus on building the uh the front end we can reuse the same code here where we can try to reuse the same uh um uh llm generation as well I'm not sure what is going to be the result so it's better to use it together with me so first let's go ahead and run npm create V at latest to generate a new react project but this time make sure that you are not inside the server so if you are in server you can do PFD to look where you are make sure to go one layer up to be if you do us to see the server here and now let's go ahead and do npm create V latest let's give a project name let's do chat with YouTube or let's do here client let's call let's use uh a framework and the framework is going to be react I'm going to use um should I use typescript let's use typescript rpt and that's it now we have a client side project if I'm going to go into CD client and do npm start or npm install to install the dependencies in van npm run Dev we're going to see a local host here and if I open open it up we're going to see the starting point for a react application perfect let's go ahead and as as I was saying either uh use this llm to generate uh this prompt in an llm like entropic or in the CLA or um chbt and generate the Cod is like that or come here I'm going to leave it in the comments so you have access to it uh and press the source code here we're going to have the same client here in the source I'm going to look at the up. TSX I'm going to copy everything here and I'm going to come into the client source application based everything here and this same thing for uh is it index. CSS I think so let's copy everything from index. CSX and add it here by replacing everything like this uh the only thing is that if you look into up. TSX it tries to connect to Local Host 3000 so let's change it to 3 3,001 let's change it to 3,000 because now our back end is running on 3,000 and let's try to what to restart it by running npm run Dev again this is the API if I open it up here boom here we have a chat interface if I'm going to say what's going to happen what's going to happen in the client if I if I'll say hello there was an error because probably we're going to have to change a little bit how we do that uh if we look into app. TSX and are looking here around line 50 we have API generate and the data here is a little bit different it does prompt it does Fred ID and it does video ID let's try to do video ID like this in the server in the index what do we have it should be the same SL generate slash generate instead of prompt I'm using query it was easier if I use the same so let's just change query here Friday is good video ID hardcoded video ID hardcoded and now if I go here and say hello if I reload say hello what's going on here if I look in the console into the network Tab and say again hello send we see that it failed why it's because of a what uh response request what's going on maybe our API is not running server yes fail to run index I'm going to go ahead and restart start my API my server and it still fails to run no now it says server running on this port if I come back here and say hello okay now it gets to the API hello I'm here to help you find information from YouTube video transcripts is there a specific YouTube video or topic you would like me to search for information about I can retrieve relevant parts of a video transcript based on a query perfect what we're going to do is let's go ahead and double check like we hardcoded vi video ID that video ID I'm just going to double check in the data if we have such a video ID yeah we do have and this one is is this apple style video let's check what um will the viewer learn by following this tutorial this is a question about a specific video use the tool to get to get to get to get to get how is it called to get uh relevant transcript okay it's very insistent okay what is the topic of the video you see like the the one benefit of an AI agent is that it can decide like how often and how to interact with the tool in this case a retrieval tool for the rag system the downside is that you lose a little bit of control and as you can see here some questions the tool didn't realize that it has to inter integrate with that um it has to call that tool so sometimes an old school chain of calls might be better but with write prompt engineering with WR descriptions of a tool uh I think you can get like where actual results and keep the benefits of having this AI agent that decides like um what to to call how often to call and so on so we see that based on the transcript this video appears to be aor about creating a mobile application perfect amazing so we have our front end as well we have our client side as well let me go ahead and do the following um I'm going to do a git add G commit minus M front and chat interface another issue is the agent will call a tool when you don't want it to yeah that that's also true like having like an agent as we have here we don't say like the word or how to do the things we just give it a bunch of tools and we let it decide like when to call it how to call it and so on so yeah sometimes it's going to do things that you might not do but that's it's That's The Power of an autonomous agent mine likes to use the generate image tool anytime it writes an image generation prompt I highly doubt you're comfortable speaking like that when you are not behind the safety of the screen what do you mean oh you you have some beef chill guys it's okay okay so what do we want to do next guys um what do I want to do next I know what I want to do next um the next step is being able to start conversation about new videos because right now in our neon database we prefilled it with some transcripts from two different videos and we can talk about those videos by hardcoding some data what I want to do next is to be able to embed an index any kind of video that the user wants to talk about for that we need to allow that to happen and one step before reaching that because we're going to do that with Bri data uh before we do that I want to host our both client side and server side so that we later we're going to see see like how we can connect bright data back to our system to get this data about the video transcripts so what we're going to do is we now are going to host our server with jio go ahead jio.com where you can follow the link in the description by the way uh this part of the video is sponsored by jio so thank you very much jio for making this possible and you can go uh on janio you're going to go into products deployment platform and you can uh go ahead in the documentation create an account and you can see different Frameworks and tutorials how to um deploy them in the genesio CLI let's go ahead and install genesio first by doing npm install genesio DG in the terminal I'm going to do that here I already have it installed but it that is not bad to update it as well uh and then we have to run genesio login let me double check that yeah need this one but make sure to create a genesio account and then you're going to need the deployment the the API key from there and you're going to run genesio is it login I forgot like how to to connect it with our yes jio login to the platform so if you run jio login you're going to connect it with your account after that we can start deploying our application but before deploying I'm going to create um genesio do yaml file that will specify how do we want to deploy our po server and the client um VL uh I'll will also provide it in the guide so you don't have to write it but I will write it quickly so uh I will comment like what everything means so first we have let me do it like this so I have a reference so the name is going to be the name of our project let's call it YouTube chat application you can specify the region where you want to deploy it for example Us East one and let's do yaml version two next we we have two things one of them is the back end and another one later is going to be the front end but first let's focus on the back end the back end you specify the puff to it so the puff is This Server so let's say server then language uh we're going to say name is uh GS and you can also specify the package package manager in my case I will specify npm now back in this line with language we're going to also have a environment that I don't know we'll have for example the API URL which is going to be the actual URL of uh our API let's say ABC for a second after that in our back end we're going to have some functions the function that we're going to have let's say that it's going to be name API simply API the puff to that function is going to be because relative to the back and puff server our function is going to be this puff so it's going to be dot slash the Handler or the entry actually the entry is going to be index file so index dogs and the type is going to be HTTP server so Jano is going to run a function that is going to serve our express application now in this environment API URL I want the whole backend to have access to the URL of where is our backend deployed so we can access it dynamically like this by saying that I will look into the backend so backend dot functions functions. name API do URL and this is going to be uh provided as a environment variable API URL everywhere in our backend we're going to see why we need it later now that we have our back end done let's go ahead and focus on the front end in case of a front end um the path is going to be client we are going to say what do we want to publish and we're going to publish with this folder with this folder is something that is going to be generated uh if we run a script when we want to deploy npm run build so if we run npm run build in the client is going to generate um this dist folder and that this folder is what we want to send and publish uh finally we need some environment here as well as we have on the back end something similar to here where is it I need some spaces but in this case it's a little bit differently uh it should be prefix with vcore API URL if you do V it's going to be accessible in the client side code there that's it now let's go ahead open the terminal and try to uh you can also do genio local to run it locally or you can do jio deploy to deploy it to jio hosting it says that we detect that entropic and open Ai and DB URL are not set remotely do you want us to set them for you let's do yes and I think it's going to look for this configuration and set them remotely uh everything on the back end work correctly the front end this does not exist uh I was expecting it to run automatically npm run build oh I think the problem is here it should be scripts not script because I can run it myself but it should run automatically when the engine are deployed so let's try again by changing it to scripts and what do we see we see that the function is deployed we see that is building the back the front end we see that because we didn't provide any subdomain it automatically addited it for us in Vis jio yaml like this automatically generated we see the link to the application dashboard and the link to the front end if I open front end what's going to happen we see that our AI chat has been hosted and we can say hello and if it can connect with our backend as well that means that everything is perfect perly configured and as we can see it actually is and we can ask things about the video what is the video about and it's going to interact with our neon database it didn't know it didn't call the tool but later it it will everything works or maybe not let me actually try um what is the video topic based on the retrieved transcript being more specific like what it should do like you know like I don't have any retrieve transcript yet to search no you actually have um you actually have just try it trust me you have transcript will it believe me I think it does because it's yeah based on the retrieve transcript the video appears to be about up development uh blah blah blah and so on and so on perfect amazing so this URL now is publicly accessible because we use jio to to host it very easily I will give it to you but I don't know if I should give it to you but you saw it so it depends uh if we open here janio in the dashboard we see that we have a function and we have a front end if you want to debug the functions you're going to go into the monitoring or into the logs and you're going to see different logs from your function calls you actually here just try it this is very um input so yeah this is how easy it is to deploy uh full stack applications both front end and back end with genesio perfect now in The Next Step let me actually go ahead and do get add deploy to genesio in the next step we are going to um add functionalities to interact with bright data and to scrape the transcripts of the videos that the user needs seems like convex would be a better option for the database how did you settle on new one uh I just wanted something simple like postgress and that's why like when I need just a simple barebone pogress I go to to new one but but um I haven't worked with convex yet actually and I'm pretty sure like if it's build like exactly for for for that one it would be better but it's super simple to change the only thing that you would have to change is in the server in our embedding here in the vector store you're going to initialize a different Vector store and L chain integrates with convex HS it's possible like that as well give me one second I'm going to take a very very short break and I come back and we continue with our implementation for hello so let me just double check something um I'm thinking how to design the user experience of of starting of of indexing a video that's that's what I wanted to say my initial idea was before we start and actually I had it before we start an AI chat we have to we have an input we have a um an input where we put the video ID not the video ID the video URL and then we take take the URL we scrape it we index it and only then we open up the chat and we can talk with that video now that now that I'm thinking wouldn't it be better if we just have a chat interface and we paste a YouTube video here and we start talking about it then we paste another video here and we talk about it and so on what do you think um how should we index videos more free flow in a chat way where our AI agent is going to have a tool that knows how to index videos or a more structured way where we have like an input give me the video ID I'm going to index it and then we open a chart with that video let me know in the comments like in the in the chat what what do you think would be better what you would like to see for example come on because there let me close some of the stuff down this is we need it I don't need this ones because in any way we're going to use Bri data to uh to fetch or to scrape the video data from YouTube we already saw how to do that uh uh and what we did is we want to Bright data we created an account then under web scrapers we go to web scrapers Library we are searching for YouTube and we see that there are eight different scrapers for YouTube while we are interested in this collect videos by URL so I'm going to click on it scrape our API let's do next and here in the API request Builder in the API request Builder we add the API token we add some inputs and we see a c command in this part we can also see how we can do that from node using fetch if I do that I can and also if I'm going to do a couple of things I need to include the errors that's good and I don't need to delete deliver results to S free storage I'm going to unselect that one but I want to send it to a web hook sending the response to a web hook uh the way it's going to work is oh I didn't show the the parts let me do it again so the thing is that uh we are still going to use bright data so going on bright data um dashboard we're going to go under web scrapers come on why it's not changing here so bright data dashboard web scrapers web scrapers library and we are searching for YouTube we're looking at the YouTube videos post and we select scraper API here we see that we already saw in the API request Builder but we just send the URL of a video and as a result we're going to get the scrape data including the transcript we're going to configure it a little bit for example I'm going to delete and leave only one input it's going to be easier for me to see there eror I'm going to deselect deliver results to external storage and I'm going to send send to web hook that means that when we send this request to to Bri dat data set trigger we are sending a request to start the scraping job but because scraping jobs can be it's a long time task it can be a couple of seconds but if there is lots of data it can be minutes um depending on the collection this one we see that on average is 7 Seconds anyway instead of waiting for the result we just trigger the request and then we can either re send another request to check the status where we can give Bri data a URL that bright data is going to call when it finishes the scraping job that's what we're going to do we're going to do here let's do HTTP example.com and later we're going to fetch it change it let's do example com/ webhook this means that hey bright data when you finish scraping this job send this data here and the file format I'm going to leave it to Json and in the example request instead of Linux bash I'm going to do node fetch here is a good example of how we can send this request let me copy it let's go in our server and I'm going to call create a new uh new file let's call it bright dat. GS and let's export const uh start or Trigger YouTube video scrape we have the URL of a video and what we have to do is we're going to paste the code that bright data gave us so we're going to change it a little bit for example we do not need to import fetch from anywhere I'm going to remove it because it's going to be there in the data this is the input so this is the URL that is going to be um s here so what I'm going to do is maybe I'm going to call this trigger scrape input with this URL not with this URL with this URL and here I'm going to Simply take the URL from the parameters and send it to Bright data like this maybe we can adjust it to send multiple uh videos as well but for now it's good like this then what we do here is we send a fetch to this long URL but let's break it down for example I'm going to break it down into maybe like this everything until slash trigger let's do here const bright data trigger URL is going to be equal to this one let's take it and let's transform this URL into a template string with your back ticks come on back tick here so that we can replace this URL with simply saying bright data trigger URL then we have data set ID data set ID identifies this YouTube video post data set it can also be dynamic if you want I leave it like this endp point is where do we want to send the results to where do we want to send the results to well we want to send it back to our API back to our server so in our index here let's go ahead and create a post post request called Web hook request response and let's simply go conso log request. body to see what data we're going to receive here now we have to say hey Bri data simply call back the server here at SL web hook but the URL we don't know we can hardcode it from uh from genisio platform but remember in jio yaml we said that we're going to give a environment variable called API URL that's what we why we need it we need it to dynamically say hey the const call back or web hook URL is going to be this one but actually it's going to be I'm going to change here to process. env. API URL SL webhook b/ web Hook is important because it's our endpoint implemented here okay so let's change the endpoint here pay attention of how we're going to do it this HTTP example.com webhook Until the End we're going to delete and replace it with the web hook URL then we have format Json is good uncompressed web hook true and include errors true everything is good here now the method is post authorization uh headers this is the bright data uh your API key so it's better to take it from here and add it to the environment variables as bright data API key and back here we're going to replace it again with a with process.env do bright come on should be bright data API key then content type Json and for the body we give this data I don't like the dot van so what I'm going to do I'm going to before fetch I'm going to say const response equal a weight then I'm going to put here I'm going to stop and what we have then we have data so const data equal a weit response Json and that's it and maybe you can also do a try catch maybe we can do result and we can do console log result and this is our function that is going to trigger a scraping job for a video URL we can do that by again we simply call it here maybe we can we should call it at the end right not at the top so we can give here a YouTube url like this one and we can do let's do CD server clear and I'm going to do node EnV file and let's run the BR data GS this function so we see that as a result we get the snapshot ID if we look into the Bri data logs we should have a new job here and if we look at this snapshot ID ending with 9 Q this is the last one here it took 5 Seconds to complete we can download or we can check what happened there with the endpoint um we haven't deployed it yet so give me a second but if we look here back in our API request Builder and you put here the URL of our genesio let's see uh let's first stop this one and let's deploy our update our update has this SL web hook endpoint yeah because we need to go one above to be in the root we detected a new bright data let's set it remotely automatically for us um so we see that the function API is this URL so I can copy it and basically use this one in the notify URL or no in the send web hook so send to web hook web hook URL this URL of my function you can also open it in the dashboard and here you're going to see a function URL and we need to also do slash web hook you can also press test web hook and this is going to test send a test result and we see test sent successfully if we go into the jio into the logs we're going to see a test a request body this was the test that was sent for us and we received it in our backend uh in our backend invest SL web hook that means that now if I am going to invoke the same function again for example Trigger YouTube video with this URL by this is a little bit hacky right now but in a second we're going to connect it with our API and it's going to make a lot more sense but I want to trigger a new scraping job and I want it to automatically call our web hook so if I go into the server and do node bright data GS that is calling this function we see this snapshot and this snapshot if I look into the logs it's ready and it's supposed to call our backend and if I reload we see yes we did um actually no it didn't you know why I know why because I'm running it locally and locally the web hook URL is not setting is not correct so that's why we need to do it remotely uh but yeah the next question is uh should I when should I call this Trigger YouTube video scrape should I create a tool out of it and give it to my uh let's try to create it as a tool let's try to create it as a tool I haven't tried it creating it as a tool um make sure to to remove it from here as a tool in our agent uh When I Was preparing I did it like with uh a input here so you input the YouTube video URL and then you talk with it but I think it would make more sense to see at least how we can do it with a tool in our agent so let's go ahead in our agent and create here a tool const um Trigger YouTube scrape scrape tool now it has a function that does something and some configuration for example name it can be Trigger YouTube scrape tool and description description trigger the scraping of a YouTube video using it using the URL the tool will not will uh start a scraping job that usually I will give it more context to know how to use it maybe I can do it even in in new lines like this The Tool uh that usually takes around 7 seconds maybe later we can give it a tool to also ask for um the status of jobs the tool will return the job ID that can be used to check the status of a scraping job this is a bit the tool will return the job ID should I just from Bright data here because it returns an object with snapshot ID should I just return snapshot ID I think so let's just do return results dot snapshot ID the tool will return the snap shot slash job ID that can be use okay use the tool only if a video is not in the vector store already in the schema we need the URL and we are going to get it here as URL what we need to do with it is we need to say hey snapshot ID return Trigger YouTube video from Bright data let's do console.log triggering YouTube video scrape and this one that's cool that because now if I'm going to make sure to run the server and run the front end locally and if I'm going to go to local call host uh what's the the API for the Local Host it's this one if I will say uh I will go ahead and take a YouTube url but wait a second I forgot one thing I forgot to take the trigger YouTube video scrape tool and give it to my agent now if I'm going to go ahead and take a video for let me see what exactly I want here I don't know what to [Music] say I'm going to do also F1 so if I take this URL and send it here can we talk about this and if I send this is a very interesting this is a very specific prompt saying that hey I want to scrape this video let's see what's going to do what's going to happen if I look in the logs for our server we see the triggering YouTube scrape job for this video ID for this video ID and it's not finished yet YouTube video scrip scrape triggered so it has a snap snapshot ID and what it does based on the information covered from the video transcript I can provide you with a summary of a YouTube YouTube video summary building a custom scrolling component in react native no that's not really true that's not really true and we are going to have to adjust it a little bit that's because now that we are working with URLs and video IDs like this it's not longer going to be part like in the retrieve tool it's no longer going to be the video ID here so I'm going to remove this configurable video ID or maybe let me do it like this and I'm going to take it from here from the parameters that our tool is going to receive and it's going to be the llm that is going to decide what the video ID is so again giving more control to the llm in here we're going to say in the schema that we have the video ID but we can also describe the ID of a video to retrieve yeah for a specific YouTube video now if I'm going to go ahead and say the same thing can we talk about this it's going to do that trigger and then is going to try to use the data from newon the thing is that it's not ready yet like our trigger even though we are triggering it the data is not stored in the in the database yet we didn't complete the loop yet so that's why we say I apology but it looks like the video content is still being processed and is available for me to retrieve information yet this typically takes around 7 seconds but sometimes it can take a bit longer that means that even though scraping job was correctly triggered as we can see here it's correctly triggered by our agent uh we need to deploy it and make sure that our SL web hook receives the requestbody but not only do we need to receive a request. body we need to index them how do we do that well request. body is basically similar to this data. GS it's an array with videos it can be one video it can be multiple video at the same time we have embeddings which has a function add video to Vector store which expects a video data so in our server index in the web hook what we need to do is we need to in a simple way we need to do a weight making it a sync first add video to vector store requestbody sl0 because the body is going to be an array and I can show you that by looking into the logs of genesio logs we see bodies and array but if you want to store all of them what we have to do is we have to say request. body. map for every single video data there we want to addit to um to the vector store and because this is an array of promises we're going to put it into a weit promise. all and say that hey a wait storing all the data and only then finish it return okay so now if we deploy uh I will probably do that um there is one more small thing that we need to take care of and instead of showing you the problem first let me explain it usually the express are going to limit how big the body of the post request can be however in our case if we are fetching the if we are scraping a podcast of 4 hours that's going to have a lot of data so it can be a couple of kilobytes couple of hundred kilobytes so in V express. Json we can give a option here to increase the limit of that data I can even do 200 megabytes I'm just just to make sure that it's going to work now that I have this one here let me go ahead and deploy everything to production using um jio deploy and we're no longer going to test it locally we're going to test it the deployed one so we see front and URL you can copy it we can go here and we can start by copying a URL let's go back to our application and let's talk about and let's do the video URL now if we look really quickly here on uh bright data I think it's supposed to to trigger a new job here yes it's running and this bright data job should call back back our API at/ web hook we're going to see that in the logs here I don't think we logged anything but we see that the function call at 51 just now which means that in newon if everything work correctly in neon database we should already have information about a video from a new from a new video I that is this four L at the end so if I look here in the new on [Music] database this is still that one and if I scroll there are a lot of them so let's do like this this is the last page if I look at the end it didn't work right I don't think it did uh um I need to double check if it actually was scraped correctly so video this one can I do a filter here where metadata but metadata is it oh no yeah here it is Louis congrats you see for it's a small video so it's four chunks at the end uh if I search here you see that these four chunks are about this video so what I can say here now is uh is it ready yet and it's supposed to already look into the neon database instead of triggering a new one did it trigger a new one uh this is now is 53 so I don't see a new job being triggered which is very good and the answer is great news the video content is now available based on what uh I've retrieved this appear to be a video about Formula 1 racing specifically featuring Louis Hamilton here is what I can tell you from the content uh how did Louis what was Louis last uh words last words not not that bad like last words in the interview let's see if it will if it can understand this kind of stuff based on we'll stay positive we'll keep our hands high and keep pushing forward perfect now I can go ahead and take a new video for example from our Channel and say hey come on live let's take this Lucas video and we can continue here as well can we talk about this video and provide a video it's supposed to trigger a new scraping jump let's see yes it's running so this is all done by the AI agent it's crazy and after some time it's going to add new stuff in our transcripts table we're going to already have 639 but this video is huge so that's why it took a little bit of time is it ready [Music] So based on a Content retrieve at around 42 minutes Mark I'm not sure like why it's say that at this point of a video Lucas appears to be wrapping up a tutorial live stream he's just finished implementing some functionalities related to making items pressible he just finished like that that that uh what is the tutorial about so basically I can talk with this tutorial with this YouTube video let me try to find something that lookas maybe do so sad what kind of list let's do what kind of list is that tutorial teaching shall we do that that's going to be the next question so this beginner friendly tutorial where Lucas is teaching the viewers how to build Apple news cloning R native like that like that like that what kind of list is Lucas teaching so how it's going to work it's going to look at it's going to find from all of the transcripts here from around 300 transcripts transcripts that are more similar to that maybe this one around here and based on that it's going to analyze and answer the question so let's see maybe something even more specific [Music] H how specific do we want to get but yeah let's see what's the answer and now because we are using um the AI model we can even combine multiple videos error processing request that's interesting I'm wondering why I don't know maybe time limit I don't know but what I wanted to try to do is go back to a previous video for example the Louis um what what was Louis excited about and I think it should link it to the previous video without scraping new data because it already has it in the database mhm the video where is earlier was about Formula One Would you like me yeah the question was about the previous video with ID maybe this one now I can properly answer your question uh what kind of was discussing okay key points about qualifying session perfect so I think this is better because it's very flexible it can start scraping like different jobs and even if we try to do that again I hope it's not going to add new items in the database because if it's smart enough it should first check if it has information about that so even if I remove and restart the chat from scratch and say can we talk about and the video about Lucas I I hope it's not going to start a scraping job but it's not up to us it's up to the agent and it actually indeed tried to to do that uh maybe we can instruct it better through the description of our agents use the tool only if a video is not in the vector store already so we need to tell it like check the vector store first because it added more items here also you can add a table with video IDs where you're going to save a status so so that it easier understand if it has videos or not um before calling this tool make sure that that it is not already in the vector store so maybe like this maybe with an additional tool to check the status of a video it can also improve like how our AI is going to is going to work but well let's change what I want to do here is that now from the client we are no longer having to send the video ID manually because that is the agent is going to understand from the context of what we are talking about um it's going to understand like the the video uh let's see and in the backend in the server here in the index we don't need in the generate the video ID again this is something that the chat is going to understand through the messages that it worked with perfect so now I can deploy it again and I think with this we have a pretty cool rag system that we can use to talk with YouTube videos Lucas filling in for Vadim who will return next week he's a developer video content and so one um all right what will you guys guys build with this one let me know in the comments below because I believe this system opens up so many opportunities and possibilities I'm thinking you can um you can build like a Chrome extension where you go in a video and you can already pop up here and chat with that video like give me the summary what did he say at the beginning what did he say at the end like uh it can be a great Learning Resource on top of you YouTube or other sources uh from the internet that can change the way we are consuming uh content um another idea that I have that uh this might serve as a core for implementing uh can be something for example we as notes da have a lot of content on uh um on our Channel when but sometimes it's hard to remember where for a new students to know like where did we use what so for example if you're interested in animation I would go into a tool into a chat box and say in what video uh did they talk about or uh give me the video ID or better URL for videos about F1 you have you know about I think without even changing anything it might work because it will look at the context it will check F1 and we'll find like these videos and let's see I don't have pre-existing list of videos I would need to specific on tools however tools I have designed R information from videos already know already know about by providing a video ID where to scrape new videos by providing video URLs mhm okay so yeah it doesn't have a tool to look at video yeah yeah yeah or to scrape new videos provide videos what if it just uses the same tool it should work it should work we generate in with the retrieve it needs a query and a video ID yeah this video ID yeah look I'm uh I was not sharing it but I wanted to for it to give me a list of videos about Formula 1 uh I think what but for that to work we just need to create a new tool let me try I'm really curious to see I'll create a new tool called retrieve similar videos and it's not going to get a video ID but it's going to get the query it's not going to get configuration and it's going to find like yeah top three videos about that and it's going not going to have any filter looking at all the data in the database it's not going to serialize the content of a page but it's going to uh map over doc. metadata do video ID so IDs and then we're going to return IDs retrieve similar videos description retrieve the IDs of the more similar videos to the query and I don't have this video this video ID so it's another tool that I can give to my agent and I think with that tool if I deploy we should be able to to talk with all the videos there and by adding this kind of tools like maybe you you are the tool to index a channel in all of his videos and then uh get um a tutor based on a Creator so you index the whole thing that he said and then you create a chatbot based on that Creator that's actually a very good idea let me see what's happening it deployed let's see uh the same the same question again let's see if it now can give me a list of uh video URLs I found a Formula One related video in the database here is the details video ID and this is the video link perfect is the highlights but there is one more you can access the F1 video direct [Music] through um I know what I know what happened there because even though um there are more items there about F1 the similarity search here of similar videos only received free top chunks and the fre top chunks might be for the same video so that's why uh it only gave me one video instead of more so maybe you can increase here from three chunks to 30 most similar chunks to that query H I don't know or you can have another table where you have videos and what are they about with a little bit shorter description with a shorter Vector based on the description so that you can also search like this for the videos as well perfect love it and I hope you enjoy this one as well uh all the links all the documentation and the are going to be available through the guide link in the description below so just simply go in the description and you'll find a link to the step-by-step guide um I'm going to put there also the source code so you can look at it and maybe Implement something of your own play with it like I'm so excited with with the possibilities of this one and everything related to AI nowadays um it looks like magic like we put stuff together we put the tools together and then it can do anything we just have to ask it the right question so I hope you enjoy this one I hope you learn something new uh learn new about a agents about rag system thank you very much for our sponsors bright data that allowed us to get access to any data on the internet which is so important nowadays in the AI age to have access to data and also uh janio for helping us host deploy our application in a very scalable environment in a in a in a server that can scale with our uh application thank you everyone who joined uh if you have more ideas if you'd like to learn more about AI or mobile development or anything else let me know in the comments below I'm going to to read them and note it down to to build something for you in the next week if you enjoy this one make sure to subscribe and I'll see you guys next week bye-bye",
    formatted_transcript: [
      {
        start_time: 199,
        end_time: 5319,
        duration: 5120,
        text: "what's up Noz developers welcome back to another live tutorial today we're going",
      },
      {
        start_time: 5319,
        end_time: 12639,
        duration: 7320,
        text: "to have another AI agent tutorial and our AI tutorial that is going to help",
      },
      {
        start_time: 12639,
        end_time: 19320,
        duration: 6681,
        text: "and teach you how to build an AI agent from scratch using langra as with an",
      },
      {
        start_time: 19320,
        end_time: 28800,
        duration: 9480,
        text: "aspect of rag today we're going to learn more about all of these terms what we mean and I'm so excited about everything",
      },
      {
        start_time: 28800,
        end_time: 34000,
        duration: 5200,
        text: "that is happening right now in the AI world like what's possible to build what",
      },
      {
        start_time: 34000,
        end_time: 41280,
        duration: 7280,
        text: "powerful tools we have available at our fingertips and how easy it is to actually Implement them after we",
      },
      {
        start_time: 41280,
        end_time: 46399,
        duration: 5119,
        text: "understand how they work and the goal of these tutorials is to help you make",
      },
      {
        start_time: 46399,
        end_time: 53640,
        duration: 7241,
        text: "sense of everything that is going on out there and to give this ideas of what is possible so make sure to follow along",
      },
      {
        start_time: 53640,
        end_time: 60840,
        duration: 7200,
        text: "this tutorial by the end and I promise you that you're going to know more about AI agents and how to build them know",
      },
      {
        start_time: 60840,
        end_time: 66119,
        duration: 5279,
        text: "more about rag system and how to build them and by then you're actually going",
      },
      {
        start_time: 66119,
        end_time: 72439,
        duration: 6320,
        text: "to have an system an AI agent with an interface with backend deployed and",
      },
      {
        start_time: 72439,
        end_time: 78320,
        duration: 5881,
        text: "accessible by anyone that can uh answer questions",
      },
      {
        start_time: 78320,
        end_time: 83600,
        duration: 5280,
        text: "about YouTube videos so the project that we're going to build today is the AI",
      },
      {
        start_time: 83600,
        end_time: 90960,
        duration: 7360,
        text: "chat with YouTube videos and what do I mean by that let me give you a little context that one of the most powerful",
      },
      {
        start_time: 90960,
        end_time: 99920,
        duration: 8960,
        text: "applications of llm nowadays is to build this sophisticated um question answering Bots",
      },
      {
        start_time: 99920,
        end_time: 107399,
        duration: 7479,
        text: "that have knowledge about a very particular area because we most probably",
      },
      {
        start_time: 107399,
        end_time: 113600,
        duration: 6201,
        text: "all have already experienced uh general purpose llms uh such as the chbt let's",
      },
      {
        start_time: 113600,
        end_time: 120399,
        duration: 6799,
        text: "say from open AI that is exceptionally good at understanding human language",
      },
      {
        start_time: 120399,
        end_time: 126600,
        duration: 6201,
        text: "and generating text answering questions or continuing uh text",
      },
      {
        start_time: 126600,
        end_time: 132760,
        duration: 6160,
        text: "generation however the general purpose AI models they do not know very specific",
      },
      {
        start_time: 132760,
        end_time: 138120,
        duration: 5360,
        text: "information so while it's a very good generalist when it comes to specializing",
      },
      {
        start_time: 138120,
        end_time: 145680,
        duration: 7560,
        text: "in a very specific topic it's not very good it doesn't have most up-to-date information out of a box um so for",
      },
      {
        start_time: 145680,
        end_time: 150920,
        duration: 5240,
        text: "example if we ask a question about a documentation or about like a document a",
      },
      {
        start_time: 150920,
        end_time: 157280,
        duration: 6360,
        text: "law or something like that it can get a little bit lost however if we as",
      },
      {
        start_time: 157280,
        end_time: 162400,
        duration: 5120,
        text: "developers give the right information to the llm the llm can use that information",
      },
      {
        start_time: 162400,
        end_time: 168360,
        duration: 5960,
        text: "to generate an accurate and upto-date anware which makes this system so",
      },
      {
        start_time: 168360,
        end_time: 175280,
        duration: 6920,
        text: "powerful this system of injecting uh context into llm is called Rag and",
      },
      {
        start_time: 175280,
        end_time: 181840,
        duration: 6560,
        text: "that's what we are going to use today and in our project our",
      },
      {
        start_time: 181840,
        end_time: 186879,
        duration: 5039,
        text: "system is going to get information is going to get a YouTube video we're going",
      },
      {
        start_time: 186879,
        end_time: 193799,
        duration: 6920,
        text: "to do some magic there to scrape that transcript of that YouTube video so we know what's being talked in that YouTube",
      },
      {
        start_time: 193799,
        end_time: 199560,
        duration: 5761,
        text: "video and then our AI chat is going to be able to answer questions very",
      },
      {
        start_time: 199560,
        end_time: 206920,
        duration: 7360,
        text: "specific to that YouTube video such as what is the main topic of a podcast how much money did for example he invest in",
      },
      {
        start_time: 206920,
        end_time: 211959,
        duration: 5039,
        text: "Beast games like very specific of what being discussed there and what's going",
      },
      {
        start_time: 211959,
        end_time: 217879,
        duration: 5920,
        text: "to happen is our AI system is going to go ahead and get the part that is most",
      },
      {
        start_time: 217879,
        end_time: 222959,
        duration: 5080,
        text: "relevant to this question and based on that part of the interview is going to",
      },
      {
        start_time: 222959,
        end_time: 228400,
        duration: 5441,
        text: "generate an answer or for example it can take an eight hour tutorial from our",
      },
      {
        start_time: 228400,
        end_time: 235079,
        duration: 6679,
        text: "Channel and you can ask questions like what tools didim use there he's going to look for the video uh transcript is",
      },
      {
        start_time: 235079,
        end_time: 240319,
        duration: 5240,
        text: "going to find the information there and is going to give you an answer or uh",
      },
      {
        start_time: 240319,
        end_time: 247959,
        duration: 7640,
        text: "maybe you can use it like I get an error did I miss anything and again it's going to use the brain power of an nlm with",
      },
      {
        start_time: 247959,
        end_time: 253760,
        duration: 5801,
        text: "the context of a video to give you the right",
      },
      {
        start_time: 254079,
        end_time: 261639,
        duration: 7560,
        text: "answer and this is actually how I came up to this idea I was thinking about building an agent that can answer",
      },
      {
        start_time: 261639,
        end_time: 266880,
        duration: 5241,
        text: "questions based on our videos for example you might be searching for um a",
      },
      {
        start_time: 266880,
        end_time: 272160,
        duration: 5280,
        text: "tool and you want to know in which video we implemented you can use this agent to",
      },
      {
        start_time: 272160,
        end_time: 278919,
        duration: 6759,
        text: "ask and it's going to go and knowing all the information about our videos is going to answer where that is happening",
      },
      {
        start_time: 278919,
        end_time: 285919,
        duration: 7000,
        text: "there are a lot of applications of this kind of powerful Bots uh from uh analyzing public data like on YouTube",
      },
      {
        start_time: 285919,
        end_time: 293039,
        duration: 7120,
        text: "chatting with long TXS with long loss uh with blog posts with",
      },
      {
        start_time: 293039,
        end_time: 300039,
        duration: 7000,
        text: "podcasts and much much much more so if we talked about rag let me",
      },
      {
        start_time: 300039,
        end_time: 306080,
        duration: 6041,
        text: "quickly discuss more about that so what is rag rag is stands for retrieval",
      },
      {
        start_time: 306080,
        end_time: 312479,
        duration: 6399,
        text: "augmented generation and in simple terms generation means the part of an llm that",
      },
      {
        start_time: 312479,
        end_time: 317680,
        duration: 5201,
        text: "generates text you give it some text usually let's say a question and how it",
      },
      {
        start_time: 317680,
        end_time: 323360,
        duration: 5680,
        text: "works it generates what is the most probable next part of a text that comes",
      },
      {
        start_time: 323360,
        end_time: 329680,
        duration: 6320,
        text: "after that usually an answer for example retrieval augmented means that it first",
      },
      {
        start_time: 329680,
        end_time: 336400,
        duration: 6720,
        text: "Reves context that it needs and it augments it improves the generation part",
      },
      {
        start_time: 336400,
        end_time: 341639,
        duration: 5239,
        text: "using the information retrieved so in our case with YouTube it",
      },
      {
        start_time: 341639,
        end_time: 349280,
        duration: 7641,
        text: "first will retrieve information about the video about the transcript and then using that information is going to uh",
      },
      {
        start_time: 349280,
        end_time: 355639,
        duration: 6359,
        text: "generate the answer rag has usually two parts in it",
      },
      {
        start_time: 355639,
        end_time: 363880,
        duration: 8241,
        text: "and the first part is in the pipeline is a indexing pipeline this usually happens offline um not when",
      },
      {
        start_time: 363880,
        end_time: 368919,
        duration: 5039,
        text: "the user requests something but beforehand and that usually happens in",
      },
      {
        start_time: 368919,
        end_time: 374720,
        duration: 5801,
        text: "following steps first we have to load the data this can be documents this can",
      },
      {
        start_time: 374720,
        end_time: 382919,
        duration: 8199,
        text: "be HTML Json URLs PDFs we need to get the data that we uh want to work with",
      },
      {
        start_time: 382919,
        end_time: 388800,
        duration: 5881,
        text: "after we get the data we have to split it into manageable chunks because uh if",
      },
      {
        start_time: 388800,
        end_time: 394560,
        duration: 5760,
        text: "we have like thousands of uh characters into a document it's going to be harder",
      },
      {
        start_time: 394560,
        end_time: 400240,
        duration: 5680,
        text: "to um there is a limit to how much context we can give it an llm and it",
      },
      {
        start_time: 400240,
        end_time: 407400,
        duration: 7160,
        text: "would be better to split it and then when we have a question only get the chunks the pieces of data that are",
      },
      {
        start_time: 407400,
        end_time: 412639,
        duration: 5239,
        text: "relevant to that question after we split the documents into small chunks what we",
      },
      {
        start_time: 412639,
        end_time: 419360,
        duration: 6721,
        text: "do is we embed embeddings um in simple words means we",
      },
      {
        start_time: 419360,
        end_time: 425160,
        duration: 5800,
        text: "take take a bunch of text we put it through a system and in the end we get",
      },
      {
        start_time: 425160,
        end_time: 433400,
        duration: 8240,
        text: "an vector and a vector is basically an array of numbers array of numbers that represents",
      },
      {
        start_time: 433400,
        end_time: 439240,
        duration: 5840,
        text: "a vector uh in a very multi multi-dimensional space to think about a",
      },
      {
        start_time: 439240,
        end_time: 447479,
        duration: 8239,
        text: "vector very simple one would be a two-dimensional Vector that is an arrow pointing into One Direction and having",
      },
      {
        start_time: 447479,
        end_time: 455120,
        duration: 7641,
        text: "this vector later we can compare it with other vectors to know how similar they are",
      },
      {
        start_time: 455120,
        end_time: 460960,
        duration: 5840,
        text: "that's basically how similarity search in this system works we take a text we",
      },
      {
        start_time: 460960,
        end_time: 467479,
        duration: 6519,
        text: "generate a vector which is a numerical representation of that text after that",
      },
      {
        start_time: 467479,
        end_time: 474800,
        duration: 7321,
        text: "we take a in The Next Step we're going to see how we find the similarity so after we generate this",
      },
      {
        start_time: 474800,
        end_time: 480879,
        duration: 6079,
        text: "embeddings and again it's important to understand the concept of it it's not very important to understand how this is",
      },
      {
        start_time: 480879,
        end_time: 487120,
        duration: 6241,
        text: "happening because it's a matter of calling an AI model that is built for",
      },
      {
        start_time: 487120,
        end_time: 494000,
        duration: 6880,
        text: "generating this embeddings so think about it as a function we give it text it gives us back an array of numbers",
      },
      {
        start_time: 494000,
        end_time: 499280,
        duration: 5280,
        text: "which represents a vector having this Vector we need to",
      },
      {
        start_time: 499280,
        end_time: 504919,
        duration: 5639,
        text: "store it somewhere and we need to store it in a database that can support",
      },
      {
        start_time: 504919,
        end_time: 510039,
        duration: 5120,
        text: "querying based on Vector similarity basically saying give me documents that",
      },
      {
        start_time: 510039,
        end_time: 517760,
        duration: 7721,
        text: "are very similar to this document based on these numbers after we have a store data there",
      },
      {
        start_time: 517760,
        end_time: 524279,
        duration: 6519,
        text: "we are ready for the next step the next step is retrieve and generate this usually happens when the user interacts",
      },
      {
        start_time: 524279,
        end_time: 530279,
        duration: 6000,
        text: "with our system when it asks a question so the user asks a normal question in a",
      },
      {
        start_time: 530279,
        end_time: 535800,
        duration: 5521,
        text: "very human readable language it can have mistakes and so on but llm is smart",
      },
      {
        start_time: 535800,
        end_time: 542800,
        duration: 7000,
        text: "enough to embed it and based on the embedding of a question which is the",
      },
      {
        start_time: 542800,
        end_time: 549440,
        duration: 6640,
        text: "same process as here we are finding the documents that are related to that",
      },
      {
        start_time: 549440,
        end_time: 556839,
        duration: 7399,
        text: "question that are very similar to that question then we see which of these",
      },
      {
        start_time: 556839,
        end_time: 563640,
        duration: 6801,
        text: "documents are the most relevant document to this question most relevant pieces of",
      },
      {
        start_time: 563640,
        end_time: 568959,
        duration: 5319,
        text: "do parts of our text relevant to the question we retrieve it from the",
      },
      {
        start_time: 568959,
        end_time: 575560,
        duration: 6601,
        text: "database and we put it as context in the prompt then this prompt we send it to a",
      },
      {
        start_time: 575560,
        end_time: 580640,
        duration: 5080,
        text: "normal llm such as open AI um models and",
      },
      {
        start_time: 580640,
        end_time: 585959,
        duration: 5319,
        text: "then we get an answer back but the answer has the context so it's very",
      },
      {
        start_time: 585959,
        end_time: 593360,
        duration: 7401,
        text: "specific to the data that we gave let me know if that is um that is",
      },
      {
        start_time: 593360,
        end_time: 602000,
        duration: 8640,
        text: "clear um but we're going to understand it and I'm going to explain it again and again as we Implement all of these steps",
      },
      {
        start_time: 602000,
        end_time: 607040,
        duration: 5040,
        text: "let's talk a little bit about the architecture of application that we're going to build today so first we're",
      },
      {
        start_time: 607040,
        end_time: 613320,
        duration: 6280,
        text: "going to have a chat interface we're going to build that with react the chat",
      },
      {
        start_time: 613320,
        end_time: 621160,
        duration: 7840,
        text: "interface uh is going to interact with our AI agent which is",
      },
      {
        start_time: 621160,
        end_time: 627680,
        duration: 6520,
        text: "going to be um in in our backend we're going to build our back end with no GS",
      },
      {
        start_time: 627680,
        end_time: 634720,
        duration: 7040,
        text: "I'm a JavaScript developer so I must rather I I feel more comfortable building with JavaScript but if you're",
      },
      {
        start_time: 634720,
        end_time: 642519,
        duration: 7799,
        text: "python developer langra is also available for Python and I know a lot of people prefer python in this in this",
      },
      {
        start_time: 642519,
        end_time: 649440,
        duration: 6921,
        text: "situations over JavaScript but I think it's perfectly fine with GS as well so the backend is in our case is",
      },
      {
        start_time: 649440,
        end_time: 655760,
        duration: 6320,
        text: "going to be an API that is going to contain multiple Parts one of them is going to be our AI agent and the AI",
      },
      {
        start_time: 655760,
        end_time: 663320,
        duration: 7560,
        text: "agent in this case like is a simple abstraction on top of an llm the large",
      },
      {
        start_time: 663320,
        end_time: 668519,
        duration: 5199,
        text: "language model provided by either anthropic or open",
      },
      {
        start_time: 668519,
        end_time: 674040,
        duration: 5521,
        text: "Ai and these uh providers like entropic and open AI they are very uh",
      },
      {
        start_time: 674040,
        end_time: 680880,
        duration: 6840,
        text: "interchangeable so use the one that you uh feel best um in this situation we're going to",
      },
      {
        start_time: 680880,
        end_time: 685920,
        duration: 5040,
        text: "have a simple chat chatting application such as CH that we can ask a question it",
      },
      {
        start_time: 685920,
        end_time: 691240,
        duration: 5320,
        text: "can answer us back nothing more than that it not doesn't yet have context",
      },
      {
        start_time: 691240,
        end_time: 696360,
        duration: 5120,
        text: "about YouTube videos but we need our chat interface to know and to talk about",
      },
      {
        start_time: 696360,
        end_time: 702160,
        duration: 5800,
        text: "the YouTube videos that we want to talk about for that we're going to have to",
      },
      {
        start_time: 702160,
        end_time: 710079,
        duration: 7919,
        text: "index our YouTube videos to build this rag system so if we look at the uh flow",
      },
      {
        start_time: 710079,
        end_time: 715360,
        duration: 5281,
        text: "we have to load the data first how we're going to load the data",
      },
      {
        start_time: 715360,
        end_time: 722800,
        duration: 7440,
        text: "well the data we're going to get it from YouTube uh and we're going to do that using the web scraper provided by bright",
      },
      {
        start_time: 722800,
        end_time: 729399,
        duration: 6599,
        text: "data if you don't know about bright data this is the best uh tool to scrape and",
      },
      {
        start_time: 729399,
        end_time: 735720,
        duration: 6321,
        text: "get access to public data uh on the internet uh they run on a very powerful",
      },
      {
        start_time: 735720,
        end_time: 741600,
        duration: 5880,
        text: "proxy Network and are implementing a lot of features of unblocking the web for",
      },
      {
        start_time: 741600,
        end_time: 747839,
        duration: 6239,
        text: "you like solving capturas or rotating IPS and basically you can think about",
      },
      {
        start_time: 747839,
        end_time: 754279,
        duration: 6440,
        text: "like okay I need data I don't know and I don't want to care about how to get it just going to go on bright data and",
      },
      {
        start_time: 754279,
        end_time: 760000,
        duration: 5721,
        text: "there you're most probably will find an API pre-build for scraping this data for",
      },
      {
        start_time: 760000,
        end_time: 765440,
        duration: 5440,
        text: "you if not you can use the scraping browser and implement this yourself and",
      },
      {
        start_time: 765440,
        end_time: 770839,
        duration: 5399,
        text: "in the world of AI with bright data you can give basically access to any data on",
      },
      {
        start_time: 770839,
        end_time: 777680,
        duration: 6841,
        text: "the web to your AI because the power of our AI models is depends on the power of",
      },
      {
        start_time: 777680,
        end_time: 784880,
        duration: 7200,
        text: "the data that we provide or give it access to so with combining bright data with AI models I think this is a very",
      },
      {
        start_time: 784880,
        end_time: 790360,
        duration: 5480,
        text: "good combination and Powerful one to that unlocks you so much",
      },
      {
        start_time: 790360,
        end_time: 796399,
        duration: 6039,
        text: "possibilities so we're going to use Bri data to scrape YouTube videos",
      },
      {
        start_time: 796399,
        end_time: 802199,
        duration: 5800,
        text: "specifically the transcriptions the captions and then we're going to need to",
      },
      {
        start_time: 802199,
        end_time: 807360,
        duration: 5161,
        text: "uh if we looking back into this one we need to split and embed it for that",
      },
      {
        start_time: 807360,
        end_time: 814800,
        duration: 7440,
        text: "we're going to use an l M such as open AI that is uh and specifically an",
      },
      {
        start_time: 814800,
        end_time: 820800,
        duration: 6000,
        text: "embedding model not a generation model embedding means we give you text you",
      },
      {
        start_time: 820800,
        end_time: 826480,
        duration: 5680,
        text: "give me back a vector after we have a vector we need to store it somewhere we",
      },
      {
        start_time: 826480,
        end_time: 831560,
        duration: 5080,
        text: "will store it in a vector database so it should be a database that can do these",
      },
      {
        start_time: 831560,
        end_time: 839639,
        duration: 8079,
        text: "queries on vectors like similarity queries and pogress has a PG vector that",
      },
      {
        start_time: 839639,
        end_time: 846519,
        duration: 6880,
        text: "is an extension uh allowing to do this kind of uh similarity search on",
      },
      {
        start_time: 846519,
        end_time: 853639,
        duration: 7120,
        text: "postgress data so we're going to do that as well we're going to create a database we're going to store the data",
      },
      {
        start_time: 853639,
        end_time: 859839,
        duration: 6200,
        text: "there and that is the first step done for the next step when the user ask a",
      },
      {
        start_time: 859839,
        end_time: 865079,
        duration: 5240,
        text: "question we need to retrieve this data and generate it so that's where our AI",
      },
      {
        start_time: 865079,
        end_time: 872800,
        duration: 7721,
        text: "agent we're going to have to give it access to our vector database to retrieve the information that it needs",
      },
      {
        start_time: 872800,
        end_time: 880800,
        duration: 8000,
        text: "to generate the answer so finally we're going to deploy",
      },
      {
        start_time: 880800,
        end_time: 886959,
        duration: 6159,
        text: "everything to jio both the front end and our back end for the AI agent and the",
      },
      {
        start_time: 886959,
        end_time: 892440,
        duration: 5481,
        text: "API and if you don't know about genesio this is the best way to deploy web",
      },
      {
        start_time: 892440,
        end_time: 897639,
        duration: 5199,
        text: "applications they support a lot of Frameworks both front end and backend",
      },
      {
        start_time: 897639,
        end_time: 903959,
        duration: 6320,
        text: "and that's what I like about it because I can use jio to deploy both the front end and the back end of our application",
      },
      {
        start_time: 903959,
        end_time: 911079,
        duration: 7120,
        text: "and we're going to have it everything up and running very very fast and I would like to say thank you to janio and to",
      },
      {
        start_time: 911079,
        end_time: 917040,
        duration: 5961,
        text: "Bri data for making this video possible very excited uh if you are also excited",
      },
      {
        start_time: 917040,
        end_time: 921160,
        duration: 4120,
        text: "I think we can get started let's roll the",
      },
      {
        start_time: 923740,
        end_time: 931360,
        duration: 7620,
        text: "[Music] intro all all right",
      },
      {
        start_time: 931360,
        end_time: 936959,
        duration: 5599,
        text: "so I want to mention that the step-by-step guide as usually is in the",
      },
      {
        start_time: 936959,
        end_time: 942800,
        duration: 5841,
        text: "link in the description below so if you go ahead on the under the video where is",
      },
      {
        start_time: 942800,
        end_time: 950839,
        duration: 8039,
        text: "it uh and open it here you're going to see the guide so go ahead open it up uh",
      },
      {
        start_time: 950839,
        end_time: 959399,
        duration: 8560,
        text: "go to site leave your name email and you're going to receive access to the",
      },
      {
        start_time: 959399,
        end_time: 964920,
        duration: 5521,
        text: "uh to the guide to the notion guide so let me copy the URL as well to open it",
      },
      {
        start_time: 964920,
        end_time: 970959,
        duration: 6039,
        text: "up here with you and here you're going to have like more step by step and I left here a",
      },
      {
        start_time: 970959,
        end_time: 981120,
        duration: 10161,
        text: "little bit more resources where you can learn more um so we're going to use a lot the",
      },
      {
        start_time: 981120,
        end_time: 987240,
        duration: 6120,
        text: "blog from linkchain because we're going to use l chain to build our AI agent and",
      },
      {
        start_time: 987240,
        end_time: 992399,
        duration: 5159,
        text: "we have here a two-part block log however not everything from here is",
      },
      {
        start_time: 992399,
        end_time: 999199,
        duration: 6800,
        text: "super applicable to our case so I would recommend you read here to know more or",
      },
      {
        start_time: 999199,
        end_time: 1005120,
        duration: 5921,
        text: "follow what we are going to do and we're going to do everything step by step for",
      },
      {
        start_time: 1005120,
        end_time: 1010920,
        duration: 5800,
        text: "that let's go ahead and open a terminal and get started I cannot wait to to get",
      },
      {
        start_time: 1010920,
        end_time: 1016839,
        duration: 5919,
        text: "started I'm going to zoom in here let's navigate to our",
      },
      {
        start_time: 1016839,
        end_time: 1020839,
        duration: 4000,
        text: "project YouTube",
      },
      {
        start_time: 1021920,
        end_time: 1031839,
        duration: 9919,
        text: "0320 like this and let's create a directory let's call it chat with",
      },
      {
        start_time: 1031839,
        end_time: 1038000,
        duration: 6161,
        text: "YouTube uh let's call it AI chat with",
      },
      {
        start_time: 1039160,
        end_time: 1044959,
        duration: 5799,
        text: "YouTube let's go ahead and open this folder in our editor of choice I'm going",
      },
      {
        start_time: 1044959,
        end_time: 1052960,
        duration: 8001,
        text: "to open it with cursor you can open it with Visual Studio code uh or any other editor of your choice in",
      },
      {
        start_time: 1052960,
        end_time: 1058440,
        duration: 5480,
        text: "my case using cursor is going to speed up a little bit the the development",
      },
      {
        start_time: 1058440,
        end_time: 1065000,
        duration: 6560,
        text: "process because nowadays I feel more and more often using um AI Co code",
      },
      {
        start_time: 1065000,
        end_time: 1070919,
        duration: 5919,
        text: "generation to to speed up my my process today I'm going to use it only in",
      },
      {
        start_time: 1070919,
        end_time: 1076200,
        duration: 5281,
        text: "specific cases where it's going to save us time but when it comes to learning",
      },
      {
        start_time: 1076200,
        end_time: 1084799,
        duration: 8599,
        text: "the AI agent we're going to try to write everything ourself um so being in this folder in",
      },
      {
        start_time: 1084799,
        end_time: 1091120,
        duration: 6321,
        text: "this project we're going to create uh first one folder called",
      },
      {
        start_time: 1091120,
        end_time: 1097600,
        duration: 6480,
        text: "server and this folder I open up terminal and did mkd server where you",
      },
      {
        start_time: 1097600,
        end_time: 1103120,
        duration: 5520,
        text: "can simply do new folder here and let's go ahead and do CD server in our",
      },
      {
        start_time: 1103120,
        end_time: 1111360,
        duration: 8240,
        text: "terminal and initialize our noj project I'm going to do that with npm in need- Y",
      },
      {
        start_time: 1111360,
        end_time: 1117159,
        duration: 5799,
        text: "and in our server we have package.json while we are here maybe we can even do",
      },
      {
        start_time: 1117159,
        end_time: 1122880,
        duration: 5721,
        text: "here type module um",
      },
      {
        start_time: 1122880,
        end_time: 1129080,
        duration: 6200,
        text: "to be able to use like normal import statements and for now that's it in a",
      },
      {
        start_time: 1129080,
        end_time: 1137080,
        duration: 8000,
        text: "second we're going to install dependencies here but for now let's go ahead and simply create the agent. GS",
      },
      {
        start_time: 1137080,
        end_time: 1142480,
        duration: 5400,
        text: "here because the first step in our case is is going to build our",
      },
      {
        start_time: 1142799,
        end_time: 1152720,
        duration: 9921,
        text: "agent here let's just do console log hello world in our package.json",
      },
      {
        start_time: 1152720,
        end_time: 1160440,
        duration: 7720,
        text: "H maybe I don't need it I will just go ahead in the terminal inside being inside the server",
      },
      {
        start_time: 1160440,
        end_time: 1166280,
        duration: 5840,
        text: "I'm going to do node agent. GS and if I do that we're",
      },
      {
        start_time: 1166280,
        end_time: 1172320,
        duration: 6040,
        text: "going to see Hello World so that's how we're going going to start initially testing it we're going to Simply execute",
      },
      {
        start_time: 1172320,
        end_time: 1179760,
        duration: 7440,
        text: "this agent file later we're going to put it inside um behind an API uh so we can",
      },
      {
        start_time: 1179760,
        end_time: 1188600,
        duration: 8840,
        text: "fetch and integrate it from the client side from the front end perfect let's go ahead and um there",
      },
      {
        start_time: 1188600,
        end_time: 1194799,
        duration: 6199,
        text: "is also a blog post which I did two weeks ago around building AI agents with",
      },
      {
        start_time: 1194799,
        end_time: 1201240,
        duration: 6441,
        text: "lra that one is really a step by step uh implementation of how to build this kind",
      },
      {
        start_time: 1201240,
        end_time: 1207440,
        duration: 6200,
        text: "of agents and I will open it up because there I showed you how to get started",
      },
      {
        start_time: 1207440,
        end_time: 1214880,
        duration: 7440,
        text: "with that what I want to do is I want to First install these dependencies I will install Leng chain L graph length chain",
      },
      {
        start_time: 1214880,
        end_time: 1221080,
        duration: 6200,
        text: "Das core and L chain entropic because I'm going to use entropic for the llm",
      },
      {
        start_time: 1221080,
        end_time: 1227200,
        duration: 6120,
        text: "for the completion model and then also Zod we're going to see why we need Zod",
      },
      {
        start_time: 1227200,
        end_time: 1232360,
        duration: 5160,
        text: "in a moment so let's copy this command from here I'm by the way also going to",
      },
      {
        start_time: 1232360,
        end_time: 1238840,
        duration: 6480,
        text: "add it uh here in the steps actually it's you can go in the steps and take it",
      },
      {
        start_time: 1238840,
        end_time: 1244120,
        duration: 5280,
        text: "from there and being inside the server here",
      },
      {
        start_time: 1244120,
        end_time: 1249360,
        duration: 5240,
        text: "let's go ahead and install L chain langra where is it",
      },
      {
        start_time: 1249360,
        end_time: 1256039,
        duration: 6679,
        text: "langra and Zod now we need to create thatv file",
      },
      {
        start_time: 1256039,
        end_time: 1262120,
        duration: 6081,
        text: "where we're going to write the um how is it",
      },
      {
        start_time: 1262960,
        end_time: 1269360,
        duration: 6400,
        text: "called we need the environment variable with entropic",
      },
      {
        start_time: 1269360,
        end_time: 1274720,
        duration: 5360,
        text: "key to get the entropic key go ahead on",
      },
      {
        start_time: 1275000,
        end_time: 1278919,
        duration: 3919,
        text: "entopic anthropic",
      },
      {
        start_time: 1282880,
        end_time: 1288159,
        duration: 5279,
        text: "doc go ahead and uh do build with CLA do",
      },
      {
        start_time: 1288159,
        end_time: 1295600,
        duration: 7441,
        text: "learn more start building and in your uh after signing in in your account you're",
      },
      {
        start_time: 1295600,
        end_time: 1304360,
        duration: 8760,
        text: "going to be able to generate an API Key by the way entropic is not the only way to do that you can easily integrate with",
      },
      {
        start_time: 1304360,
        end_time: 1313039,
        duration: 8679,
        text: "open AI as well however I tried with open Ai and I didn't really like the performance like how it behaved there so",
      },
      {
        start_time: 1313039,
        end_time: 1319240,
        duration: 6201,
        text: "I don't know maybe I didn't try the right model from open AI but we're still going to use open AI in the next step",
      },
      {
        start_time: 1319240,
        end_time: 1330200,
        duration: 10960,
        text: "for something else so in the embedding what we need to do in the EnV we need to provide here",
      },
      {
        start_time: 1330200,
        end_time: 1336720,
        duration: 6520,
        text: "the API key actually let me go ahead and uh",
      },
      {
        start_time: 1337159,
        end_time: 1344400,
        duration: 7241,
        text: "entropic console. entropic to generate a new key that we",
      },
      {
        start_time: 1344400,
        end_time: 1349000,
        duration: 4600,
        text: "can easily remove later",
      },
      {
        start_time: 1350960,
        end_time: 1358120,
        duration: 7160,
        text: "uh I need the de how is it called console",
      },
      {
        start_time: 1361559,
        end_time: 1367360,
        duration: 5801,
        text: "entropic do don't remember the the account that I",
      },
      {
        start_time: 1370840,
        end_time: 1377159,
        duration: 6319,
        text: "used okay here it is so what I'm going to do is I'm going to go into the API",
      },
      {
        start_time: 1377159,
        end_time: 1383760,
        duration: 6601,
        text: "keys I'm going to click read key and I'm going to see say here chat with",
      },
      {
        start_time: 1383760,
        end_time: 1389120,
        duration: 5360,
        text: "YouTube Key let's do add I'm going to copy it I'm going to also delete it",
      },
      {
        start_time: 1389120,
        end_time: 1395799,
        duration: 6679,
        text: "later don't worry and here let's put it into an an",
      },
      {
        start_time: 1396039,
        end_time: 1407200,
        duration: 11161,
        text: "Tropic come on un Tropic API key and let's put the API",
      },
      {
        start_time: 1407200,
        end_time: 1414440,
        duration: 7240,
        text: "key here let's also go ahead and add a new file",
      },
      {
        start_time: 1414440,
        end_time: 1421320,
        duration: 6880,
        text: "here dogit ignore with without dasg",
      },
      {
        start_time: 1421320,
        end_time: 1428000,
        duration: 6680,
        text: "ignore and add the. EnV file V because we don't want to commit the uh private",
      },
      {
        start_time: 1428000,
        end_time: 1433679,
        duration: 5679,
        text: "key of our models to our git while we're ve we can also put the node",
      },
      {
        start_time: 1433679,
        end_time: 1441159,
        duration: 7480,
        text: "modules perfect now that we have entropic key here uh we are going going to have access to it through",
      },
      {
        start_time: 1441159,
        end_time: 1450960,
        duration: 9801,
        text: "process.env but what we're going to do is we are going to use it to create",
      },
      {
        start_time: 1451120,
        end_time: 1458360,
        duration: 7240,
        text: "the the entropic chat client so in our agent what we need is",
      },
      {
        start_time: 1458360,
        end_time: 1462640,
        duration: 4280,
        text: "first we need to do to",
      },
      {
        start_time: 1463440,
        end_time: 1468960,
        duration: 5520,
        text: "import chat entropic from L chain entropic",
      },
      {
        start_time: 1468960,
        end_time: 1476520,
        duration: 7560,
        text: "then we need to say hey our llm is going to be a new chat",
      },
      {
        start_time: 1477320,
        end_time: 1483760,
        duration: 6440,
        text: "entropic where you can also specify here the model that you want to use for",
      },
      {
        start_time: 1483760,
        end_time: 1491120,
        duration: 7360,
        text: "example 3.5 like this or maybe you can even do latest or now we can do 3.7 if",
      },
      {
        start_time: 1491120,
        end_time: 1498919,
        duration: 7799,
        text: "we want you can also provide here the API key but if you don't provide B",
      },
      {
        start_time: 1498919,
        end_time: 1505440,
        duration: 6521,
        text: "injected as entropic aior key with this name it's going to automatically take it",
      },
      {
        start_time: 1505440,
        end_time: 1515720,
        duration: 10280,
        text: "from there so we're going to see like if it it if it has it next we will create a react",
      },
      {
        start_time: 1515720,
        end_time: 1521799,
        duration: 6079,
        text: "agent react not from react GS that we use on to build uh",
      },
      {
        start_time: 1521799,
        end_time: 1529039,
        duration: 7240,
        text: "interfaces uh it's from uh it stands for uh reason and act",
      },
      {
        start_time: 1529039,
        end_time: 1535279,
        duration: 6240,
        text: "so it's going to be an agent that can reason and use tools for us uh we just",
      },
      {
        start_time: 1535279,
        end_time: 1543080,
        duration: 7801,
        text: "give it like what's possible and it's going to decide how to to uh execute everything to provide the the answer",
      },
      {
        start_time: 1543080,
        end_time: 1549158,
        duration: 6078,
        text: "we're going to see in a second like what I mean by that to create one we're going to",
      },
      {
        start_time: 1549200,
        end_time: 1555520,
        duration: 6320,
        text: "import uh create agent",
      },
      {
        start_time: 1555520,
        end_time: 1561640,
        duration: 6120,
        text: "from L chair uh L chain core let me see where",
      },
      {
        start_time: 1561640,
        end_time: 1569080,
        duration: 7440,
        text: "from length chain slash length graph slash prebuild if I'm",
      },
      {
        start_time: 1569080,
        end_time: 1575760,
        duration: 6680,
        text: "not mistaken now we can say that hey our agent is going to be this",
      },
      {
        start_time: 1575760,
        end_time: 1582520,
        duration: 6760,
        text: "agent and an agent needs first of all the llm the llm which is going to be how",
      },
      {
        start_time: 1582520,
        end_time: 1590640,
        duration: 8120,
        text: "is going to complete stuff but it also needs let's set of tools in our casee we",
      },
      {
        start_time: 1590640,
        end_time: 1595720,
        duration: 5080,
        text: "do not have tools yet so we're going to give an empty array in this case this",
      },
      {
        start_time: 1595720,
        end_time: 1600919,
        duration: 5199,
        text: "agent is really dump it's a simple llm but later we can add tools so it can do",
      },
      {
        start_time: 1600919,
        end_time: 1609080,
        duration: 8161,
        text: "more stuff let's go ahead and uh test it out by saying Hey I want to do an",
      },
      {
        start_time: 1609080,
        end_time: 1614360,
        duration: 5280,
        text: "invocation of this agent with was the capital of the Moon that's very",
      },
      {
        start_time: 1614360,
        end_time: 1623000,
        duration: 8640,
        text: "interesting question let's see the result and to test it out I'm going to to Simply uh execute this agent. GS if I",
      },
      {
        start_time: 1623000,
        end_time: 1628360,
        duration: 5360,
        text: "do node agent. GS we're going to see an error seeing",
      },
      {
        start_time: 1628360,
        end_time: 1637080,
        duration: 8720,
        text: "that uh What uh the create agent right at Lang chain d l",
      },
      {
        start_time: 1637080,
        end_time: 1645000,
        duration: 7920,
        text: "graph D prebuild isn't it from there",
      },
      {
        start_time: 1649399,
        end_time: 1656880,
        duration: 7481,
        text: "oh create react agent I forgot that so yeah create react agent so in this case",
      },
      {
        start_time: 1656880,
        end_time: 1662960,
        duration: 6080,
        text: "it's not input but it's what uh I think it should be messages",
      },
      {
        start_time: 1662960,
        end_time: 1670480,
        duration: 7520,
        text: "right messages let's see how to invoke it",
      },
      {
        start_time: 1670480,
        end_time: 1673480,
        duration: 3000,
        text: "properly",
      },
      {
        start_time: 1687240,
        end_time: 1692279,
        duration: 5039,
        text: "what is the capital of a moon I don't know it says uh it has a red warning",
      },
      {
        start_time: 1692279,
        end_time: 1701600,
        duration: 9321,
        text: "here but I think it's going to work maybe we'll see we'll see ah no I don't think it",
      },
      {
        start_time: 1707120,
        end_time: 1716440,
        duration: 9320,
        text: "will so it's actually should be we need to give it an array of",
      },
      {
        start_time: 1716440,
        end_time: 1725000,
        duration: 8560,
        text: "messages and one message will be will have role user and content what is the capital of a moon very similar to how um",
      },
      {
        start_time: 1725000,
        end_time: 1732200,
        duration: 7200,
        text: "a chat interface will look like you have an array of messages the last one is from the user and the result is going to",
      },
      {
        start_time: 1732200,
        end_time: 1737799,
        duration: 5599,
        text: "contain the list of messages and what we are interested in is actually the the",
      },
      {
        start_time: 1737799,
        end_time: 1743960,
        duration: 6161,
        text: "last message but let's see if it will work like this if I do node agent what",
      },
      {
        start_time: 1743960,
        end_time: 1752840,
        duration: 8880,
        text: "we see is the API key entropic API key not found that's because even though we set it up here in the EnV when we",
      },
      {
        start_time: 1752840,
        end_time: 1760080,
        duration: 7240,
        text: "executed node agent. GS uh we should also provide the",
      },
      {
        start_time: 1760080,
        end_time: 1765399,
        duration: 5319,
        text: "EnV file equal EnV so we need to load",
      },
      {
        start_time: 1765399,
        end_time: 1771880,
        duration: 6481,
        text: "the environments from that file before executing the file the agent and just",
      },
      {
        start_time: 1771880,
        end_time: 1778039,
        duration: 6159,
        text: "like that we have the answer we have messages we have a human message and we",
      },
      {
        start_time: 1778039,
        end_time: 1783440,
        duration: 5401,
        text: "have an AI message this is ID content the moon",
      },
      {
        start_time: 1783440,
        end_time: 1789600,
        duration: 6160,
        text: "doesn't have a capital city because it doesn't have permanent and so on so cool",
      },
      {
        start_time: 1789600,
        end_time: 1795039,
        duration: 5439,
        text: "that's basically uh our list of messages so to",
      },
      {
        start_time: 1795039,
        end_time: 1803320,
        duration: 8281,
        text: "get the last one usually what we do is we say results at minus one to take the",
      },
      {
        start_time: 1803320,
        end_time: 1810440,
        duration: 7120,
        text: "last message from that array and then we look at the message do content and if I",
      },
      {
        start_time: 1810440,
        end_time: 1816600,
        duration: 6160,
        text: "execute it again we should see just the answer",
      },
      {
        start_time: 1817840,
        end_time: 1822600,
        duration: 4760,
        text: "no oh it's results.",
      },
      {
        start_time: 1823760,
        end_time: 1830000,
        duration: 6240,
        text: "messages dot content so results. messages there's the",
      },
      {
        start_time: 1830000,
        end_time: 1836679,
        duration: 6679,
        text: "array we take the last one and we display the content if I run the",
      },
      {
        start_time: 1840399,
        end_time: 1845760,
        duration: 5361,
        text: "file we see a simple answer like",
      },
      {
        start_time: 1846000,
        end_time: 1854120,
        duration: 8120,
        text: "this perfect let me know what do you think we should do next do we connect",
      },
      {
        start_time: 1854120,
        end_time: 1859159,
        duration: 5039,
        text: "this simple llm because at the moment this is a simple llm like like we called",
      },
      {
        start_time: 1859159,
        end_time: 1866039,
        duration: 6880,
        text: "it agent and we used like an agent but this doesn't make it a true agent why",
      },
      {
        start_time: 1866039,
        end_time: 1874960,
        duration: 8921,
        text: "because an agent needs a set of tools and the agent is going to receive",
      },
      {
        start_time: 1874960,
        end_time: 1880720,
        duration: 5760,
        text: "an input for example a prompt and it's going to first create a plan for",
      },
      {
        start_time: 1880720,
        end_time: 1886480,
        duration: 5760,
        text: "itself by calling different tools by govering different data it's going to",
      },
      {
        start_time: 1886480,
        end_time: 1892559,
        duration: 6079,
        text: "create a plan and it will do that over and over again until the llm is happy",
      },
      {
        start_time: 1892559,
        end_time: 1898880,
        duration: 6321,
        text: "and said said like okay this is answer this is a good answer and it's going to answer it",
      },
      {
        start_time: 1898880,
        end_time: 1904639,
        duration: 5759,
        text: "so for that to happen it needs list access to tools we're going to do that",
      },
      {
        start_time: 1904639,
        end_time: 1909760,
        duration: 5121,
        text: "later and one of the tools is going to be to retrieve information about like",
      },
      {
        start_time: 1909760,
        end_time: 1916399,
        duration: 6639,
        text: "videos but for now our agent is a simple llm we can give it a question it will",
      },
      {
        start_time: 1916399,
        end_time: 1924880,
        duration: 8481,
        text: "give us an answer using the cloud 3.7 from anthropic nothing too fancy now",
      },
      {
        start_time: 1924880,
        end_time: 1933760,
        duration: 8880,
        text: "the question is do you want us to build first the rug system here in a server",
      },
      {
        start_time: 1933760,
        end_time: 1939120,
        duration: 5360,
        text: "environment and test it with calling this function or do you want us to build",
      },
      {
        start_time: 1939120,
        end_time: 1945679,
        duration: 6559,
        text: "the interface first and connect it with our server so we can interact from the",
      },
      {
        start_time: 1945679,
        end_time: 1949840,
        duration: 4161,
        text: "from the client side from the interface",
      },
      {
        start_time: 1953080,
        end_time: 1959000,
        duration: 5920,
        text: "what first maybe maybe maybe I know but let's see what do you",
      },
      { start_time: 1960840, end_time: 1963840, duration: 3000, text: "think" },
      {
        start_time: 1970639,
        end_time: 1977638,
        duration: 6999,
        text: "uh and by the way hello everyone who is joining us live how are you doing guys",
      },
      {
        start_time: 1981000,
        end_time: 1986080,
        duration: 5080,
        text: "I'm using L chain in production want to try yam index I haven't tried yam index",
      },
      {
        start_time: 1986080,
        end_time: 1991159,
        duration: 5079,
        text: "yet uh what's the benefit of uh of it over L chain or what's the",
      },
      {
        start_time: 1991159,
        end_time: 1997480,
        duration: 6321,
        text: "difference I'm also learning a lot like about this AI lately and I'm so excited",
      },
      {
        start_time: 1997480,
        end_time: 2004279,
        duration: 6799,
        text: "what what the possibilities are hello um Joshy hello roio hello",
      },
      {
        start_time: 2004279,
        end_time: 2010760,
        duration: 6481,
        text: "blender music how are you guys uh Hey man you're doing a great job just",
      },
      {
        start_time: 2010760,
        end_time: 2017279,
        duration: 6519,
        text: "finished your react na8 hour videos what a Content thank you so much thank you I appreciate",
      },
      {
        start_time: 2017279,
        end_time: 2024279,
        duration: 7000,
        text: "it is it possible to persist data between each agent tool calls yes it's",
      },
      {
        start_time: 2024279,
        end_time: 2033000,
        duration: 8721,
        text: "possible and uh between uh agent tool calls yes",
      },
      {
        start_time: 2034919,
        end_time: 2042480,
        duration: 7561,
        text: "yes and we are going to do it we're going to persist the the history",
      },
      {
        start_time: 2042480,
        end_time: 2050560,
        duration: 8080,
        text: "of the of the chat so that you you can ask ask followup",
      },
      {
        start_time: 2052359,
        end_time: 2060358,
        duration: 7999,
        text: "questions okay let me see um so I think we go rag first I also",
      },
      {
        start_time: 2060359,
        end_time: 2065720,
        duration: 5361,
        text: "believe so because rag is the topic the the Hye part of this video and I want to",
      },
      {
        start_time: 2065720,
        end_time: 2072919,
        duration: 7199,
        text: "explain it well because client side um is just the interface so first we're",
      },
      {
        start_time: 2072919,
        end_time: 2080118,
        duration: 7199,
        text: "going to interact it with this like this later we're going to put it into an API and connect it to the client side so",
      },
      {
        start_time: 2080119,
        end_time: 2086000,
        duration: 5881,
        text: "we're going to do both of them but first let's go ahead and build the the",
      },
      { start_time: 2086000, end_time: 2088398, duration: 2398, text: "rag" },
      {
        start_time: 2094520,
        end_time: 2102760,
        duration: 8240,
        text: "system oky dokie so again",
      },
      {
        start_time: 2103839,
        end_time: 2109040,
        duration: 5201,
        text: "um uh if you go into the where is",
      },
      {
        start_time: 2109040,
        end_time: 2115720,
        duration: 6680,
        text: "it well first of all uh in our presentation if we look at the steps the",
      },
      {
        start_time: 2115720,
        end_time: 2122040,
        duration: 6320,
        text: "first one is going to be loading again our plan for loading the data was to use",
      },
      {
        start_time: 2122040,
        end_time: 2127839,
        duration: 5799,
        text: "bright data to scrape the transcript of YouTube videos from YouTube let's go",
      },
      {
        start_time: 2127839,
        end_time: 2134160,
        duration: 6321,
        text: "ahead and manually do that together with PR data and uh get some very specific",
      },
      {
        start_time: 2134160,
        end_time: 2141839,
        duration: 7679,
        text: "data of how this is going to look in the next step for that uh and by the way this part of the video of scraping is",
      },
      {
        start_time: 2141839,
        end_time: 2148119,
        duration: 6280,
        text: "sponsoring by Bri data so thank you very much our partners from Bri data for um",
      },
      {
        start_time: 2148119,
        end_time: 2153200,
        duration: 5081,
        text: "enabling us to build such amazing applications and to unlock any data on",
      },
      {
        start_time: 2153200,
        end_time: 2158960,
        duration: 5760,
        text: "the web so go to follow the link in the description below or go to bata.com com",
      },
      {
        start_time: 2158960,
        end_time: 2166800,
        duration: 7840,
        text: "uh and if you go to your dashboard we're going to use their web",
      },
      {
        start_time: 2166800,
        end_time: 2172960,
        duration: 6160,
        text: "data U where is it the web",
      },
      {
        start_time: 2172960,
        end_time: 2178720,
        duration: 5760,
        text: "scrapers so go ahead open web scrapers and if we go into the web scraper",
      },
      {
        start_time: 2178720,
        end_time: 2185599,
        duration: 6879,
        text: "Library these are pre-built webs scrapers that give you access to data in",
      },
      {
        start_time: 2185599,
        end_time: 2192359,
        duration: 6760,
        text: "a similar way as you would fetch an API but actually that data is uh scraped in",
      },
      {
        start_time: 2192359,
        end_time: 2197880,
        duration: 5521,
        text: "real time from the websites in a very secure and scalable way so you can you",
      },
      {
        start_time: 2197880,
        end_time: 2205400,
        duration: 7520,
        text: "can scale your project without any limitations there are a lot of sources data sources like",
      },
      {
        start_time: 2205400,
        end_time: 2213400,
        duration: 8000,
        text: "LinkedIn Instagram Facebook uh and so on uh even like Ecommerce like from Amazon",
      },
      {
        start_time: 2213400,
        end_time: 2218960,
        duration: 5560,
        text: "and so on what I'm interested in is YouTube data so so if I search Here",
      },
      {
        start_time: 2218960,
        end_time: 2224040,
        duration: 5080,
        text: "YouTube we're going to see that there are actually eight scrapers for YouTube",
      },
      {
        start_time: 2224040,
        end_time: 2232000,
        duration: 7960,
        text: "and the one that I need is uh video posts by URL so let's go ahead and click",
      },
      {
        start_time: 2232000,
        end_time: 2239800,
        duration: 7800,
        text: "on video posts by URL there is also a link in our guide scraper API let's do",
      },
      {
        start_time: 2239800,
        end_time: 2246880,
        duration: 7080,
        text: "next in the documentation of this API we say that we just give a YouTube url we can give also a country where to look",
      },
      {
        start_time: 2246880,
        end_time: 2252839,
        duration: 5959,
        text: "from and in as a response we are going to get",
      },
      {
        start_time: 2252839,
        end_time: 2260520,
        duration: 7681,
        text: "the data about that YouTube such as the title the video URL likes views date posted description",
      },
      {
        start_time: 2260520,
        end_time: 2268280,
        duration: 7760,
        text: "and so on but what's cool is that we're also going to um scrape the transcript",
      },
      {
        start_time: 2268280,
        end_time: 2274119,
        duration: 5839,
        text: "the transcript both in raw format like the whole transcript like this and also",
      },
      {
        start_time: 2274119,
        end_time: 2280119,
        duration: 6000,
        text: "if you scroll down below the transcript formatted with a",
      },
      {
        start_time: 2280119,
        end_time: 2286040,
        duration: 5921,
        text: "duration similar to how it appears on the video so we're going to use this",
      },
      {
        start_time: 2286040,
        end_time: 2292880,
        duration: 6840,
        text: "transcript from Bri data in our system to provide information to our rag system",
      },
      {
        start_time: 2292880,
        end_time: 2298520,
        duration: 5640,
        text: "to be able to answer questions about that video giving information to the llm",
      },
      {
        start_time: 2298520,
        end_time: 2303640,
        duration: 5120,
        text: "like what's happening in that video let's go ahead in the API request",
      },
      {
        start_time: 2303640,
        end_time: 2309599,
        duration: 5959,
        text: "Builder and see how we would interact with Bri data to give us this data for",
      },
      {
        start_time: 2309599,
        end_time: 2314640,
        duration: 5041,
        text: "example we're going to give inputs and we can do batch request so we can do",
      },
      {
        start_time: 2314640,
        end_time: 2320359,
        duration: 5719,
        text: "multiple inputs per request and here it's a simple URL of a",
      },
      {
        start_time: 2320359,
        end_time: 2325880,
        duration: 5521,
        text: "YouTube video for example uh let me do",
      },
      {
        start_time: 2325880,
        end_time: 2334800,
        duration: 8920,
        text: "two YouTube videos that I'm interested in I'm going to do one short one and one",
      },
      {
        start_time: 2334800,
        end_time: 2342640,
        duration: 7840,
        text: "a bit bigger let's do where is",
      },
      {
        start_time: 2343359,
        end_time: 2349400,
        duration: 6041,
        text: "it I'm going to do a short video to be able to to see like what's happening and",
      },
      {
        start_time: 2349400,
        end_time: 2356400,
        duration: 7000,
        text: "later I'm going to also do a bigger one give me one second or maybe we should actually do my",
      },
      {
        start_time: 2356400,
        end_time: 2361800,
        duration: 5400,
        text: "video like some some some of my videos yeah let's do",
      },
      {
        start_time: 2361800,
        end_time: 2368079,
        duration: 6279,
        text: "that for example h",
      },
      {
        start_time: 2368079,
        end_time: 2372079,
        duration: 4000,
        text: "which one I'm going to do a live",
      },
      {
        start_time: 2381000,
        end_time: 2386440,
        duration: 5440,
        text: "stream that one is going to be like",
      },
      {
        start_time: 2386720,
        end_time: 2393040,
        duration: 6320,
        text: "huge but maybe yeah we're we're going to test it with a huge video as well let me",
      },
      {
        start_time: 2393040,
        end_time: 2398480,
        duration: 5440,
        text: "just grab for example",
      },
      {
        start_time: 2405640,
        end_time: 2412440,
        duration: 6800,
        text: "this one so I'm going to give a 7 Minutes video from Formula 1 about",
      },
      {
        start_time: 2412440,
        end_time: 2418160,
        duration: 5720,
        text: "today's Sprint col ification I haven't watched it yet because I'm preparing but I'm very",
      },
      {
        start_time: 2418160,
        end_time: 2424000,
        duration: 5840,
        text: "interested I'm going to go into the Bri data API where it is here and the first",
      },
      {
        start_time: 2424000,
        end_time: 2430720,
        duration: 6720,
        text: "input is going to be this one and the second one is going to be a longer video like a 4our videos from our Channel",
      },
      {
        start_time: 2430720,
        end_time: 2437040,
        duration: 6320,
        text: "about building with react native and reanimated let's copy this URL as well send it as the second",
      },
      {
        start_time: 2437040,
        end_time: 2443079,
        duration: 6039,
        text: "one and what do we see here are some configurations to include errors if they",
      },
      {
        start_time: 2443079,
        end_time: 2449119,
        duration: 6040,
        text: "happen we can provide a URL where to send notifications and I'm going to exclude",
      },
      {
        start_time: 2449119,
        end_time: 2456240,
        duration: 7121,
        text: "this delivery to external storages if I do that and copy this Cur",
      },
      {
        start_time: 2456240,
        end_time: 2466400,
        duration: 10160,
        text: "command and go into a terminal and open it up like this and",
      },
      {
        start_time: 2466400,
        end_time: 2473720,
        duration: 7320,
        text: "paste the command here also make sure to add the API token here from your account like go ahead and",
      },
      {
        start_time: 2473720,
        end_time: 2480760,
        duration: 7040,
        text: "first create an API token and added here and it's going to automatically be added to the command what we're going to see",
      },
      {
        start_time: 2480760,
        end_time: 2486160,
        duration: 5400,
        text: "back is a snapshot ID a snapshot ID basically means that a job for scraping",
      },
      {
        start_time: 2486160,
        end_time: 2492640,
        duration: 6480,
        text: "the data started usually scraping data takes some time it's not instant because it has to",
      },
      {
        start_time: 2492640,
        end_time: 2498160,
        duration: 5520,
        text: "actually simulate opening a browser and navigating to that page and interacting",
      },
      {
        start_time: 2498160,
        end_time: 2504800,
        duration: 6640,
        text: "like a user would do so if we look in the logs here we see that a new job with",
      },
      {
        start_time: 2504800,
        end_time: 2510960,
        duration: 6160,
        text: "this snapshot that we just copy from the console log we see it here what we can",
      },
      {
        start_time: 2510960,
        end_time: 2518119,
        duration: 7159,
        text: "do is we can click download to Json and we're going to have a Json file",
      },
      {
        start_time: 2518119,
        end_time: 2525640,
        duration: 7521,
        text: "let me take the Json file and bring it in our",
      },
      {
        start_time: 2525640,
        end_time: 2531318,
        duration: 5678,
        text: "server as come",
      },
      {
        start_time: 2533000,
        end_time: 2538160,
        duration: 5160,
        text: "on I'm going to bring it here and I'm going to call",
      },
      {
        start_time: 2538160,
        end_time: 2545640,
        duration: 7480,
        text: "it data let's call itgs to easier import it",
      },
      {
        start_time: 2545640,
        end_time: 2552720,
        duration: 7080,
        text: "I'm going to click save to format it and I'm going to add at the top export",
      },
      {
        start_time: 2552720,
        end_time: 2558480,
        duration: 5760,
        text: "default so what we see inde the is an array with two objects the first one and",
      },
      {
        start_time: 2558480,
        end_time: 2565480,
        duration: 7000,
        text: "then the second one we see that this is the title of the video Sprint",
      },
      {
        start_time: 2565480,
        end_time: 2574000,
        duration: 8520,
        text: "qualifying we see this is the transcript and then we see if we scroll",
      },
      {
        start_time: 2574000,
        end_time: 2580200,
        duration: 6200,
        text: "down through this transcript formatted we're going going to see the second video as",
      },
      {
        start_time: 2580200,
        end_time: 2587480,
        duration: 7280,
        text: "well oh come on the second video is this",
      },
      {
        start_time: 2587480,
        end_time: 2594800,
        duration: 7320,
        text: "one and the transcript is what'sapp not just developers so now that we have this data",
      },
      {
        start_time: 2594800,
        end_time: 2600160,
        duration: 5360,
        text: "later we're going to automate how we uh start and how we get this data for now",
      },
      {
        start_time: 2600160,
        end_time: 2606160,
        duration: 6000,
        text: "let's just import it from data.js let's import it in our agent GS and say hey",
      },
      {
        start_time: 2606160,
        end_time: 2612319,
        duration: 6159,
        text: "import data from data GS and let's",
      },
      {
        start_time: 2612319,
        end_time: 2620920,
        duration: 8601,
        text: "say video one equal to data at position zero or video yeah let's do video",
      },
      {
        start_time: 2620920,
        end_time: 2626240,
        duration: 5320,
        text: "one because this is an array we're going to look at the first",
      },
      {
        start_time: 2626240,
        end_time: 2631559,
        duration: 5319,
        text: "video Perfect here is the data The Next Step that we have to",
      },
      {
        start_time: 2631559,
        end_time: 2638720,
        duration: 7161,
        text: "do is we loaded the data now we have to split it",
      },
      {
        start_time: 2640640,
        end_time: 2644359,
        duration: 3719,
        text: "let me",
      },
      {
        start_time: 2650520,
        end_time: 2655640,
        duration: 5120,
        text: "uh splitting we can do that in a",
      },
      {
        start_time: 2655640,
        end_time: 2661359,
        duration: 5719,
        text: "very ourself by simply looking at the",
      },
      {
        start_time: 2661359,
        end_time: 2667400,
        duration: 6041,
        text: "transcript of that video and splitting it into chunks of 1,000 characters",
      },
      {
        start_time: 2667400,
        end_time: 2672720,
        duration: 5320,
        text: "however L chain provides some pre-build Splitters that are a little bit more",
      },
      {
        start_time: 2672720,
        end_time: 2679280,
        duration: 6560,
        text: "sophisticated that is improving how this splitting Works to not lose some context",
      },
      {
        start_time: 2679280,
        end_time: 2686920,
        duration: 7640,
        text: "one of these Splitters is called re recursive character text Splitter from",
      },
      {
        start_time: 2686920,
        end_time: 2694960,
        duration: 8040,
        text: "length chain text is it at L chain",
      },
      {
        start_time: 2698599,
        end_time: 2701359,
        duration: 2760,
        text: "isn't it like",
      },
      {
        start_time: 2707800,
        end_time: 2714800,
        duration: 7000,
        text: "this uh like this and probably I need to install it right",
      },
      {
        start_time: 2714800,
        end_time: 2722640,
        duration: 7840,
        text: "npm install yes let's install length chain SL text splitters",
      },
      {
        start_time: 2727200,
        end_time: 2733640,
        duration: 6440,
        text: "so here we're going to do split the video into chunks for that",
      },
      {
        start_time: 2733640,
        end_time: 2741280,
        duration: 7640,
        text: "we're going to have to define a splitter using new recursive character splitter and",
      },
      {
        start_time: 2741280,
        end_time: 2746559,
        duration: 5279,
        text: "provide here some options as we can see the default ones that are recommended",
      },
      {
        start_time: 2746559,
        end_time: 2751960,
        duration: 5401,
        text: "here for me is chunk size and chunk overlap so what does it mean chunk size",
      },
      {
        start_time: 2751960,
        end_time: 2757920,
        duration: 5960,
        text: "means how large should the chunks of data be here we say it should be 1,000",
      },
      {
        start_time: 2757920,
        end_time: 2765200,
        duration: 7280,
        text: "characters and chck overlap is going to Simply uh repeat the last 200 characters",
      },
      {
        start_time: 2765200,
        end_time: 2771599,
        duration: 6399,
        text: "from this Chunk in the next one as well in this way if there is important",
      },
      {
        start_time: 2771599,
        end_time: 2778720,
        duration: 7121,
        text: "context between these splits we're not going to lose it so even vaa is going to lead to a little bit more data because",
      },
      {
        start_time: 2778720,
        end_time: 2783760,
        duration: 5040,
        text: "it repeats 200 characters at the beginning at end it's going to allow to",
      },
      {
        start_time: 2783760,
        end_time: 2788720,
        duration: 4960,
        text: "give enough context and not lose it",
      },
      {
        start_time: 2791960,
        end_time: 2798720,
        duration: 6760,
        text: "now um splitter like this at yeah uh is going to",
      },
      {
        start_time: 2798720,
        end_time: 2803800,
        duration: 5080,
        text: "work oh wait splitter by calling split",
      },
      {
        start_time: 2803800,
        end_time: 2813240,
        duration: 9440,
        text: "uh not text we can do split text as well yeah I think we can do split",
      },
      {
        start_time: 2813960,
        end_time: 2820880,
        duration: 6920,
        text: "text but we should actually work a better way would be to work with",
      },
      {
        start_time: 2820880,
        end_time: 2828280,
        duration: 7400,
        text: "documents um so we're going to call split documents for that we need to have a",
      },
      {
        start_time: 2828280,
        end_time: 2834040,
        duration: 5760,
        text: "list of documents let's call them docs I'm going to Define them a little",
      },
      {
        start_time: 2834040,
        end_time: 2839800,
        duration: 5760,
        text: "bit here to the top saying that the docs is going to be an",
      },
      {
        start_time: 2839800,
        end_time: 2846960,
        duration: 7160,
        text: "array an array where we create one of these documents with our video one",
      },
      {
        start_time: 2846960,
        end_time: 2852720,
        duration: 5760,
        text: "let's say that the document needs page content and the page content is what is",
      },
      {
        start_time: 2852720,
        end_time: 2858920,
        duration: 6200,
        text: "inside that document inside that document we're going to use the video one. transcript which if we look into",
      },
      {
        start_time: 2858920,
        end_time: 2865920,
        duration: 7000,
        text: "the data video one is this object and the transcript is this long",
      },
      {
        start_time: 2865920,
        end_time: 2870480,
        duration: 4560,
        text: "text so this is going to be the page",
      },
      {
        start_time: 2874720,
        end_time: 2880079,
        duration: 5359,
        text: "content the new document that document should be",
      },
      {
        start_time: 2880079,
        end_time: 2886280,
        duration: 6201,
        text: "imported from L chain core documents now if we take the documents",
      },
      {
        start_time: 2886280,
        end_time: 2892359,
        duration: 6079,
        text: "and split the documents here we have chunks let's see what are these chunks",
      },
      {
        start_time: 2892359,
        end_time: 2899318,
        duration: 6959,
        text: "console.log chunks if I open it up and run",
      },
      {
        start_time: 2900319,
        end_time: 2905800,
        duration: 5481,
        text: "the do node agent we're going to see what entropic key not found yeah because",
      },
      {
        start_time: 2905800,
        end_time: 2911720,
        duration: 5920,
        text: "we need to do withv file so what we see here is",
      },
      {
        start_time: 2911720,
        end_time: 2919440,
        duration: 7720,
        text: "that this chunks is an array with bunch of texts the first 1,000 characters then",
      },
      {
        start_time: 2919440,
        end_time: 2925200,
        duration: 5760,
        text: "the next one and these all are documents documents documents documents if we look",
      },
      {
        start_time: 2925200,
        end_time: 2933240,
        duration: 8040,
        text: "at the last part I'm going to even copy it and search for it we're going to see that it's both here and both here",
      },
      {
        start_time: 2933240,
        end_time: 2939839,
        duration: 6599,
        text: "because the text overlaps and that works with v end as well if I'm going to copy",
      },
      {
        start_time: 2939839,
        end_time: 2946359,
        duration: 6520,
        text: "it it's going to be both here and both here because the last part might be",
      },
      {
        start_time: 2946359,
        end_time: 2951760,
        duration: 5401,
        text: "important information for this chunk but it also can be important information for for this",
      },
      {
        start_time: 2951760,
        end_time: 2957680,
        duration: 5920,
        text: "chunk now we see that these uh documents also have this metadata this is a great",
      },
      {
        start_time: 2957680,
        end_time: 2963480,
        duration: 5800,
        text: "place to write additional data about those documents so if I look into where",
      },
      {
        start_time: 2963480,
        end_time: 2969920,
        duration: 6440,
        text: "we Define this document here we can def find the metadata here as well and one",
      },
      {
        start_time: 2969920,
        end_time: 2977559,
        duration: 7639,
        text: "of the important metadata Parts here is what video is this content transcripts",
      },
      {
        start_time: 2977559,
        end_time: 2984319,
        duration: 6760,
        text: "about because later we're going to have a lot of videos so we need to know like what where is it coming from we can call",
      },
      {
        start_time: 2984319,
        end_time: 2990799,
        duration: 6480,
        text: "it video ID and say that the video ID is coming from video one. uh video ID",
      },
      {
        start_time: 2990799,
        end_time: 2998040,
        duration: 7241,
        text: "because if we look into the data there is a video ID property here",
      },
      {
        start_time: 2998040,
        end_time: 3007040,
        duration: 9000,
        text: "now if I will execute this one again we're going to see that in metadata we have video ID later we can also filter",
      },
      {
        start_time: 3007040,
        end_time: 3014240,
        duration: 7200,
        text: "only the documents that are related to this video",
      },
      {
        start_time: 3017559,
        end_time: 3023079,
        duration: 5520,
        text: "perfect so the splitting Parts is done the next step is",
      },
      {
        start_time: 3023079,
        end_time: 3030960,
        duration: 7881,
        text: "embedding and embedding if we look into the length chain",
      },
      {
        start_time: 3030960,
        end_time: 3040119,
        duration: 9159,
        text: "here um this is what L graph I'm going to",
      },
      {
        start_time: 3040119,
        end_time: 3043440,
        duration: 3321,
        text: "find this",
      },
      {
        start_time: 3048599,
        end_time: 3054880,
        duration: 6281,
        text: "one uh as you can see for the chat model basically the model that will generate",
      },
      {
        start_time: 3054880,
        end_time: 3062480,
        duration: 7600,
        text: "text we can use these kind of available models uh grop open Ai entropic and so",
      },
      {
        start_time: 3062480,
        end_time: 3070440,
        duration: 7960,
        text: "on and actually more but for the embedding we need to use a model that is",
      },
      {
        start_time: 3070440,
        end_time: 3077000,
        duration: 6560,
        text: "specific for embeddings uh as I see entropic doesn't have an embedding model so that's why",
      },
      {
        start_time: 3077000,
        end_time: 3084480,
        duration: 7480,
        text: "it's not here for that we can use open AI you can see that open AI",
      },
      {
        start_time: 3084799,
        end_time: 3092079,
        duration: 7280,
        text: "embeddings you're going to see that that maybe on their site or the documentation is that they have this",
      },
      {
        start_time: 3092079,
        end_time: 3099400,
        duration: 7321,
        text: "kind of models where you give as we input some text and it get back the",
      },
      {
        start_time: 3099400,
        end_time: 3105400,
        duration: 6000,
        text: "embedding as an array of numbers the vector of that",
      },
      {
        start_time: 3105400,
        end_time: 3114000,
        duration: 8600,
        text: "text so let's go ahead and say that we are going to use um open AI as our embedding model so",
      },
      {
        start_time: 3114000,
        end_time: 3122960,
        duration: 8960,
        text: "let's go ahead and first install length chain - open AI in our application let's do make sure",
      },
      {
        start_time: 3122960,
        end_time: 3131119,
        duration: 8159,
        text: "you are inside the server and install the open Ai and what we're going to need to do is",
      },
      {
        start_time: 3131119,
        end_time: 3138640,
        duration: 7521,
        text: "we're going to import the first we need the open AI key inside",
      },
      {
        start_time: 3138640,
        end_time: 3144119,
        duration: 5479,
        text: "ourv go ahead sign up for open AI get to a key",
      },
      {
        start_time: 3144119,
        end_time: 3151079,
        duration: 6960,
        text: "and I'm going to get it here here let me do it like",
      },
      {
        start_time: 3151079,
        end_time: 3159720,
        duration: 8641,
        text: "this and I added it to the EnV now we are ready to use open AI what",
      },
      {
        start_time: 3159720,
        end_time: 3168920,
        duration: 9200,
        text: "we need is to import open AI embeddings in our agent open AI",
      },
      {
        start_time: 3168920,
        end_time: 3174760,
        duration: 5840,
        text: "embeddings from L chain open AI after",
      },
      {
        start_time: 3174760,
        end_time: 3181119,
        duration: 6359,
        text: "splitting what we are going to do let's do here embed",
      },
      {
        start_time: 3181640,
        end_time: 3189760,
        duration: 8120,
        text: "chunks to embed chunks we need the embeddings using the new create",
      },
      {
        start_time: 3189760,
        end_time: 3194000,
        duration: 4240,
        text: "or how is it open Ai",
      },
      {
        start_time: 3200799,
        end_time: 3208520,
        duration: 7721,
        text: "embeddings and you can also specify the model here I'm pretty sure is like uh default",
      },
      {
        start_time: 3208520,
        end_time: 3215520,
        duration: 7000,
        text: "one if you don't specify but know that you can specify what exact model we're going to use the embedding free large",
      },
      {
        start_time: 3215520,
        end_time: 3225160,
        duration: 9640,
        text: "that is going to produce a specific like the model uh produces a specific amount of",
      },
      {
        start_time: 3225160,
        end_time: 3231960,
        duration: 6800,
        text: "um the size of a vector so a large model not mistaken should be around I don't",
      },
      {
        start_time: 3231960,
        end_time: 3238078,
        duration: 6118,
        text: "know 2,000 or something like that um",
      },
      {
        start_time: 3239760,
        end_time: 3245359,
        duration: 5599,
        text: "dimensions of that Vector so the more Dimensions the more nuances it can",
      },
      {
        start_time: 3245359,
        end_time: 3253280,
        duration: 7921,
        text: "detect in the text but at the same time it's more data",
      },
      {
        start_time: 3253280,
        end_time: 3259520,
        duration: 6240,
        text: "to store larger it's more consuming okay so the thing is that now",
      },
      {
        start_time: 3259520,
        end_time: 3265680,
        duration: 6160,
        text: "that we have this model that can generate embeddings we need a store",
      },
      {
        start_time: 3265680,
        end_time: 3272799,
        duration: 7119,
        text: "somewhere to store that embedding that data with",
      },
      {
        start_time: 3272799,
        end_time: 3280839,
        duration: 8040,
        text: "embeddings what we can do if we look in the documentation we need to pick a vector store we need a storage solution",
      },
      {
        start_time: 3280839,
        end_time: 3287200,
        duration: 6361,
        text: "that can store these vectors not only they can store it but they can optimally",
      },
      {
        start_time: 3287200,
        end_time: 3292920,
        duration: 5720,
        text: "query based on similarity I'm going to start with memory because this is going to be the",
      },
      {
        start_time: 3292920,
        end_time: 3300640,
        duration: 7720,
        text: "easiest one it simply stores them in memory and to get started that's totally fine for us let's go ahead and import",
      },
      {
        start_time: 3300640,
        end_time: 3306640,
        duration: 6000,
        text: "memory Vector store from Vector store memory at the",
      },
      {
        start_time: 3306640,
        end_time: 3311720,
        duration: 5080,
        text: "top um and let's create the vector",
      },
      {
        start_time: 3311720,
        end_time: 3318960,
        duration: 7240,
        text: "store where we have our embeddings so this is the vector store new memory",
      },
      {
        start_time: 3318960,
        end_time: 3322960,
        duration: 4000,
        text: "Vector store and we send this embedding",
      },
      {
        start_time: 3324799,
        end_time: 3332400,
        duration: 7601,
        text: "model finally finally what we need to do give me one",
      },
      {
        start_time: 3332400,
        end_time: 3335520,
        duration: 3120,
        text: "second is",
      },
      {
        start_time: 3342200,
        end_time: 3350839,
        duration: 8639,
        text: "to um Let me let me think like how to to introduce this one slowly",
      },
      {
        start_time: 3367599,
        end_time: 3373559,
        duration: 5960,
        text: "okay so what we need to do is say hey await Vector store add documents and",
      },
      {
        start_time: 3373559,
        end_time: 3383000,
        duration: 9441,
        text: "we're going to add the chunks that we generated here as simple as that",
      },
      {
        start_time: 3387119,
        end_time: 3394000,
        duration: 6881,
        text: "um how to visualize it that's another question because yeah let's try right",
      },
      {
        start_time: 3394000,
        end_time: 3399039,
        duration: 5039,
        text: "now like vector",
      },
      {
        start_time: 3401680,
        end_time: 3410440,
        duration: 8760,
        text: "store let's try to Simply run our project with no DMV file we see a",
      },
      {
        start_time: 3410960,
        end_time: 3417880,
        duration: 6920,
        text: "problem package Json reader cannot find L chain input",
      },
      {
        start_time: 3417880,
        end_time: 3424319,
        duration: 6439,
        text: "imported I think uh we also need to install length chain like this without",
      },
      {
        start_time: 3424319,
        end_time: 3429200,
        duration: 4881,
        text: "ad npmi length",
      },
      {
        start_time: 3432760,
        end_time: 3440079,
        duration: 7319,
        text: "chain okay perfect let's now try to invoke the agent",
      },
      {
        start_time: 3440079,
        end_time: 3446200,
        duration: 6121,
        text: "again and we don't see any errors that means that everything went fine uh which",
      },
      {
        start_time: 3446200,
        end_time: 3452480,
        duration: 6280,
        text: "chunks should be should have been embedded and wrote to the database",
      },
      {
        start_time: 3452480,
        end_time: 3457640,
        duration: 5160,
        text: "but we do not have like we do not see it like how can we visualize what's",
      },
      {
        start_time: 3457640,
        end_time: 3463440,
        duration: 5800,
        text: "happening there well that's because we have simply done",
      },
      {
        start_time: 3463440,
        end_time: 3472480,
        duration: 9040,
        text: "the first step of indexing loading the data splitting generating embeddings and storing the data the next part is the",
      },
      {
        start_time: 3472480,
        end_time: 3480640,
        duration: 8160,
        text: "retrieving and generating let's go ahead and see how we can retrieve documents from our database",
      },
      {
        start_time: 3480640,
        end_time: 3486839,
        duration: 6199,
        text: "that are similar to a question to do that let's go ahead and say",
      },
      {
        start_time: 3486839,
        end_time: 3494960,
        duration: 8121,
        text: "here uh retrieve the most relevant",
      },
      {
        start_time: 3502039,
        end_time: 3509119,
        duration: 7080,
        text: "chunks so what we are going to do is we're going to say a docs equal a wait",
      },
      {
        start_time: 3509119,
        end_time: 3515400,
        duration: 6281,
        text: "Vector store we're going to work with this Vector store we're going to do a similarity",
      },
      {
        start_time: 3515400,
        end_time: 3521799,
        duration: 6399,
        text: "search a similarity search uh because we index the table",
      },
      {
        start_time: 3521799,
        end_time: 3529960,
        duration: 8161,
        text: "the the data from qualifying let's",
      },
      {
        start_time: 3533240,
        end_time: 3539760,
        duration: 6520,
        text: "do what season is this Sprint",
      },
      {
        start_time: 3539760,
        end_time: 3547480,
        duration: 7720,
        text: "in I'm going to ask send a question",
      },
      {
        start_time: 3547480,
        end_time: 3553160,
        duration: 5680,
        text: "relative similar to the context of a video and I'm going to do a similarity",
      },
      {
        start_time: 3553160,
        end_time: 3559440,
        duration: 6280,
        text: "search meaning that I'm going to find the chunks that are more similar to this",
      },
      {
        start_time: 3559440,
        end_time: 3567000,
        duration: 7560,
        text: "question so let's see what is going to be the answer uh dogs we already have it right",
      },
      {
        start_time: 3567000,
        end_time: 3572920,
        duration: 5920,
        text: "so retrieved docs let's do it like this and we say",
      },
      {
        start_time: 3572920,
        end_time: 3579920,
        duration: 7000,
        text: "give me five docs if I run the agent",
      },
      {
        start_time: 3579920,
        end_time: 3586160,
        duration: 6240,
        text: "again what we're going to see",
      },
      {
        start_time: 3586160,
        end_time: 3593039,
        duration: 6879,
        text: "is the",
      },
      {
        start_time: 3593599,
        end_time: 3598680,
        duration: 5081,
        text: "documents where at the top is the most most similar one I was expecting to see",
      },
      {
        start_time: 3598680,
        end_time: 3607160,
        duration: 8480,
        text: "also the actual similarity because here how do I prove you that it's",
      },
      {
        start_time: 3607160,
        end_time: 3611000,
        duration: 3840,
        text: "working what if",
      },
      {
        start_time: 3619480,
        end_time: 3624599,
        duration: 5119,
        text: "I something from the end",
      },
      {
        start_time: 3628270,
        end_time: 3631400,
        duration: 3130,
        text: "[Music]",
      },
      {
        start_time: 3637359,
        end_time: 3645240,
        duration: 7881,
        text: "what was the finish time of",
      },
      {
        start_time: 3645839,
        end_time: 3653480,
        duration: 7641,
        text: "Norris uh and I'm going to select one and before that I'm going to console",
      },
      {
        start_time: 3653480,
        end_time: 3662038,
        duration: 8558,
        text: "log the chunks and here I'm going to console log this one but I'm also going to have",
      },
      {
        start_time: 3663520,
        end_time: 3669039,
        duration: 5519,
        text: "like so that we see let's go ahead and try to run it",
      },
      {
        start_time: 3669039,
        end_time: 3675480,
        duration: 6441,
        text: "again initially the documents are in chronological order from the",
      },
      {
        start_time: 3675480,
        end_time: 3681039,
        duration: 5559,
        text: "beginning uh the first one is personal best through the sector and so",
      },
      {
        start_time: 3681039,
        end_time: 3687720,
        duration: 6681,
        text: "one and at the end we do a similarity search for for the question what is the",
      },
      {
        start_time: 3687720,
        end_time: 3693240,
        duration: 5520,
        text: "Norris end time and we see that here it's the document that is most related",
      },
      {
        start_time: 3693240,
        end_time: 3699960,
        duration: 6720,
        text: "to the the the finish time of Norris so we can use this text to try to answer",
      },
      {
        start_time: 3699960,
        end_time: 3704920,
        duration: 4960,
        text: "that question by move putting it through an",
      },
      {
        start_time: 3705400,
        end_time: 3710559,
        duration: 5159,
        text: "llm uh again this is the similarity search uh let me see if I can actually",
      },
      {
        start_time: 3710559,
        end_time: 3716599,
        duration: 6040,
        text: "get query filter call backs",
      },
      {
        start_time: 3726279,
        end_time: 3735079,
        duration: 8800,
        text: "yeah it doesn't give us the exact like uh similarity value but that's good it at least does",
      },
      {
        start_time: 3735079,
        end_time: 3738839,
        duration: 3760,
        text: "the similarity search",
      },
      {
        start_time: 3747599,
        end_time: 3753920,
        duration: 6321,
        text: "so what can we do here now that we",
      },
      {
        start_time: 3753920,
        end_time: 3762520,
        duration: 8600,
        text: "can having a query a question if we can find similar part similar",
      },
      {
        start_time: 3762520,
        end_time: 3769960,
        duration: 7440,
        text: "transcripts from the video we can use them put them through uh the llm here in",
      },
      {
        start_time: 3769960,
        end_time: 3775880,
        duration: 5920,
        text: "the agent so that it's going to use it to create the answer for example if my",
      },
      {
        start_time: 3775880,
        end_time: 3780920,
        duration: 5040,
        text: "my question here is going to be what was the finished time of",
      },
      {
        start_time: 3780920,
        end_time: 3787079,
        duration: 6159,
        text: "Norris it's not going to be able to to give me a proper result uh",
      },
      {
        start_time: 3787079,
        end_time: 3795799,
        duration: 8720,
        text: "answer because this llm the agent does not yet have access to our Vector",
      },
      {
        start_time: 3796039,
        end_time: 3801640,
        duration: 5601,
        text: "database or not provide the information I have",
      },
      {
        start_time: 3807359,
        end_time: 3812480,
        duration: 5121,
        text: "so let's go ahead and build a tool that",
      },
      {
        start_time: 3812480,
        end_time: 3819680,
        duration: 7200,
        text: "can use the vector store to retrieve the right information building a tool is also",
      },
      {
        start_time: 3819680,
        end_time: 3824720,
        duration: 5040,
        text: "greatly documented and explained in our previous tutorial build and deploy your",
      },
      {
        start_time: 3824720,
        end_time: 3830440,
        duration: 5720,
        text: "first AI agent with langra",
      },
      {
        start_time: 3830760,
        end_time: 3837240,
        duration: 6480,
        text: "um yeah this is the tool so what we need to do is import this",
      },
      {
        start_time: 3837240,
        end_time: 3844599,
        duration: 7359,
        text: "tool at the top let's import the tool and we are going to create",
      },
      {
        start_time: 3844839,
        end_time: 3851039,
        duration: 6200,
        text: "it maybe here",
      },
      {
        start_time: 3851039,
        end_time: 3858440,
        duration: 7401,
        text: "retrieval tool const retrieve tool is equal to",
      },
      {
        start_time: 3858440,
        end_time: 3864440,
        duration: 6000,
        text: "Tool and we create it like this we're going to have an",
      },
      {
        start_time: 3864440,
        end_time: 3872279,
        duration: 7839,
        text: "async and it should return something a tool has two two parameters the first",
      },
      {
        start_time: 3872279,
        end_time: 3877720,
        duration: 5441,
        text: "one is the actual function that is going to run the second one is going to be",
      },
      {
        start_time: 3877720,
        end_time: 3883839,
        duration: 6119,
        text: "some metadata about the to Tool let's call give it a name retrieve and we need",
      },
      {
        start_time: 3883839,
        end_time: 3890760,
        duration: 6921,
        text: "to also give it a description description is very important because that's how the llm will know what is",
      },
      {
        start_time: 3890760,
        end_time: 3898000,
        duration: 7240,
        text: "this tool supposed to do and when should it be used uh here retrieve most relevant uh",
      },
      {
        start_time: 3898000,
        end_time: 3903119,
        duration: 5119,
        text: "relevant chunks of text from the",
      },
      {
        start_time: 3903119,
        end_time: 3909279,
        duration: 6160,
        text: "transcript of a YouTube video something like",
      },
      {
        start_time: 3909279,
        end_time: 3915079,
        duration: 5800,
        text: "that it's also important to provide here a schema a",
      },
      {
        start_time: 3915079,
        end_time: 3921319,
        duration: 6240,
        text: "schema we are going to Define it with Zod so let's go at the top and import Z",
      },
      {
        start_time: 3921319,
        end_time: 3929480,
        duration: 8161,
        text: "from Zod and Zod is a tool that can create help us create schemas of how object",
      },
      {
        start_time: 3929480,
        end_time: 3935240,
        duration: 5760,
        text: "should look like and a tool needs a schema so that the llm knows what inputs",
      },
      {
        start_time: 3935240,
        end_time: 3941079,
        duration: 5839,
        text: "what data to send there let's say that the schema is going to be an",
      },
      {
        start_time: 3941160,
        end_time: 3948920,
        duration: 7760,
        text: "object and there will be a query and the query is going to be a",
      },
      {
        start_time: 3948920,
        end_time: 3956200,
        duration: 7280,
        text: "string this query now that we added it here is going to be accessible through the tool execution function so we can",
      },
      {
        start_time: 3956200,
        end_time: 3962119,
        duration: 5919,
        text: "have query and here we can say hey console",
      },
      {
        start_time: 3962119,
        end_time: 3968880,
        duration: 6761,
        text: "console oh come on console.log retrieve dogs for the query",
      },
      {
        start_time: 3968880,
        end_time: 3976520,
        duration: 7640,
        text: "console log query I'm not going to do a similarity search yet let's just return",
      },
      {
        start_time: 3976520,
        end_time: 3982000,
        duration: 5480,
        text: "an empty string noris was",
      },
      {
        start_time: 3982000,
        end_time: 3990079,
        duration: 8079,
        text: "first finishing in uh 33 seconds which is impossible but",
      },
      {
        start_time: 3990079,
        end_time: 3997440,
        duration: 7361,
        text: "it's a way for us to test if this tool was invoked or not now if we take this tool and we give",
      },
      {
        start_time: 3997440,
        end_time: 4004680,
        duration: 7240,
        text: "it to our agent inside the tools here the agent will know that hey I have",
      },
      {
        start_time: 4004680,
        end_time: 4011359,
        duration: 6679,
        text: "a tool that has this description it can retrieve the most relevant chunks of text from the video transcript it will",
      },
      {
        start_time: 4011359,
        end_time: 4017640,
        duration: 6281,
        text: "say that it's a question that might benefit from this information it's going",
      },
      {
        start_time: 4017640,
        end_time: 4024039,
        duration: 6399,
        text: "to look at the schema and it's going to create a query and it's going to call this tool then is going to get back",
      },
      {
        start_time: 4024039,
        end_time: 4033440,
        duration: 9401,
        text: "result and we'll analyze and see what to do next let's go ahead and see what actually is happening now I'm going to",
      },
      {
        start_time: 4033440,
        end_time: 4038680,
        duration: 5240,
        text: "maybe comment out the logs that we did",
      },
      {
        start_time: 4038799,
        end_time: 4045359,
        duration: 6560,
        text: "before and I'm going to invoke our agent",
      },
      {
        start_time: 4048160,
        end_time: 4050558,
        duration: 2398,
        text: "that was",
      },
      {
        start_time: 4054319,
        end_time: 4062160,
        duration: 7841,
        text: "bad so what do we see based on the transcript information I found noris finished in 33 seconds and was first",
      },
      {
        start_time: 4062160,
        end_time: 4069599,
        duration: 7439,
        text: "place that's exactly what we kind of said like it's not the right information",
      },
      {
        start_time: 4069599,
        end_time: 4075799,
        duration: 6200,
        text: "but where is it our question to our agent was what",
      },
      {
        start_time: 4075799,
        end_time: 4082160,
        duration: 6361,
        text: "was the finish time of Norris you see this is what we are",
      },
      {
        start_time: 4082160,
        end_time: 4089279,
        duration: 7119,
        text: "asking then LM analyze this question and is invoking the retrieve tool and in the",
      },
      {
        start_time: 4089279,
        end_time: 4096520,
        duration: 7241,
        text: "retrieve tool we are doing here console log query the query is already different because the llm was smart enough to",
      },
      {
        start_time: 4096520,
        end_time: 4102600,
        duration: 6080,
        text: "change it in a way to get the data that it needs so it simply changed it to noris finished",
      },
      {
        start_time: 4102600,
        end_time: 4109719,
        duration: 7119,
        text: "time that's what an agent that's how an agent improves a rag",
      },
      {
        start_time: 4109719,
        end_time: 4114758,
        duration: 5039,
        text: "system because the question is can you build an rag system without an agent",
      },
      {
        start_time: 4114759,
        end_time: 4119880,
        duration: 5121,
        text: "invance is totally yes you can build a normal",
      },
      {
        start_time: 4119880,
        end_time: 4128000,
        duration: 8120,
        text: "um uh flow AI flow for an Rec system without this agent inside it's simply",
      },
      {
        start_time: 4128000,
        end_time: 4134960,
        duration: 6960,
        text: "doing it step by step in a sequence first get data when generate embeddings then get similarities then create the",
      },
      {
        start_time: 4134960,
        end_time: 4143120,
        duration: 8160,
        text: "prompt and then send it to the llm a lot of things can be done manually and in sequence but having an llm here we see",
      },
      {
        start_time: 4143120,
        end_time: 4148758,
        duration: 5638,
        text: "the first benefit is that the question that we ask is going to",
      },
      {
        start_time: 4148759,
        end_time: 4154400,
        duration: 5641,
        text: "actually be transformed to something that is going to make a lot more sense for the AI to get the",
      },
      {
        start_time: 4154400,
        end_time: 4160278,
        duration: 5878,
        text: "data and we see that we faked some data here so in the retrieval tool we just",
      },
      {
        start_time: 4160279,
        end_time: 4167758,
        duration: 7479,
        text: "said no resource first and finish in 33 seconds and then having this information llm generated the final answer that we",
      },
      {
        start_time: 4167759,
        end_time: 4173560,
        duration: 5801,
        text: "see here in their response perfect but let's go ahead and",
      },
      {
        start_time: 4173560,
        end_time: 4180920,
        duration: 7360,
        text: "having this query let's do this retrieval of docs because we have a query we have a",
      },
      {
        start_time: 4180920,
        end_time: 4191278,
        duration: 10358,
        text: "vector store we can use the query inside a similarity search",
      },
      {
        start_time: 4191279,
        end_time: 4200000,
        duration: 8721,
        text: "we can search how many chunks are do you think would be Rel let's do three chunks maybe it's going",
      },
      {
        start_time: 4200000,
        end_time: 4205480,
        duration: 5480,
        text: "to to be in three different places at the same time the llm can call this over",
      },
      {
        start_time: 4205480,
        end_time: 4211760,
        duration: 6280,
        text: "and over again for to get all the response so F3 or maybe F5 probably is",
      },
      {
        start_time: 4211760,
        end_time: 4217719,
        duration: 5959,
        text: "going to be enough so now that we retrieve the docks",
      },
      {
        start_time: 4227840,
        end_time: 4234920,
        duration: 7080,
        text: "um let's put the them in a Ser alized",
      },
      {
        start_time: 4234920,
        end_time: 4242400,
        duration: 7480,
        text: "dogs meaning let's merge them together and what I'm going to do is I'm going to",
      },
      {
        start_time: 4242400,
        end_time: 4249120,
        duration: 6720,
        text: "do retrieve dock so for every doc",
      },
      {
        start_time: 4249120,
        end_time: 4253120,
        duration: 4000,
        text: "let's return",
      },
      {
        start_time: 4258840,
        end_time: 4267520,
        duration: 8680,
        text: "I don't know content doc. page",
      },
      {
        start_time: 4270040,
        end_time: 4276560,
        duration: 6520,
        text: "content do Doc Page content and at the end I'm going to put up dashn to say",
      },
      {
        start_time: 4276560,
        end_time: 4281239,
        duration: 4679,
        text: "that it's the end",
      },
      {
        start_time: 4290600,
        end_time: 4297920,
        duration: 7320,
        text: "or maybe I'll simply do let's let's simplify it so I'm going to map for the documents",
      },
      {
        start_time: 4297920,
        end_time: 4304159,
        duration: 6239,
        text: "I'm going to leave an array of Simply the content and I'm going to do a DOT",
      },
      {
        start_time: 4304159,
        end_time: 4309760,
        duration: 5601,
        text: "join with a dashn basically what I'm doing here is",
      },
      {
        start_time: 4309760,
        end_time: 4315760,
        duration: 6000,
        text: "I'm taking five or three docs that we get and put them in one single text",
      },
      {
        start_time: 4315760,
        end_time: 4323480,
        duration: 7720,
        text: "and I can take the serialized docs and return it here uh to back to the llm now if I'm",
      },
      {
        start_time: 4323480,
        end_time: 4328800,
        duration: 5320,
        text: "going to go ahead and execute the same query again it's supposed to base its",
      },
      {
        start_time: 4328800,
        end_time: 4336760,
        duration: 7960,
        text: "answer from the transcript that we actually fetched so this is the query that our",
      },
      {
        start_time: 4336760,
        end_time: 4344120,
        duration: 7360,
        text: "tool received and we see based on the information retrieve from the video transcript L is finish in six position",
      },
      {
        start_time: 4344120,
        end_time: 4350800,
        duration: 6680,
        text: "in what appears to be a Sprint qualifying session the transcript mentions Hamilton versus upb cler",
      },
      {
        start_time: 4350800,
        end_time: 4356600,
        duration: 5800,
        text: "Russell Norris in six we listening the order of drivers so you see it generated",
      },
      {
        start_time: 4356600,
        end_time: 4365800,
        duration: 9200,
        text: "an answer based on the transcript so that's in a way our whole rag AI agent",
      },
      {
        start_time: 4365800,
        end_time: 4372280,
        duration: 6480,
        text: "complete uh if we look at this we started with indexing first and now we",
      },
      {
        start_time: 4372280,
        end_time: 4377520,
        duration: 5240,
        text: "have this retrieval and generation having a question from a",
      },
      {
        start_time: 4377520,
        end_time: 4383080,
        duration: 5560,
        text: "user we provide a tool that can retrieve relevant information from",
      },
      {
        start_time: 4383080,
        end_time: 4389400,
        duration: 6320,
        text: "transcripts from our Vector database and then using an llm like entropic we are",
      },
      {
        start_time: 4389400,
        end_time: 4397080,
        duration: 7680,
        text: "generating the answer here perfect",
      },
      {
        start_time: 4401000,
        end_time: 4407719,
        duration: 6719,
        text: "now let me go ahead um and initialize a",
      },
      {
        start_time: 4407719,
        end_time: 4416480,
        duration: 8761,
        text: "git so you're going to have access because this is the base but we are just getting started guys let's do get add",
      },
      {
        start_time: 4416480,
        end_time: 4425360,
        duration: 8880,
        text: "git commit uh basic AI agent with",
      },
      {
        start_time: 4433239,
        end_time: 4440360,
        duration: 7121,
        text: "rag um what's",
      },
      {
        start_time: 4443679,
        end_time: 4450320,
        duration: 6641,
        text: "happening let me check the the live chat if you have any questions feel free to to ask them I'm going to stop from time",
      },
      {
        start_time: 4450320,
        end_time: 4454440,
        duration: 4120,
        text: "to time to answer",
      },
      {
        start_time: 4456880,
        end_time: 4462560,
        duration: 5680,
        text: "them I'm already building a project like this amazing I had not started to do the",
      },
      {
        start_time: 4462560,
        end_time: 4467679,
        duration: 5119,
        text: "video file pipeline yet so this is perfect this is a video file uh we are",
      },
      {
        start_time: 4467679,
        end_time: 4473600,
        duration: 5921,
        text: "not working with video files we're working with transcripts of the",
      },
      {
        start_time: 4476000,
        end_time: 4483560,
        duration: 7560,
        text: "videos Sprint but you said spring not sure",
      },
      {
        start_time: 4483560,
        end_time: 4489480,
        duration: 5920,
        text: "when oh it uses transcript that's how my project currently works yeah perfect",
      },
      {
        start_time: 4489480,
        end_time: 4495920,
        duration: 6440,
        text: "what is rag rag as I was explaining earlier is",
      },
      {
        start_time: 4495920,
        end_time: 4503360,
        duration: 7440,
        text: "so we have an llm an llm is great at generating text that's how it answers",
      },
      {
        start_time: 4503360,
        end_time: 4510840,
        duration: 7480,
        text: "questions you give it some text which can be a question and it tries to predict what should be the next part of",
      },
      {
        start_time: 4510840,
        end_time: 4516719,
        duration: 5879,
        text: "a text meaning an answer it's very good at understanding language and at",
      },
      {
        start_time: 4516719,
        end_time: 4523840,
        duration: 7121,
        text: "predicting what comes next and it's very good at general information but it's not very good at very specific information",
      },
      {
        start_time: 4523840,
        end_time: 4529880,
        duration: 6040,
        text: "that either my not be public or it can be information that is super up to date",
      },
      {
        start_time: 4529880,
        end_time: 4535800,
        duration: 5920,
        text: "like what is today's we in AI llm will not have that",
      },
      {
        start_time: 4535800,
        end_time: 4545679,
        duration: 9879,
        text: "information so what we are doing is we are giving AI access to a data source",
      },
      {
        start_time: 4545679,
        end_time: 4552600,
        duration: 6921,
        text: "that we can uh index on the similarity based on",
      },
      {
        start_time: 4552600,
        end_time: 4559120,
        duration: 6520,
        text: "a search term for example you have a documentation",
      },
      {
        start_time: 4559120,
        end_time: 4567960,
        duration: 8840,
        text: "website and you want to build a chatbot that users can write how to initialize a new project the chatbot will first look",
      },
      {
        start_time: 4567960,
        end_time: 4574280,
        duration: 6320,
        text: "through all the the documentation pages and will find the documentation pages",
      },
      {
        start_time: 4574280,
        end_time: 4581000,
        duration: 6720,
        text: "that are more relevant to the question how to initialize a project it might find two to three very relevant",
      },
      {
        start_time: 4581000,
        end_time: 4587800,
        duration: 6800,
        text: "documentations it's going to use the information from V it's going to put it through the llm back saying hey this is",
      },
      {
        start_time: 4587800,
        end_time: 4593560,
        duration: 5760,
        text: "what user is asking this is what documentations we have provide an answer",
      },
      {
        start_time: 4593560,
        end_time: 4599520,
        duration: 5960,
        text: "to that question so this part of injecting this data retrieving the data",
      },
      {
        start_time: 4599520,
        end_time: 4607600,
        duration: 8080,
        text: "is the what makes it a rag system and allows it to be powerful in",
      },
      {
        start_time: 4607600,
        end_time: 4612920,
        duration: 5320,
        text: "order to know like more data more relevant data that you that you might",
      },
      {
        start_time: 4612920,
        end_time: 4616840,
        duration: 3920,
        text: "need for specific use cases",
      },
      {
        start_time: 4619600,
        end_time: 4625480,
        duration: 5880,
        text: "so llm we access to additional data",
      },
      {
        start_time: 4649159,
        end_time: 4657120,
        duration: 7961,
        text: "have you figure out how to prompt cash how to prompt cash with transcripts",
      },
      {
        start_time: 4657120,
        end_time: 4662880,
        duration: 5760,
        text: "in this setup what do you mean by that prompt prompt C",
      },
      {
        start_time: 4663320,
        end_time: 4671560,
        duration: 8240,
        text: "cash let me know okay so we have our agent that",
      },
      {
        start_time: 4671560,
        end_time: 4681120,
        duration: 9560,
        text: "where is it at current is doing a lot of stuff it's loading data from from our",
      },
      {
        start_time: 4681120,
        end_time: 4686960,
        duration: 5840,
        text: "dam data there it's splitting it it's uh",
      },
      {
        start_time: 4686960,
        end_time: 4693440,
        duration: 6480,
        text: "adding it to a vector database by embedding so a lot of things are happening here behind the scene behind",
      },
      {
        start_time: 4693440,
        end_time: 4701520,
        duration: 8080,
        text: "this line documents it's not simply inserting it to the database but it's first generating these embeddings using",
      },
      {
        start_time: 4701520,
        end_time: 4708760,
        duration: 7240,
        text: "the open AI model uh because having them inside a vector",
      },
      {
        start_time: 4708760,
        end_time: 4715600,
        duration: 6840,
        text: "store we can later retrieve them based on a similarity search basically hey",
      },
      {
        start_time: 4715600,
        end_time: 4724198,
        duration: 8598,
        text: "having this text what is the most similar document for for for that text and similar in in terms of",
      },
      {
        start_time: 4724560,
        end_time: 4732080,
        duration: 7520,
        text: "context so we build a tool and we build an agent we give that agent V tool that",
      },
      {
        start_time: 4732080,
        end_time: 4737520,
        duration: 5440,
        text: "can retrieve documents perfect in The Next Step we're going to clean it",
      },
      {
        start_time: 4737520,
        end_time: 4745320,
        duration: 7800,
        text: "up a bit and start thinking about like how to move it closer to a production R application and system that that can run",
      },
      {
        start_time: 4745320,
        end_time: 4750480,
        duration: 5160,
        text: "on autopilot with multiple um with multiple videos with a",
      },
      {
        start_time: 4750480,
        end_time: 4756040,
        duration: 5560,
        text: "proper database because right now we are using the memory Vector store in memory",
      },
      {
        start_time: 4756040,
        end_time: 4762960,
        duration: 6920,
        text: "Vector store storing this data in memory and as soon as I stop the the server",
      },
      {
        start_time: 4762960,
        end_time: 4769800,
        duration: 6840,
        text: "it's lost so for AI there is prom caching where",
      },
      {
        start_time: 4769800,
        end_time: 4775080,
        duration: 5280,
        text: "the llm will cache your input so it can be can be reused so like with Claude",
      },
      {
        start_time: 4775080,
        end_time: 4781000,
        duration: 5920,
        text: "your cached input is like if the input is $1 the cached input will",
      },
      {
        start_time: 4781000,
        end_time: 4790480,
        duration: 9480,
        text: "be 115 but then you send the same thing again into cash so the input is like 20",
      },
      {
        start_time: 4792920,
        end_time: 4801719,
        duration: 8799,
        text: "cents yeah not sure not sure how this is going to work here I would have to look into",
      },
      {
        start_time: 4810760,
        end_time: 4816360,
        duration: 5600,
        text: "that okayy dokie okay",
      },
      {
        start_time: 4838360,
        end_time: 4844120,
        duration: 5760,
        text: "uh one second guys let me think about something",
      },
      {
        start_time: 4872159,
        end_time: 4877320,
        duration: 5161,
        text: "um next let me show you a small problem and fix it together with you for example",
      },
      {
        start_time: 4877320,
        end_time: 4882560,
        duration: 5240,
        text: "we are asking the first question let's do it like this uh",
      },
      {
        start_time: 4882560,
        end_time: 4890440,
        duration: 7880,
        text: "console log q1 is going to be this one and what if",
      },
      {
        start_time: 4890440,
        end_time: 4896840,
        duration: 6400,
        text: "we go ahead and ask the question two which is going to",
      },
      {
        start_time: 4896840,
        end_time: 4902760,
        duration: 5920,
        text: "be what is the finish time of very stop and I don't know finish",
      },
      {
        start_time: 4902760,
        end_time: 4912120,
        duration: 9360,
        text: "time or position or no let's do it in another way let's do what about ver",
      },
      {
        start_time: 4912120,
        end_time: 4920560,
        duration: 8440,
        text: "stopen and here what was the uh finish",
      },
      {
        start_time: 4920760,
        end_time: 4926480,
        duration: 5720,
        text: "position and time what I'm trying to do here and let's do results two and here",
      },
      {
        start_time: 4926480,
        end_time: 4932800,
        duration: 6320,
        text: "results two is I'm trying to simulate asking a follow-up question a followup",
      },
      {
        start_time: 4932800,
        end_time: 4941880,
        duration: 9080,
        text: "question might not have all the context I mean a good chat AI agent will REM",
      },
      {
        start_time: 4941880,
        end_time: 4948000,
        duration: 6120,
        text: "will understand that a question like this what about stopen is not",
      },
      {
        start_time: 4948000,
        end_time: 4955920,
        duration: 7920,
        text: "is is connected with a previous question so it should be something like finish position over stoen in order for that to",
      },
      {
        start_time: 4955920,
        end_time: 4961159,
        duration: 5239,
        text: "happen our agent should have short-term memory knowing uh or actually long-term",
      },
      {
        start_time: 4961159,
        end_time: 4967920,
        duration: 6761,
        text: "memory uh having context about like previous messages in the Fred because if",
      },
      {
        start_time: 4967920,
        end_time: 4976440,
        duration: 8520,
        text: "I do that right now if I'm not mistaken uh let me do CD ser",
      },
      {
        start_time: 4978639,
        end_time: 4984360,
        duration: 5721,
        text: "server let's do node and invoke it it should answer",
      },
      {
        start_time: 4984360,
        end_time: 4990400,
        duration: 6040,
        text: "correctly the first the question one what is the finished",
      },
      {
        start_time: 4997320,
        end_time: 5003639,
        duration: 6319,
        text: "position it failed to actually invoke the tool there",
      },
      {
        start_time: 5009440,
        end_time: 5014800,
        duration: 5360,
        text: "and in the cute question two about your stomping why did it ask about Norris",
      },
      {
        start_time: 5014800,
        end_time: 5017119,
        duration: 2319,
        text: "wait a",
      },
      {
        start_time: 5028800,
        end_time: 5036320,
        duration: 7520,
        text: "second that's a bit weird because when I asked about ver St and it started doing about noris",
      },
      {
        start_time: 5036320,
        end_time: 5043000,
        duration: 6680,
        text: "uh oh oh oh oh oh oh oh because I'm stupid let's do what about we're",
      },
      {
        start_time: 5043000,
        end_time: 5048880,
        duration: 5880,
        text: "stopping here I left literally the same",
      },
      {
        start_time: 5050679,
        end_time: 5056440,
        duration: 5761,
        text: "question based on video",
      },
      {
        start_time: 5058800,
        end_time: 5063360,
        duration: 4560,
        text: "transcript let's try again",
      },
      {
        start_time: 5068560,
        end_time: 5075920,
        duration: 7360,
        text: "so for this question it invokes the tool it asks for noris finish",
      },
      {
        start_time: 5078119,
        end_time: 5083960,
        duration: 5841,
        text: "time it doesn't like the response it invokes it again nor is final time",
      },
      {
        start_time: 5083960,
        end_time: 5089280,
        duration: 5320,
        text: "position oh no no no it understand that it this question finish position and",
      },
      {
        start_time: 5089280,
        end_time: 5094440,
        duration: 5160,
        text: "time it split automatically in two requests one is noris finish time and",
      },
      {
        start_time: 5094440,
        end_time: 5099639,
        duration: 5199,
        text: "another one noris final time position result amazing and",
      },
      {
        start_time: 5099639,
        end_time: 5108719,
        duration: 9080,
        text: "then by invoking by by retrieving two sets of data it was able to say",
      },
      {
        start_time: 5108719,
        end_time: 5114520,
        duration: 5801,
        text: "that yeah there is no specific time there in numerical",
      },
      {
        start_time: 5118440,
        end_time: 5125040,
        duration: 6600,
        text: "format and here what about verstappen and what it says I'd be happy to help you find information about m versten",
      },
      {
        start_time: 5125040,
        end_time: 5130800,
        duration: 5760,
        text: "however I need to search for YouTube video transfer for could you please clarify what specific aspect about ma",
      },
      {
        start_time: 5130800,
        end_time: 5135840,
        duration: 5040,
        text: "Sten you're interested in so here we understand that when we asked second",
      },
      {
        start_time: 5135840,
        end_time: 5142080,
        duration: 6240,
        text: "time a follow-up question what about resten it did not connect it with a first question and he did not understand",
      },
      {
        start_time: 5142080,
        end_time: 5147400,
        duration: 5320,
        text: "that we mean like finish position in time it's not clear here it's for us",
      },
      {
        start_time: 5147400,
        end_time: 5154679,
        duration: 7279,
        text: "it's clear that the AI doesn't connect the two questions together that it's the same interaction for that to happen we",
      },
      {
        start_time: 5154679,
        end_time: 5160320,
        duration: 5641,
        text: "need to provide here to the agent a long-term memory a",
      },
      {
        start_time: 5160320,
        end_time: 5169000,
        duration: 8680,
        text: "checkpoint so again in the previous tutorial I have here adding memory to our agent and we can do that by",
      },
      {
        start_time: 5169000,
        end_time: 5174320,
        duration: 5320,
        text: "importing memory from linkchain L graph at the",
      },
      {
        start_time: 5176440,
        end_time: 5185520,
        duration: 9080,
        text: "top and somewhere here where we create the agent we can say a memory saver and",
      },
      {
        start_time: 5185520,
        end_time: 5194360,
        duration: 8840,
        text: "we're going to give it here as if I'm not mistaken is check pointer memory saver check",
      },
      {
        start_time: 5194679,
        end_time: 5203560,
        duration: 8881,
        text: "pointer memory saver or if you want to save on some characters you can call it here",
      },
      {
        start_time: 5203560,
        end_time: 5209639,
        duration: 6079,
        text: "checkpoint and remove a duplicated because it's the same name now because",
      },
      {
        start_time: 5209639,
        end_time: 5215560,
        duration: 5921,
        text: "it has a checkpoint we are not going to be able to invoke it like this and if we do if I'm not mistaken we're going to",
      },
      {
        start_time: 5215560,
        end_time: 5221639,
        duration: 6079,
        text: "have an error saying that now you have a checkpoint we need to provide them um a",
      },
      {
        start_time: 5221639,
        end_time: 5228040,
        duration: 6401,
        text: "configuration with a Fred ID so using a Fred ID we're going to know like what",
      },
      {
        start_time: 5228040,
        end_time: 5235360,
        duration: 7320,
        text: "other previous messages to connect it with and that is going to happen when we call agent.",
      },
      {
        start_time: 5235360,
        end_time: 5241840,
        duration: 6480,
        text: "invoke uh after the whole invocation we",
      },
      {
        start_time: 5241840,
        end_time: 5250360,
        duration: 8520,
        text: "are going to have here a conf configurable options with configurable and here we're going to have Fred ID",
      },
      {
        start_time: 5250360,
        end_time: 5256360,
        duration: 6000,
        text: "let's say like I don't know Fred number one I'm going to take this options and",
      },
      {
        start_time: 5256360,
        end_time: 5261480,
        duration: 5120,
        text: "I'm going to add it to the second invocation as well that way connecting",
      },
      {
        start_time: 5261480,
        end_time: 5269639,
        duration: 8159,
        text: "them together and pay attention where I am adding them this is actually after the object that has a messages it's not",
      },
      {
        start_time: 5269639,
        end_time: 5276159,
        duration: 6520,
        text: "besides it so it's two different objects now if I'm going to send the same",
      },
      {
        start_time: 5276159,
        end_time: 5281520,
        duration: 5361,
        text: "request here what I expect is that the second question will understand that",
      },
      {
        start_time: 5281520,
        end_time: 5288080,
        duration: 6560,
        text: "it's a follow up for the first one so it will understand that I'm asking about finish time and position for where",
      },
      {
        start_time: 5288080,
        end_time: 5293880,
        duration: 5800,
        text: "stoping and we see that indeed it understood so it's doing a search query",
      },
      {
        start_time: 5293880,
        end_time: 5298760,
        duration: 4880,
        text: "in our tool forward stop and finish time and position",
      },
      {
        start_time: 5299040,
        end_time: 5306560,
        duration: 7520,
        text: "results uh finished second place right behind Lou Hamilton amazing so that's uh",
      },
      {
        start_time: 5306560,
        end_time: 5313719,
        duration: 7159,
        text: "not amazing that he finished second uh not a big fan but amazing that it's working so just by simply adding this",
      },
      {
        start_time: 5313719,
        end_time: 5319800,
        duration: 6081,
        text: "checkpoint that's what we managed to do adding like more configuration",
      },
      { start_time: 5320480, end_time: 5323480, duration: 3000, text: "here" },
      {
        start_time: 5325520,
        end_time: 5332320,
        duration: 6800,
        text: "um another thing that we can do here uh when we invoke in the",
      },
      {
        start_time: 5332320,
        end_time: 5338800,
        duration: 6480,
        text: "configurable we can send more metadata things like let's say the video",
      },
      {
        start_time: 5338800,
        end_time: 5346639,
        duration: 7839,
        text: "ID that we are querying for video uncore ID is going to be equal to let's go into",
      },
      {
        start_time: 5346639,
        end_time: 5354520,
        duration: 7881,
        text: "the data and say that we are working with with this video ID the first one",
      },
      {
        start_time: 5354520,
        end_time: 5360159,
        duration: 5639,
        text: "Sprint qualifying we can take this video ID and in the configure we say that in this",
      },
      {
        start_time: 5360159,
        end_time: 5367520,
        duration: 7361,
        text: "thread hey we are talking about this video again it depends on how you want to uh architect the the experience but",
      },
      {
        start_time: 5367520,
        end_time: 5372679,
        duration: 5159,
        text: "if you want one thread to be specific to one video that would be a good",
      },
      {
        start_time: 5372679,
        end_time: 5379880,
        duration: 7201,
        text: "configuration later we can think about like how maybe we can send a channel ID here or we can let the AI agent",
      },
      {
        start_time: 5379880,
        end_time: 5385280,
        duration: 5400,
        text: "understand magically how what video we are talking about but this is a good way",
      },
      {
        start_time: 5385280,
        end_time: 5391040,
        duration: 5760,
        text: "to send data so I'm going to send it through configurable here I will remove a second one",
      },
      {
        start_time: 5391040,
        end_time: 5400320,
        duration: 9280,
        text: "because we we had it just for testing thing and I'm going to take this video",
      },
      {
        start_time: 5400320,
        end_time: 5406600,
        duration: 6280,
        text: "ID and what where we going to receive it I need to receive it somehow here in the",
      },
      {
        start_time: 5406600,
        end_time: 5415320,
        duration: 8720,
        text: "retrieve tool to receive it in the retrieve tool this is the input of the",
      },
      {
        start_time: 5415320,
        end_time: 5420440,
        duration: 5120,
        text: "tool but here we get the options of the",
      },
      {
        start_time: 5420440,
        end_time: 5426719,
        duration: 6279,
        text: "invocation and we can go ahead and get access to the Fred ID where in this case",
      },
      {
        start_time: 5426719,
        end_time: 5432280,
        duration: 5561,
        text: "I need the video uncore ID so if I do",
      },
      {
        start_time: 5432280,
        end_time: 5439000,
        duration: 6720,
        text: "here uh query console log video ID let's see if",
      },
      {
        start_time: 5439000,
        end_time: 5445040,
        duration: 6040,
        text: "in our tool we get access to the video ID from our",
      },
      {
        start_time: 5445040,
        end_time: 5449520,
        duration: 4480,
        text: "invocation if I call this one",
      },
      {
        start_time: 5452159,
        end_time: 5456600,
        duration: 4441,
        text: "here we see that ID",
      },
      {
        start_time: 5458119,
        end_time: 5463800,
        duration: 5681,
        text: "here it's still going to work the same because we just simply do this but what",
      },
      {
        start_time: 5463800,
        end_time: 5470239,
        duration: 6439,
        text: "we can do here is we can use the video ID for the similarity search I'm going",
      },
      {
        start_time: 5470239,
        end_time: 5480920,
        duration: 10681,
        text: "to show you the documentation where you can find it just Google L graph uh Vector store and the",
      },
      {
        start_time: 5480920,
        end_time: 5489119,
        duration: 8199,
        text: "JavaScript for example if I'm not mistaken here and you're going to see",
      },
      {
        start_time: 5494159,
        end_time: 5500040,
        duration: 5881,
        text: "that L graph Vector l l chain Vector",
      },
      {
        start_time: 5500040,
        end_time: 5505119,
        duration: 5079,
        text: "store GS so in the documentation you're going",
      },
      {
        start_time: 5505119,
        end_time: 5509119,
        duration: 4000,
        text: "to see some options that you can",
      },
      {
        start_time: 5511520,
        end_time: 5515840,
        duration: 4320,
        text: "use I need options",
      },
      {
        start_time: 5517080,
        end_time: 5524080,
        duration: 7000,
        text: "yeah I'm pretty sure like you can you you'll find here like maybe I'm going to leave a link in the guide here so you",
      },
      {
        start_time: 5524080,
        end_time: 5530440,
        duration: 6360,
        text: "can have access to it but what I mean there is that when we do Vector store. similarity search the first one is query",
      },
      {
        start_time: 5530440,
        end_time: 5536880,
        duration: 6440,
        text: "the second one is how many items we want to receive but the next one is the",
      },
      {
        start_time: 5536880,
        end_time: 5544800,
        duration: 7920,
        text: "filtering in the filter can be uh a filter on the metadata so so we can say",
      },
      {
        start_time: 5544800,
        end_time: 5553239,
        duration: 8439,
        text: "that I want only the dog dogs or maybe I need filter",
      },
      {
        start_time: 5553239,
        end_time: 5557480,
        duration: 4241,
        text: "here let me double check",
      },
      {
        start_time: 5565600,
        end_time: 5573920,
        duration: 8320,
        text: "that no it shouldn't be filter it should be simply video ID so this is the filter that is being",
      },
      {
        start_time: 5573920,
        end_time: 5580760,
        duration: 6840,
        text: "applied and is being applied on the metadata of our documents and if we look",
      },
      {
        start_time: 5580760,
        end_time: 5586360,
        duration: 5600,
        text: "in the metadata of our documents we store the video ID here later when we",
      },
      {
        start_time: 5586360,
        end_time: 5592520,
        duration: 6160,
        text: "add the database we're going to be able to see visually what I mean there and now let's go ahead and",
      },
      {
        start_time: 5592520,
        end_time: 5598080,
        duration: 5560,
        text: "see maybe um console log retrieve docs",
      },
      {
        start_time: 5598080,
        end_time: 5606280,
        duration: 8200,
        text: "to see what document docs did it receive for that query I'm going to go ahead and ask",
      },
      {
        start_time: 5606280,
        end_time: 5611880,
        duration: 5600,
        text: "the invoke the this one with a question what is the finished position of Nores",
      },
      {
        start_time: 5611880,
        end_time: 5619639,
        duration: 7759,
        text: "it knows that is this video ID because we specified it it's going to ask norish finish",
      },
      {
        start_time: 5619639,
        end_time: 5625719,
        duration: 6080,
        text: "time and it will say the apolog but it seems there is a technical issue with the retrieval function in order to",
      },
      {
        start_time: 5625719,
        end_time: 5631159,
        duration: 5440,
        text: "provide more with accurate information basically it says that there is no items with this",
      },
      {
        start_time: 5631159,
        end_time: 5639159,
        duration: 8000,
        text: "ID and why is that happening something wrong with here with a video",
      },
      {
        start_time: 5639159,
        end_time: 5646960,
        duration: 7801,
        text: "ID video ID did I call it video uncore ID here metadata video ID and let me",
      },
      {
        start_time: 5646960,
        end_time: 5655040,
        duration: 8080,
        text: "look in the database video uncore ID Vore ID",
      },
      {
        start_time: 5678600,
        end_time: 5686159,
        duration: 7559,
        text: "filter this is Vector store similarity search",
      },
      {
        start_time: 5700360,
        end_time: 5706520,
        duration: 6160,
        text: "I'm wondering if this uh is not going to work for the inmemory vector databases",
      },
      {
        start_time: 5706520,
        end_time: 5714480,
        duration: 7960,
        text: "but only for the for the postgress",
      },
      {
        start_time: 5720560,
        end_time: 5728880,
        duration: 8320,
        text: "databases uh because as I see the retrieve docks",
      },
      {
        start_time: 5728880,
        end_time: 5735679,
        duration: 6799,
        text: "right retrieve docks for query it doesn't even get here so it",
      },
      {
        start_time: 5735679,
        end_time: 5741520,
        duration: 5841,
        text: "must fail completely it doesn't get retrieve",
      },
      {
        start_time: 5743920,
        end_time: 5749679,
        duration: 5759,
        text: "docks so let's try to do a try catch just",
      },
      {
        start_time: 5749679,
        end_time: 5756080,
        duration: 6401,
        text: "to to see why it's not",
      },
      {
        start_time: 5759159,
        end_time: 5764280,
        duration: 5121,
        text: "working it's it's hopefully it's going",
      },
      {
        start_time: 5764719,
        end_time: 5770920,
        duration: 6201,
        text: "to to show me but yeah as I'm saying maybe uh this",
      },
      {
        start_time: 5770920,
        end_time: 5777800,
        duration: 6880,
        text: "kind of filtering doesn't work on the inmemory filter is not a",
      },
      {
        start_time: 5777800,
        end_time: 5784560,
        duration: 6760,
        text: "function okay so for the in memory maybe filter should be a function let's try",
      },
      {
        start_time: 5784560,
        end_time: 5791040,
        duration: 6480,
        text: "let's try saying that hey Doc is a function and we're going to",
      },
      {
        start_time: 5791040,
        end_time: 5796840,
        duration: 5800,
        text: "return true if doc do",
      },
      {
        start_time: 5796840,
        end_time: 5804440,
        duration: 7600,
        text: "metadata. video ID is equal to video uh video video ID that you're",
      },
      {
        start_time: 5804440,
        end_time: 5812520,
        duration: 8080,
        text: "looking for again uh this is going to be a bit different later but now for in memory",
      },
      {
        start_time: 5812520,
        end_time: 5820080,
        duration: 7560,
        text: "database I think it expects a function for filtering and let's uh let's try",
      },
      {
        start_time: 5820080,
        end_time: 5826719,
        duration: 6639,
        text: "to maybe remove a TR catch and invoke it",
      },
      {
        start_time: 5829320,
        end_time: 5837040,
        duration: 7720,
        text: "again okay we see that and we see retrieve documents V",
      },
      {
        start_time: 5837040,
        end_time: 5845480,
        duration: 8440,
        text: "documents cool if for example I'm going to make a mistake and say give me",
      },
      {
        start_time: 5845480,
        end_time: 5851199,
        duration: 5719,
        text: "we are working with video ID one 2 three this video ID is not in our database and",
      },
      {
        start_time: 5851199,
        end_time: 5857679,
        duration: 6480,
        text: "it's supposed to filter out like other documents in the database we see retrieve docs as an",
      },
      {
        start_time: 5857679,
        end_time: 5862760,
        duration: 5081,
        text: "empty um array saying that meaning that our",
      },
      {
        start_time: 5862760,
        end_time: 5871560,
        duration: 8800,
        text: "filtering is working correctly now what we can do is we can",
      },
      {
        start_time: 5871560,
        end_time: 5877719,
        duration: 6159,
        text: "load the other video as well let me go ahead and maybe split up a",
      },
      {
        start_time: 5877719,
        end_time: 5885000,
        duration: 7281,
        text: "little bit the logic of of generating this embeddings because I would like to",
      },
      {
        start_time: 5885000,
        end_time: 5892080,
        duration: 7080,
        text: "already clean up a little bit here this file is getting a little bit out of hand and it um is responsible for different",
      },
      {
        start_time: 5892080,
        end_time: 5897800,
        duration: 5720,
        text: "pipelines different layers uh it's both for indexing and adding to the database",
      },
      {
        start_time: 5897800,
        end_time: 5905159,
        duration: 7359,
        text: "and it's also about the agent I want agent to be only specific to agent",
      },
      {
        start_time: 5911010,
        end_time: 5920360,
        duration: 9350,
        text: "[Music] um so let's go ahead and create here in",
      },
      {
        start_time: 5920360,
        end_time: 5927520,
        duration: 7160,
        text: "the server a new file called embeddings",
      },
      {
        start_time: 5927520,
        end_time: 5935400,
        duration: 7880,
        text: "edings hopefully I wrote it correctly maybe not is it with double d",
      },
      {
        start_time: 5935400,
        end_time: 5941360,
        duration: 5960,
        text: "embeddings maybe and from the agent move stuff related to embeddings",
      },
      {
        start_time: 5941360,
        end_time: 5949199,
        duration: 7839,
        text: "where what stuff do I mean well first of all I want to move",
      },
      {
        start_time: 5949199,
        end_time: 5957199,
        duration: 8000,
        text: "the gener uh creating the open Ai embeddings and the vector store I will copy them from here I will",
      },
      {
        start_time: 5957199,
        end_time: 5964040,
        duration: 6841,
        text: "cut them actually and move them here I want to import",
      },
      {
        start_time: 5964040,
        end_time: 5970719,
        duration: 6679,
        text: "what we need here and we have here what export Vector",
      },
      {
        start_time: 5970719,
        end_time: 5976400,
        duration: 5681,
        text: "store maybe I'm going to do export const Vector store so that other files can",
      },
      {
        start_time: 5976400,
        end_time: 5982280,
        duration: 5880,
        text: "import this storage I'll also do export",
      },
      {
        start_time: 5982280,
        end_time: 5989480,
        duration: 7200,
        text: "const add documents to Vector store function uh or not documents but let's",
      },
      {
        start_time: 5989480,
        end_time: 5995119,
        duration: 5639,
        text: "do add YouTube video",
      },
      {
        start_time: 5995119,
        end_time: 5998400,
        duration: 3281,
        text: "to Vector",
      },
      {
        start_time: 6003760,
        end_time: 6010560,
        duration: 6800,
        text: "store let's say we're going to get video data and we need to do something with",
      },
      {
        start_time: 6010560,
        end_time: 6016400,
        duration: 5840,
        text: "it what do we need to do in order to add it to to the vector store well we",
      },
      {
        start_time: 6016400,
        end_time: 6022040,
        duration: 5640,
        text: "already have it in the logic in the agent AI if we look here well first we",
      },
      {
        start_time: 6022040,
        end_time: 6029280,
        duration: 7240,
        text: "have to Define the split or actually with docs so I'm going to copy creating with",
      },
      {
        start_time: 6029280,
        end_time: 6034599,
        duration: 5319,
        text: "documents creating with splitter generating the chunks and finally doing",
      },
      {
        start_time: 6034599,
        end_time: 6039639,
        duration: 5040,
        text: "Vector store at documents I'm going to copy all of this",
      },
      {
        start_time: 6039639,
        end_time: 6048520,
        duration: 8881,
        text: "into embeddings because this is part of adding a YouTube video data to Vector",
      },
      {
        start_time: 6048520,
        end_time: 6054000,
        duration: 5480,
        text: "store so for the document we need to import",
      },
      {
        start_time: 6054000,
        end_time: 6062520,
        duration: 8520,
        text: "uh document from linkchain core documents page content is going to be video data. transcript metadata is going",
      },
      {
        start_time: 6062520,
        end_time: 6067599,
        duration: 5079,
        text: "to be video data video ID or we can do it easily",
      },
      {
        start_time: 6067599,
        end_time: 6074239,
        duration: 6640,
        text: "here destructuring and video ID is going to",
      },
      {
        start_time: 6074239,
        end_time: 6080719,
        duration: 6480,
        text: "be like this because it has the same name and title we need to import the recursive",
      },
      {
        start_time: 6080719,
        end_time: 6086840,
        duration: 6121,
        text: "character text splitter from L chain text splitter here we're going to leave",
      },
      {
        start_time: 6086840,
        end_time: 6092880,
        duration: 6040,
        text: "the same configuration we're going to remove this console log and we are",
      },
      {
        start_time: 6092880,
        end_time: 6102560,
        duration: 9680,
        text: "adding it to the vector store that we created at the top Vector store add documents",
      },
      {
        start_time: 6103119,
        end_time: 6108920,
        duration: 5801,
        text: "chunks perfect so now this file is responsible for setting up the vector",
      },
      {
        start_time: 6108920,
        end_time: 6115239,
        duration: 6319,
        text: "store and adding for example YouTube videos to Vector store",
      },
      {
        start_time: 6116119,
        end_time: 6124920,
        duration: 8801,
        text: "let's go ahead back and clean up a little bit here uh we'll leave a retrieve tool",
      },
      {
        start_time: 6124920,
        end_time: 6130679,
        duration: 5759,
        text: "here I don't know I don't need the video one or maybe I need do I need",
      },
      {
        start_time: 6130679,
        end_time: 6137960,
        duration: 7281,
        text: "it I think I don't yeah I need it because it's still going to be here that",
      },
      {
        start_time: 6137960,
        end_time: 6144639,
        duration: 6679,
        text: "I want to add this video to our database so for that we need to",
      },
      {
        start_time: 6144639,
        end_time: 6149880,
        duration: 5241,
        text: "import Vector store and add YouTube video to Vector store from embeddings",
      },
      {
        start_time: 6149880,
        end_time: 6156639,
        duration: 6759,
        text: "and I want to call here a wait add YouTube video to Vector store so I still want to add it here later we're going to",
      },
      {
        start_time: 6156639,
        end_time: 6161960,
        duration: 5321,
        text: "think where to do it for now I just want to I move a code in another file and",
      },
      {
        start_time: 6161960,
        end_time: 6168840,
        duration: 6880,
        text: "call it from here I'm still going to have a retrieve tool that needs access to the vector",
      },
      {
        start_time: 6168840,
        end_time: 6174760,
        duration: 5920,
        text: "store so that's why we exported and we import it here the same access to the same",
      },
      {
        start_time: 6174760,
        end_time: 6180800,
        duration: 6040,
        text: "database and everything else is related to this one I can clean up a little bit",
      },
      {
        start_time: 6180800,
        end_time: 6188639,
        duration: 7839,
        text: "here the Imports of what we do not need anymore leaving only things that we need",
      },
      {
        start_time: 6188639,
        end_time: 6194159,
        duration: 5520,
        text: "like this and what else cleaning up a little",
      },
      {
        start_time: 6194159,
        end_time: 6197800,
        duration: 3641,
        text: "bit the console logs here as",
      },
      {
        start_time: 6200080,
        end_time: 6205119,
        duration: 5039,
        text: "well checkpoint or video ID",
      },
      {
        start_time: 6210080,
        end_time: 6216760,
        duration: 6680,
        text: "okay this one is also going to go away in a second but it's",
      },
      {
        start_time: 6216760,
        end_time: 6223280,
        duration: 6520,
        text: "testing the agent perfect so let's double check if",
      },
      {
        start_time: 6223280,
        end_time: 6229520,
        duration: 6240,
        text: "it still works I'm going to invoke the agent. GS uh question was the position of",
      },
      {
        start_time: 6229520,
        end_time: 6232520,
        duration: 3000,
        text: "Norris",
      },
      {
        start_time: 6245040,
        end_time: 6251199,
        duration: 6159,
        text: "come on uh based on I can provide with more details Hamilton vers yeah like it",
      },
      {
        start_time: 6251199,
        end_time: 6258719,
        duration: 7520,
        text: "we we understand that it's working it's using the transcript data uh what I want you to do now is let's try to add two",
      },
      {
        start_time: 6258719,
        end_time: 6263840,
        duration: 5121,
        text: "videos to the store and see that in that case it can f filter out with",
      },
      {
        start_time: 6263840,
        end_time: 6269520,
        duration: 5680,
        text: "transcripts related to one specific video for example I'm going to do a same",
      },
      {
        start_time: 6269520,
        end_time: 6275440,
        duration: 5920,
        text: "await video add YouTube video to Vector store and I'm going to say that we want",
      },
      {
        start_time: 6275440,
        end_time: 6281280,
        duration: 5840,
        text: "to add the data at position one here I can do data position zero and data",
      },
      {
        start_time: 6281280,
        end_time: 6288159,
        duration: 6879,
        text: "position one if I'm going to go ahead and",
      },
      {
        start_time: 6288159,
        end_time: 6295960,
        duration: 7801,
        text: "um ask the question about this video ID about Norris I think it's going to be",
      },
      {
        start_time: 6295960,
        end_time: 6301159,
        duration: 5199,
        text: "fine because it's going to look only at the transcripts for that user at the",
      },
      {
        start_time: 6301159,
        end_time: 6309040,
        duration: 7881,
        text: "same time it took a little bit of time to to add the embeddings but it's very fast like it's super",
      },
      {
        start_time: 6309040,
        end_time: 6314760,
        duration: 5720,
        text: "fast let's see what's happening now uh I don't see a specific time for Norris",
      },
      {
        start_time: 6314760,
        end_time: 6323320,
        duration: 8560,
        text: "mentioned that Norris racing that is going quickly through the middle part of a lap by 800 milliseconds however if I'm",
      },
      {
        start_time: 6323320,
        end_time: 6333320,
        duration: 10000,
        text: "going to go into the data and take the idea of my second video let's find it with Vore ID and the",
      },
      {
        start_time: 6333320,
        end_time: 6338440,
        duration: 5120,
        text: "second one is this one if I'm going to say it hey now this",
      },
      {
        start_time: 6338440,
        end_time: 6344480,
        duration: 6040,
        text: "same question what is the finish time of Norris is going to be on a different",
      },
      {
        start_time: 6344480,
        end_time: 6349719,
        duration: 5239,
        text: "video what I expect to see is I expect the model not to know how to answer",
      },
      {
        start_time: 6349719,
        end_time: 6355159,
        duration: 5440,
        text: "because it doesn't have that information we gave it information from a different",
      },
      {
        start_time: 6355159,
        end_time: 6358400,
        duration: 3241,
        text: "video let's",
      },
      {
        start_time: 6371239,
        end_time: 6378199,
        duration: 6960,
        text: "see um based on the transcript I don't see any information about nor is the",
      },
      {
        start_time: 6378199,
        end_time: 6383480,
        duration: 5281,
        text: "transcript appear to be discussing programming Concepts so that's exactly",
      },
      {
        start_time: 6383480,
        end_time: 6389960,
        duration: 6480,
        text: "true because we are filtering out only data from our Vector store for this",
      },
      {
        start_time: 6389960,
        end_time: 6398520,
        duration: 8560,
        text: "video ID if I will go ahead and transform change the question to what uh",
      },
      {
        start_time: 6398520,
        end_time: 6406360,
        duration: 7840,
        text: "will people learn from this video Let's see what that answer is",
      },
      {
        start_time: 6406360,
        end_time: 6413360,
        duration: 7000,
        text: "going to to look like because remember this video with this ID is a tutorial",
      },
      {
        start_time: 6413360,
        end_time: 6422598,
        duration: 9238,
        text: "from my channel uh about Apple invite application so if we look at the",
      },
      {
        start_time: 6423440,
        end_time: 6429119,
        duration: 5679,
        text: "response it doesn't understand that it needs to call the tool so let's see what",
      },
      {
        start_time: 6429119,
        end_time: 6434239,
        duration: 5120,
        text: "will people learn from uh the video",
      },
      {
        start_time: 6434239,
        end_time: 6440880,
        duration: 6641,
        text: "based on it's it's",
      },
      {
        start_time: 6441320,
        end_time: 6446560,
        duration: 5240,
        text: "transcript it's still sometimes doesn't know that but it has this capabilities",
      },
      {
        start_time: 6446560,
        end_time: 6453679,
        duration: 7119,
        text: "so maybe I need to inform it like hey at any moment you have information about video you just need to call the",
      },
      {
        start_time: 6453679,
        end_time: 6461119,
        duration: 7440,
        text: "Tool uh but with a better question I think it's going to work better now as we can see it's thinking and we see",
      },
      {
        start_time: 6461119,
        end_time: 6466280,
        duration: 5161,
        text: "based on the the video tutorial about building a mobile",
      },
      {
        start_time: 6466280,
        end_time: 6472840,
        duration: 6560,
        text: "application how to create custom auto scrolling component Marquee building and boarding screens with animation",
      },
      {
        start_time: 6472840,
        end_time: 6478760,
        duration: 5920,
        text: "implementing UI react development Concepts and so on so perfect now our AA",
      },
      {
        start_time: 6478760,
        end_time: 6486080,
        duration: 7320,
        text: "agent can work with multiple videos it can store his data in a database but when asked it's going to look at only",
      },
      {
        start_time: 6486080,
        end_time: 6491280,
        duration: 5200,
        text: "specific information for a specific video",
      },
      {
        start_time: 6491280,
        end_time: 6497638,
        duration: 6358,
        text: "Perfect let me go ahead and do a git add git",
      },
      {
        start_time: 6498520,
        end_time: 6504280,
        duration: 5760,
        text: "CIT agent with rag",
      },
      {
        start_time: 6504280,
        end_time: 6510280,
        duration: 6000,
        text: "I'm going to bring some water and the next step for us is going to be to",
      },
      {
        start_time: 6510280,
        end_time: 6517320,
        duration: 7040,
        text: "change from a memory Vector store to an actual database so that this data is not going",
      },
      {
        start_time: 6517320,
        end_time: 6524840,
        duration: 7520,
        text: "to be lost and we're not going to have to generate the embeddings always we're going to store and cash them so that",
      },
      {
        start_time: 6524840,
        end_time: 6532880,
        duration: 8040,
        text: "next time when we ask the same question about the same video we don't have to get the data again and again so that's",
      },
      {
        start_time: 6532880,
        end_time: 6538000,
        duration: 5120,
        text: "our going to be our next step give me one second",
      },
      {
        start_time: 6587599,
        end_time: 6592080,
        duration: 4481,
        text: "hello uh perfect",
      },
      {
        start_time: 6601800,
        end_time: 6606840,
        duration: 5040,
        text: "so as I was saying the next step is going to be to transform to a proper",
      },
      {
        start_time: 6606840,
        end_time: 6612760,
        duration: 5920,
        text: "database for our Vector store and that's one thing that I like about Lang chain",
      },
      {
        start_time: 6612760,
        end_time: 6619159,
        duration: 6399,
        text: "is how everything um is abstract in different layers and you're going to see",
      },
      {
        start_time: 6619159,
        end_time: 6624760,
        duration: 5601,
        text: "how easy is going to be to swap from a memory to we postgress database we just",
      },
      {
        start_time: 6624760,
        end_time: 6632159,
        duration: 7399,
        text: "have to create it and change here how we connect it and everything else is going to remain the same without us having to",
      },
      {
        start_time: 6632159,
        end_time: 6637360,
        duration: 5201,
        text: "do much changes for the database uh we need a",
      },
      {
        start_time: 6637360,
        end_time: 6645480,
        duration: 8120,
        text: "postgress database with pogress SQL We There is a PG Vector extension that",
      },
      {
        start_time: 6645480,
        end_time: 6651639,
        duration: 6159,
        text: "enables us to do similarity searches and index database based on vectors perfect",
      },
      {
        start_time: 6651639,
        end_time: 6657079,
        duration: 5440,
        text: "for our in Bings so we need a pogress database you",
      },
      {
        start_time: 6657079,
        end_time: 6662400,
        duration: 5321,
        text: "can run it locally you can use pogress with a Docker to run it locally that's",
      },
      {
        start_time: 6662400,
        end_time: 6668719,
        duration: 6319,
        text: "totally fine but I think it's a little bit more technical uh and maybe not everyone has the environment set up to",
      },
      {
        start_time: 6668719,
        end_time: 6675079,
        duration: 6360,
        text: "run postgress locally what you can do is you can use for example ne.",
      },
      {
        start_time: 6675079,
        end_time: 6680400,
        duration: 5321,
        text: "Tech uh and with neon tack it's it's actually",
      },
      {
        start_time: 6680400,
        end_time: 6686760,
        duration: 6360,
        text: "super fast and easy to to get a post database up and running uh and I think they also have a",
      },
      {
        start_time: 6686760,
        end_time: 6693560,
        duration: 6800,
        text: "good free tier for up to 10 projects let's go ahead sign up and in your",
      },
      {
        start_time: 6693560,
        end_time: 6701119,
        duration: 7559,
        text: "profile go ahead and do a new project I'm going to call it you AI YouTube",
      },
      {
        start_time: 6701119,
        end_time: 6704920,
        duration: 3801,
        text: "chat and let's do",
      },
      {
        start_time: 6707440,
        end_time: 6714480,
        duration: 7040,
        text: "create here uh we need to enable postgress uh database so what we have to",
      },
      {
        start_time: 6714480,
        end_time: 6720159,
        duration: 5679,
        text: "do is we are going to enable it by running a query in the SQL editor the",
      },
      {
        start_time: 6720159,
        end_time: 6729199,
        duration: 9040,
        text: "query I don't remember how it was but let's do enable PG Vector",
      },
      {
        start_time: 6729639,
        end_time: 6737119,
        duration: 7480,
        text: "neon and that is going to be a query called create extension",
      },
      {
        start_time: 6737119,
        end_time: 6743679,
        duration: 6560,
        text: "Vector so if I go into the SQL editor of my database on new one and write this",
      },
      {
        start_time: 6743679,
        end_time: 6748360,
        duration: 4681,
        text: "command create extensions vector and do",
      },
      {
        start_time: 6749920,
        end_time: 6753440,
        duration: 3520,
        text: "run it didn't",
      },
      {
        start_time: 6764000,
        end_time: 6770400,
        duration: 6400,
        text: "like why it didn't like second time statement executed",
      },
      {
        start_time: 6770400,
        end_time: 6775719,
        duration: 5319,
        text: "successfully so maybe it was not ready yet yet now it executed successfully so",
      },
      {
        start_time: 6775719,
        end_time: 6783000,
        duration: 7281,
        text: "I enable this Vector uh extension on our database so our tables here will be able",
      },
      {
        start_time: 6783000,
        end_time: 6788599,
        duration: 5599,
        text: "to have like vector um columns columns and index and",
      },
      {
        start_time: 6788599,
        end_time: 6794520,
        duration: 5921,
        text: "search based on their similarity the next step is to Simply connect to this",
      },
      {
        start_time: 6794520,
        end_time: 6800800,
        duration: 6280,
        text: "project from our uh application I'm going to go here and I'm going to copy",
      },
      {
        start_time: 6800800,
        end_time: 6807480,
        duration: 6680,
        text: "the connection string let's go ahead and put it into that EnV file and let's",
      },
      {
        start_time: 6807480,
        end_time: 6815079,
        duration: 7599,
        text: "call um DB URL and let's space",
      },
      {
        start_time: 6815079,
        end_time: 6820920,
        duration: 5841,
        text: "the the connection string that we got from here make sure connection pooling is",
      },
      {
        start_time: 6820920,
        end_time: 6828440,
        duration: 7520,
        text: "enabled and the next step is to go and double check",
      },
      {
        start_time: 6828440,
        end_time: 6834280,
        duration: 5840,
        text: "with with where with uh",
      },
      {
        start_time: 6834360,
        end_time: 6840199,
        duration: 5839,
        text: "with length chain under P your vector store I'm going to select PG Vector what",
      },
      {
        start_time: 6840199,
        end_time: 6845880,
        duration: 5681,
        text: "I need to do is do npm install at L chain",
      },
      {
        start_time: 6845880,
        end_time: 6849920,
        duration: 4040,
        text: "Community let's do that",
      },
      {
        start_time: 6851760,
        end_time: 6857800,
        duration: 6040,
        text: "first and then we can create this Vector SC",
      },
      {
        start_time: 6857800,
        end_time: 6864040,
        duration: 6240,
        text: "store like this so from our Bings",
      },
      {
        start_time: 6864040,
        end_time: 6871520,
        duration: 7480,
        text: "files at the top we import PG vector and we create it instead of using",
      },
      {
        start_time: 6871520,
        end_time: 6876560,
        duration: 5040,
        text: "memory Vector we create it using PG Vector store. initialize we give the",
      },
      {
        start_time: 6876560,
        end_time: 6882560,
        duration: 6000,
        text: "same embeddings model there but we need to provide here some",
      },
      {
        start_time: 6882560,
        end_time: 6890760,
        duration: 8200,
        text: "configuration configuration uh such as postgress",
      },
      {
        start_time: 6890760,
        end_time: 6895960,
        duration: 5200,
        text: "connection options and the connection options you can either use a connection",
      },
      {
        start_time: 6895960,
        end_time: 6903679,
        duration: 7719,
        text: "string the easiest way or you can have like Port host database name and so on",
      },
      {
        start_time: 6903679,
        end_time: 6909520,
        duration: 5841,
        text: "but the easiest one is just to provide connection string as process. EnV DB URL",
      },
      {
        start_time: 6909520,
        end_time: 6915560,
        duration: 6040,
        text: "that we added here in our environment",
      },
      {
        start_time: 6915560,
        end_time: 6920880,
        duration: 5320,
        text: "variables and then we are not done yet with the configuration we need to give a",
      },
      {
        start_time: 6920880,
        end_time: 6929280,
        duration: 8400,
        text: "table name the table name what is going to be the table name for this tour let's do",
      },
      {
        start_time: 6929280,
        end_time: 6933800,
        duration: 4520,
        text: "transcript transcripts let's do",
      },
      {
        start_time: 6934360,
        end_time: 6938480,
        duration: 4120,
        text: "transcripts um",
      },
      {
        start_time: 6939800,
        end_time: 6948280,
        duration: 8480,
        text: "columns we can have ID column name come on",
      },
      {
        start_time: 6948280,
        end_time: 6955440,
        duration: 7160,
        text: "columns the ID column name let's do it ID let's do the embedding column name",
      },
      {
        start_time: 6955440,
        end_time: 6960560,
        duration: 5120,
        text: "you can specify what should be the name of the embedding you can do embedding or",
      },
      {
        start_time: 6960560,
        end_time: 6967599,
        duration: 7039,
        text: "vector for example",
      },
      {
        start_time: 6969480,
        end_time: 6977599,
        duration: 8119,
        text: "what I don't have text column name content column name this is the content",
      },
      {
        start_time: 6977599,
        end_time: 6984079,
        duration: 6480,
        text: "of that embedding and there is also metadata column name name metadata I",
      },
      {
        start_time: 6984079,
        end_time: 6991719,
        duration: 7640,
        text: "think you can leave them out as well but because it's going to be default but know that you can adjust them is it",
      },
      {
        start_time: 6991719,
        end_time: 6999520,
        duration: 7801,
        text: "embeddings or vector oh it's Vector column name sorry Vector column name",
      },
      {
        start_time: 6999520,
        end_time: 7005599,
        duration: 6079,
        text: "vector and besides columns you can also have a distance",
      },
      {
        start_time: 7005599,
        end_time: 7010920,
        duration: 5321,
        text: "strategy and this is a little bit more technical basically meaning what uh",
      },
      {
        start_time: 7010920,
        end_time: 7018159,
        duration: 7239,
        text: "function to use to calculate uh the similarity there is cosine uh there is",
      },
      {
        start_time: 7018159,
        end_time: 7025280,
        duration: 7121,
        text: "uh whatever yeah there are other methods as",
      },
      {
        start_time: 7025280,
        end_time: 7031679,
        duration: 6399,
        text: "well like inner product or Ean as well but cosine is default so you can leave",
      },
      {
        start_time: 7031679,
        end_time: 7038719,
        duration: 7040,
        text: "it like this or you can even leave it out as well anyway now if I restart my",
      },
      {
        start_time: 7038719,
        end_time: 7045560,
        duration: 6841,
        text: "application the vector store should automatically connect with this uh database with this configuration I",
      },
      {
        start_time: 7045560,
        end_time: 7052599,
        duration: 7039,
        text: "don't need to change anything else the vector store will have the same ad documents and stuff like that and it",
      },
      {
        start_time: 7052599,
        end_time: 7058560,
        duration: 5961,
        text: "should automatically handle the database creation for me if I go into new one",
      },
      {
        start_time: 7058560,
        end_time: 7066840,
        duration: 8280,
        text: "under tables we don't have any tables yet but if I'm going to go ahead and restart or run our",
      },
      {
        start_time: 7066840,
        end_time: 7073800,
        duration: 6960,
        text: "agent uh if everything is successful it's going to connect and",
      },
      {
        start_time: 7073800,
        end_time: 7080159,
        duration: 6359,
        text: "store information in postgress we see that we cannot find the PG uh package",
      },
      {
        start_time: 7080159,
        end_time: 7086320,
        duration: 6161,
        text: "because for that we need to do npm install PG this is for postgress so it's",
      },
      {
        start_time: 7086320,
        end_time: 7091880,
        duration: 5560,
        text: "a pure dependency uh let's try to run it again",
      },
      {
        start_time: 7091880,
        end_time: 7098880,
        duration: 7000,
        text: "we see Vector store from embeddings dogs does not provide an export",
      },
      {
        start_time: 7098880,
        end_time: 7105119,
        duration: 6239,
        text: "member I forgot to do export Vector",
      },
      {
        start_time: 7107079,
        end_time: 7110760,
        duration: 3681,
        text: "store if I do it",
      },
      {
        start_time: 7113639,
        end_time: 7119079,
        duration: 5440,
        text: "again how many tabs open in that browser I don't know a lot and that's not even",
      },
      {
        start_time: 7119079,
        end_time: 7124840,
        duration: 5761,
        text: "enough uh what will people learn from the video like now at this point if I go",
      },
      {
        start_time: 7124840,
        end_time: 7132360,
        duration: 7520,
        text: "to the tables we see a new table called transcripts if you go into the options here and enable table RW count we see",
      },
      {
        start_time: 7132360,
        end_time: 7139000,
        duration: 6640,
        text: "that we have around 167 chunks of data so this is not 167",
      },
      {
        start_time: 7139000,
        end_time: 7145560,
        duration: 6560,
        text: "videos but because my video one of them is 4 hours long it divided in in that",
      },
      {
        start_time: 7145560,
        end_time: 7152159,
        duration: 6599,
        text: "many chunks so we see that the first ones is about L stroll and so one fastest ahead",
      },
      {
        start_time: 7152159,
        end_time: 7159000,
        duration: 6841,
        text: "Louis Hamilton definitely uh transcript from uh Formula 1 videos but if you",
      },
      {
        start_time: 7159000,
        end_time: 7167719,
        duration: 8719,
        text: "scroll down a bit we see that what information about the Bol text and react",
      },
      {
        start_time: 7167719,
        end_time: 7173400,
        duration: 5681,
        text: "native and so on so this is the second video in the",
      },
      {
        start_time: 7173400,
        end_time: 7180199,
        duration: 6799,
        text: "metadata there is the metadata about video ID so this is how the filtering is",
      },
      {
        start_time: 7180199,
        end_time: 7188159,
        duration: 7960,
        text: "supposed to work and let's double check if filtering is working in a second and there is this Vector which as you can",
      },
      {
        start_time: 7188159,
        end_time: 7194880,
        duration: 6721,
        text: "see is a bunch of numbers if I will I don't know I can",
      },
      {
        start_time: 7194880,
        end_time: 7201280,
        duration: 6400,
        text: "copy it maybe I don't but you're going to see that it's simply a bunch of",
      },
      {
        start_time: 7201280,
        end_time: 7206960,
        duration: 5680,
        text: "numbers so this is a better way because now it is stored in the database so we",
      },
      {
        start_time: 7206960,
        end_time: 7212280,
        duration: 5320,
        text: "can we don't have to embed and generate them every time we can build a huge",
      },
      {
        start_time: 7212280,
        end_time: 7218599,
        duration: 6319,
        text: "cache of this data to later interact with this is the",
      },
      {
        start_time: 7218599,
        end_time: 7224320,
        duration: 5721,
        text: "information and again let me double check in the agent in that tool for",
      },
      {
        start_time: 7224320,
        end_time: 7231480,
        duration: 7160,
        text: "retrieval we have here the function but as we can see now that our",
      },
      {
        start_time: 7231480,
        end_time: 7237199,
        duration: 5719,
        text: "Vector store is a database it would be better to provide here a filter",
      },
      {
        start_time: 7237199,
        end_time: 7243360,
        duration: 6161,
        text: "object and that filter object if I'm not mistaken is going to be added on the database layer so it's going to",
      },
      {
        start_time: 7243360,
        end_time: 7249639,
        duration: 6279,
        text: "completely ignore those items when it does we SQL query so this is the filter",
      },
      {
        start_time: 7249639,
        end_time: 7255670,
        duration: 6031,
        text: "to retrieve documents based on the video IDE perfect now I will",
      },
      {
        start_time: 7255670,
        end_time: 7261559,
        duration: 5889,
        text: "[Music] do like",
      },
      {
        start_time: 7263360,
        end_time: 7268960,
        duration: 5600,
        text: "this and at this moment we are still adding like that those items in the",
      },
      {
        start_time: 7268960,
        end_time: 7274599,
        duration: 5639,
        text: "database so most probably we're going to have duplicated items we had 150 now we",
      },
      {
        start_time: 7274599,
        end_time: 7282679,
        duration: 8080,
        text: "have 334 uh but it works here like",
      },
      {
        start_time: 7283480,
        end_time: 7290239,
        duration: 6759,
        text: "this time it didn't call the tool but anyway or maybe it's a problem maybe it",
      },
      {
        start_time: 7290239,
        end_time: 7296480,
        duration: 6241,
        text: "call the tool I'm going to comment out this wait add YouTube videos to the vector store",
      },
      {
        start_time: 7296480,
        end_time: 7301679,
        duration: 5199,
        text: "because we're already there and I'm going to run it again to",
      },
      {
        start_time: 7301679,
        end_time: 7305480,
        duration: 3801,
        text: "see if the filtering is working",
      },
      {
        start_time: 7309440,
        end_time: 7315920,
        duration: 6480,
        text: "correctly because it's I not calling tool where the tool is not doing yeah I see information so that means that it's",
      },
      {
        start_time: 7315920,
        end_time: 7321360,
        duration: 5440,
        text: "working correctly",
      },
      {
        start_time: 7323719,
        end_time: 7326719,
        duration: 3000,
        text: "Perfecto",
      },
      {
        start_time: 7340560,
        end_time: 7346520,
        duration: 5960,
        text: "amazing so this is our G",
      },
      {
        start_time: 7346560,
        end_time: 7354400,
        duration: 7840,
        text: "ad database uh",
      },
      {
        start_time: 7354400,
        end_time: 7359719,
        duration: 5319,
        text: "pogress for the vector",
      },
      {
        start_time: 7366920,
        end_time: 7372400,
        duration: 5480,
        text: "database I think in the next step we are kind of ready to integrate",
      },
      {
        start_time: 7372400,
        end_time: 7378679,
        duration: 6279,
        text: "the the chat interface and before we do that I want",
      },
      {
        start_time: 7378679,
        end_time: 7384679,
        duration: 6000,
        text: "our server to be an restful API so that",
      },
      {
        start_time: 7384679,
        end_time: 7391000,
        duration: 6321,
        text: "we later can interact with it by sending HTTP requests at the moment our agent we",
      },
      {
        start_time: 7391000,
        end_time: 7400239,
        duration: 9239,
        text: "interact with it by literally calling agent. invoke and invoking that um executing this",
      },
      {
        start_time: 7400239,
        end_time: 7405880,
        duration: 5641,
        text: "file but what I want want to do is I want to create an API that I can send",
      },
      {
        start_time: 7405880,
        end_time: 7412800,
        duration: 6920,
        text: "this question as a post request and I can invoke this agent and get back the",
      },
      {
        start_time: 7412800,
        end_time: 7418440,
        duration: 5640,
        text: "answer for that let's go ahead in the server and create the index",
      },
      {
        start_time: 7418440,
        end_time: 7424040,
        duration: 5600,
        text: "do GS file and our server is going to be",
      },
      {
        start_time: 7424040,
        end_time: 7432000,
        duration: 7960,
        text: "an HTTP server we're going to create using Express so let's install Express",
      },
      {
        start_time: 7432000,
        end_time: 7437880,
        duration: 5880,
        text: "maybe course and types SL",
      },
      {
        start_time: 7438599,
        end_time: 7445599,
        duration: 7000,
        text: "Express and let's start by creating a simple uh import Express from Express",
      },
      {
        start_time: 7445599,
        end_time: 7451800,
        duration: 6201,
        text: "import course from course we create the express application",
      },
      {
        start_time: 7451800,
        end_time: 7456880,
        duration: 5080,
        text: "we add course which is you don't have if you don't know like it's not a big deal",
      },
      {
        start_time: 7456880,
        end_time: 7464639,
        duration: 7759,
        text: "here just add it because it's going to later help us send requests from different from our front end to our back",
      },
      {
        start_time: 7464639,
        end_time: 7471199,
        duration: 6560,
        text: "end when we will be deployed and what I can do is I can say simply add a get",
      },
      {
        start_time: 7471199,
        end_time: 7476639,
        duration: 5440,
        text: "request to the slash that will return hello world and start listening at P",
      },
      {
        start_time: 7476639,
        end_time: 7483320,
        duration: 6681,
        text: "3,000 for example or maybe we can do",
      },
      {
        start_time: 7484159,
        end_time: 7489320,
        duration: 5161,
        text: "here const Port equal process. env. port",
      },
      {
        start_time: 7489320,
        end_time: 7496119,
        duration: 6799,
        text: "or 3,000 if it's not provided I'll take Port here and the call back is going to be",
      },
      {
        start_time: 7496119,
        end_time: 7502800,
        duration: 6681,
        text: "executed when we the server started listening this is a very basic barebone",
      },
      {
        start_time: 7502800,
        end_time: 7509760,
        duration: 6960,
        text: "uh HTTP server what I can do with it is I can do node maybe with EnV file and",
      },
      {
        start_time: 7509760,
        end_time: 7515440,
        duration: 5680,
        text: "I'm going to execute not agent but index.js if I do that we see Server is",
      },
      {
        start_time: 7515440,
        end_time: 7520639,
        duration: 5199,
        text: "listening on Port 3,000 because this is a get request I",
      },
      {
        start_time: 7520639,
        end_time: 7529719,
        duration: 9080,
        text: "can simply go to uh in the browser and do Local Host 3,000 and we see the hello",
      },
      {
        start_time: 7529719,
        end_time: 7537880,
        duration: 8161,
        text: "world the hello world that was sent from here usually we are going to send this",
      },
      {
        start_time: 7537880,
        end_time: 7543360,
        duration: 5480,
        text: "requests maybe we're going to be Coral request uh post request so we can also",
      },
      {
        start_time: 7543360,
        end_time: 7551960,
        duration: 8600,
        text: "use the coral command in the in the terminal to send these requests okay good um what what I'm",
      },
      {
        start_time: 7551960,
        end_time: 7560000,
        duration: 8040,
        text: "going to add now is not a get request but a post request to the endpoint maybe",
      },
      {
        start_time: 7560000,
        end_time: 7566760,
        duration: 6760,
        text: "generator query or yeah let's do generate my generate is going to be like",
      },
      {
        start_time: 7566760,
        end_time: 7572320,
        duration: 5560,
        text: "question and answer I send a question and I expect back an",
      },
      {
        start_time: 7572719,
        end_time: 7582880,
        duration: 10161,
        text: "answer the query itself I expect it from the body and let's do console log",
      },
      {
        start_time: 7582880,
        end_time: 7590599,
        duration: 7719,
        text: "query and return send like this now because this is a post requ actually I",
      },
      {
        start_time: 7590599,
        end_time: 7597440,
        duration: 6841,
        text: "did some changes so I need to stop the server and run it again or I can do I",
      },
      {
        start_time: 7597440,
        end_time: 7603159,
        duration: 5719,
        text: "can add come",
      },
      {
        start_time: 7603159,
        end_time: 7609199,
        duration: 6040,
        text: "on to my node I can add here at d-w",
      },
      {
        start_time: 7609199,
        end_time: 7616760,
        duration: 7561,
        text: "watch so that is going to watch any changes if I'm going to change something here it's going to restart so I don't",
      },
      {
        start_time: 7616760,
        end_time: 7623800,
        duration: 7040,
        text: "have to think about restarting it always perfect now that our server has restarted we can send a post request to/",
      },
      {
        start_time: 7623800,
        end_time: 7630280,
        duration: 6480,
        text: "generate to do that in a new terminal I'm going to do coral Dash",
      },
      {
        start_time: 7630280,
        end_time: 7633960,
        duration: 3680,
        text: "um that is a",
      },
      {
        start_time: 7639679,
        end_time: 7647360,
        duration: 7681,
        text: "header let me try uh send a post request",
      },
      {
        start_time: 7647360,
        end_time: 7656119,
        duration: 8759,
        text: "using curl to slash generate with a query",
      },
      {
        start_time: 7656119,
        end_time: 7661880,
        duration: 5761,
        text: "data uh let's see what the AI will tell me yeah it's the dash X that I was",
      },
      {
        start_time: 7661880,
        end_time: 7666920,
        duration: 5040,
        text: "looking for it should be",
      },
      {
        start_time: 7667360,
        end_time: 7674800,
        duration: 7440,
        text: "here so I'm trying to send a post request to Local H Local Host 3000 SL",
      },
      {
        start_time: 7674800,
        end_time: 7680159,
        duration: 5359,
        text: "generate with the data this query what will people learn from this video and",
      },
      {
        start_time: 7680159,
        end_time: 7685199,
        duration: 5040,
        text: "this video ID maybe I will take video ID as",
      },
      {
        start_time: 7685199,
        end_time: 7692040,
        duration: 6841,
        text: "well if I send this query we see something we don't know what exactly but",
      },
      {
        start_time: 7692040,
        end_time: 7699159,
        duration: 7119,
        text: "we see some errors and an error here as well canot distract your property query from requestbody that's because we",
      },
      {
        start_time: 7699159,
        end_time: 7705079,
        duration: 5920,
        text: "didn't um add quite important part which",
      },
      {
        start_time: 7705480,
        end_time: 7714040,
        duration: 8560,
        text: "is the here as a middleware we can add a",
      },
      {
        start_time: 7714040,
        end_time: 7722320,
        duration: 8280,
        text: "express. Json that will automatically transform our request body to Json because without",
      },
      {
        start_time: 7722320,
        end_time: 7728119,
        duration: 5799,
        text: "that the request body is not a Json format if I simply add that one I can",
      },
      {
        start_time: 7728119,
        end_time: 7735000,
        duration: 6881,
        text: "use it as adjacent and D structure the inputs like this now if making sure that the server is",
      },
      {
        start_time: 7735000,
        end_time: 7742920,
        duration: 7920,
        text: "running if I send the same request again we see hello world because that's what we send but in the server we see that",
      },
      {
        start_time: 7742920,
        end_time: 7748880,
        duration: 5960,
        text: "the query is this one and the video ID is this one meaning that I can go ahead",
      },
      {
        start_time: 7748880,
        end_time: 7754679,
        duration: 5799,
        text: "and import the agent here from our agent. JS",
      },
      {
        start_time: 7754679,
        end_time: 7763440,
        duration: 8761,
        text: "let's make sure that in our agent. GS we do export const a agent we no longer",
      },
      {
        start_time: 7763440,
        end_time: 7768679,
        duration: 5239,
        text: "interact with it directly so I can remove this part all together or maybe",
      },
      {
        start_time: 7768679,
        end_time: 7774719,
        duration: 6040,
        text: "I'm not going to remove it let me actually copy paste",
      },
      {
        start_time: 7775040,
        end_time: 7780119,
        duration: 5079,
        text: "it in our index inside the",
      },
      {
        start_time: 7780119,
        end_time: 7787800,
        duration: 7681,
        text: "generate I'm going to put it here I'm going to come to it in a second but I need to change how we import the agent",
      },
      {
        start_time: 7787800,
        end_time: 7793480,
        duration: 5680,
        text: "we need to destructure it when importing because we are expor in it as a constant",
      },
      {
        start_time: 7793480,
        end_time: 7799679,
        duration: 6199,
        text: "so we have agent here from agent. JS and when there is a request to SL generate",
      },
      {
        start_time: 7799679,
        end_time: 7806239,
        duration: 6560,
        text: "we get the query we get the video ID uh and we have the interaction with",
      },
      {
        start_time: 7806239,
        end_time: 7811719,
        duration: 5480,
        text: "agent as we had before I'm going to do some changes we no longer need this video ID because it's going to come from",
      },
      {
        start_time: 7811719,
        end_time: 7820119,
        duration: 8400,
        text: "the request body I'm not going to have his console log I'm going to have agent. invoke and",
      },
      {
        start_time: 7820119,
        end_time: 7826159,
        duration: 6040,
        text: "roll user and the content is going to be query not this hardcoded one but the",
      },
      {
        start_time: 7826159,
        end_time: 7831800,
        duration: 5641,
        text: "query that we receive for configuration we have Fred ID so",
      },
      {
        start_time: 7831800,
        end_time: 7839520,
        duration: 7720,
        text: "maybe we're also going to send the Fred ID here so let's do Fred",
      },
      {
        start_time: 7839520,
        end_time: 7846440,
        duration: 6920,
        text: "ID and video ID then we take the result and we return",
      },
      {
        start_time: 7846440,
        end_time: 7851480,
        duration: 5040,
        text: "it back as results",
      },
      {
        start_time: 7851480,
        end_time: 7855840,
        duration: 4360,
        text: "maybe I can do it like this let's",
      },
      {
        start_time: 7856520,
        end_time: 7862360,
        duration: 5840,
        text: "see return that Json to send it as a",
      },
      {
        start_time: 7862360,
        end_time: 7869119,
        duration: 6759,
        text: "Json and I'm going to send the last message maybe it's going to be too much information but let's see what's going",
      },
      {
        start_time: 7869119,
        end_time: 7876360,
        duration: 7241,
        text: "to happen now our server has restarted and we can send the same",
      },
      {
        start_time: 7876360,
        end_time: 7881679,
        duration: 5319,
        text: "request but we need to change it slightly",
      },
      {
        start_time: 7881679,
        end_time: 7888679,
        duration: 7000,
        text: "to add in this um- D I'm going to add a comma here I'm",
      },
      {
        start_time: 7888679,
        end_time: 7896960,
        duration: 8281,
        text: "going to do a is it an enter come on it's a bit hard",
      },
      {
        start_time: 7896960,
        end_time: 7901558,
        duration: 4598,
        text: "to to edit them but I can I'll do it like",
      },
      {
        start_time: 7904480,
        end_time: 7914079,
        duration: 9599,
        text: "this I'm going to add it here I'm going to comment it out PR ID one I'm going to uncomment it",
      },
      {
        start_time: 7914079,
        end_time: 7921400,
        duration: 7321,
        text: "copy it and comment it back and I'm going to leave it here for you to also be able to test this endpoint easily I'm",
      },
      {
        start_time: 7921400,
        end_time: 7931079,
        duration: 9679,
        text: "going to go into the terminal and I'm going to send this",
      },
      {
        start_time: 7932320,
        end_time: 7939400,
        duration: 7080,
        text: "request it's going to already work with this query and with this video ID",
      },
      {
        start_time: 7944480,
        end_time: 7951079,
        duration: 6599,
        text: "and we see a lot of things but we also see the content and I'm thinking should I just",
      },
      {
        start_time: 7951079,
        end_time: 7957159,
        duration: 6080,
        text: "return the content is anything else important here",
      },
      {
        start_time: 7957159,
        end_time: 7963320,
        duration: 6161,
        text: "for the front end where is cash and so",
      },
      {
        start_time: 7964960,
        end_time: 7971559,
        duration: 6599,
        text: "on in response metadata ID model",
      },
      {
        start_time: 7980320,
        end_time: 7989678,
        duration: 9358,
        text: "let me simplify it and just say rest.",
      },
      {
        start_time: 7989840,
        end_time: 7996400,
        duration: 6560,
        text: "send Das content so I'm simply going to send the content",
      },
      {
        start_time: 7997159,
        end_time: 8002960,
        duration: 5801,
        text: "there and if I send it again it's going just to give me the content",
      },
      {
        start_time: 8002960,
        end_time: 8008880,
        duration: 5920,
        text: "you can adjust it like depending on what information you want to send to the to the front",
      },
      {
        start_time: 8016880,
        end_time: 8021360,
        duration: 4480,
        text: "end perfect it",
      },
      {
        start_time: 8024719,
        end_time: 8031559,
        duration: 6840,
        text: "works and I think that is it for our first step into creating a",
      },
      {
        start_time: 8031559,
        end_time: 8038599,
        duration: 7040,
        text: "restful and a server for our AI agent so that in the next step our front end is",
      },
      {
        start_time: 8038599,
        end_time: 8044800,
        duration: 6201,
        text: "going to be able to interact with this server when the user write something in an input box for now let's do go ahead",
      },
      {
        start_time: 8044800,
        end_time: 8053199,
        duration: 8399,
        text: "and do G status git add get commit um",
      },
      {
        start_time: 8053199,
        end_time: 8059719,
        duration: 6520,
        text: "add rest API for our",
      },
      {
        start_time: 8059719,
        end_time: 8064400,
        duration: 4681,
        text: "backend and for the",
      },
      {
        start_time: 8065559,
        end_time: 8074159,
        duration: 8600,
        text: "agent perfect now it is time to already",
      },
      {
        start_time: 8074159,
        end_time: 8082559,
        duration: 8400,
        text: "instead of instead of doing it for C request it",
      },
      {
        start_time: 8082559,
        end_time: 8088599,
        duration: 6040,
        text: "is time to integrate the the frontend the client side application from which",
      },
      {
        start_time: 8088599,
        end_time: 8094800,
        duration: 6201,
        text: "we're going to be able to interact with our our AI agent I don't want to spend a lot of",
      },
      {
        start_time: 8094800,
        end_time: 8102719,
        duration: 7919,
        text: "time building it uh and for that reason I'm going to show you I'm going to leave in the in",
      },
      {
        start_time: 8102719,
        end_time: 8107840,
        duration: 5121,
        text: "the guide let me",
      },
      {
        start_time: 8107840,
        end_time: 8114239,
        duration: 6399,
        text: "think yeah if we look into the tutorial build AI agent with",
      },
      {
        start_time: 8114239,
        end_time: 8122079,
        duration: 7840,
        text: "lra for the front end what I did is I simply",
      },
      {
        start_time: 8122199,
        end_time: 8128199,
        duration: 6000,
        text: "created this prompt and I use entropic to build the front end for me so I told",
      },
      {
        start_time: 8128199,
        end_time: 8133320,
        duration: 5121,
        text: "it build a simple UI interface for an AI chat up with this structure with this",
      },
      {
        start_time: 8133320,
        end_time: 8140679,
        duration: 7359,
        text: "styling with this and that and that and in then we got like this AI chat interface and I think it's pretty good",
      },
      {
        start_time: 8140679,
        end_time: 8146320,
        duration: 5641,
        text: "for us uh and because I don't want to focus on building the uh the front end",
      },
      {
        start_time: 8146320,
        end_time: 8151880,
        duration: 5560,
        text: "we can reuse the same code here where we can try to reuse the same uh",
      },
      {
        start_time: 8151880,
        end_time: 8157199,
        duration: 5319,
        text: "um uh llm generation as well I'm not sure what is going to be the result so",
      },
      {
        start_time: 8157199,
        end_time: 8162480,
        duration: 5281,
        text: "it's better to use it together with me so first let's go ahead and run npm",
      },
      {
        start_time: 8162480,
        end_time: 8168440,
        duration: 5960,
        text: "create V at latest to generate a new react project but this time make sure",
      },
      {
        start_time: 8168440,
        end_time: 8174800,
        duration: 6360,
        text: "that you are not inside the server so if you are in server you can do PFD to look",
      },
      {
        start_time: 8174800,
        end_time: 8182239,
        duration: 7439,
        text: "where you are make sure to go one layer up to be if you do us to see the server",
      },
      {
        start_time: 8182239,
        end_time: 8190199,
        duration: 7960,
        text: "here and now let's go ahead and do npm create V latest let's give a project",
      },
      {
        start_time: 8190199,
        end_time: 8197000,
        duration: 6801,
        text: "name let's do chat with YouTube or let's do here",
      },
      {
        start_time: 8197800,
        end_time: 8202920,
        duration: 5120,
        text: "client let's call let's use uh a framework and the framework is going to",
      },
      {
        start_time: 8202920,
        end_time: 8208280,
        duration: 5360,
        text: "be react I'm going to use um should I use",
      },
      {
        start_time: 8208281,
        end_time: 8215920,
        duration: 7639,
        text: "typescript let's use typescript rpt and that's it now we have a client",
      },
      {
        start_time: 8215920,
        end_time: 8224120,
        duration: 8200,
        text: "side project if I'm going to go into CD client and do npm start or npm",
      },
      {
        start_time: 8224120,
        end_time: 8227760,
        duration: 3640,
        text: "install to install the",
      },
      {
        start_time: 8232840,
        end_time: 8240160,
        duration: 7320,
        text: "dependencies in van npm run Dev we're going to see a local host here",
      },
      {
        start_time: 8240160,
        end_time: 8246319,
        duration: 6159,
        text: "and if I open open it up we're going to see the starting point for a react",
      },
      {
        start_time: 8246320,
        end_time: 8252000,
        duration: 5680,
        text: "application perfect let's go ahead and as as I was saying",
      },
      {
        start_time: 8252000,
        end_time: 8260040,
        duration: 8040,
        text: "either uh use this llm to generate uh this prompt in an llm like",
      },
      {
        start_time: 8260040,
        end_time: 8265200,
        duration: 5160,
        text: "entropic or in the CLA or um",
      },
      {
        start_time: 8265200,
        end_time: 8272880,
        duration: 7680,
        text: "chbt and generate the Cod is like that or come here I'm going to leave it in",
      },
      {
        start_time: 8272880,
        end_time: 8281760,
        duration: 8880,
        text: "the comments so you have access to it uh and press the source code",
      },
      {
        start_time: 8281760,
        end_time: 8287678,
        duration: 5918,
        text: "here we're going to have the same client here in the source I'm going to look at",
      },
      {
        start_time: 8287679,
        end_time: 8294960,
        duration: 7281,
        text: "the up. TSX I'm going to copy everything here and I'm going to come into the",
      },
      {
        start_time: 8294960,
        end_time: 8302040,
        duration: 7080,
        text: "client source application based everything here and this same thing",
      },
      {
        start_time: 8302040,
        end_time: 8308280,
        duration: 6240,
        text: "for uh is it index. CSS I think so let's",
      },
      {
        start_time: 8308281,
        end_time: 8316960,
        duration: 8679,
        text: "copy everything from index. CSX and add it here by replacing everything like",
      },
      {
        start_time: 8321639,
        end_time: 8329000,
        duration: 7361,
        text: "this uh the only thing is that if you look into up. TSX it tries to connect to",
      },
      {
        start_time: 8329000,
        end_time: 8335359,
        duration: 6359,
        text: "Local Host 3000 so let's change it to 3 3,001 let's change it to 3,000 because",
      },
      {
        start_time: 8335360,
        end_time: 8343000,
        duration: 7640,
        text: "now our back end is running on 3,000 and let's try to",
      },
      {
        start_time: 8343000,
        end_time: 8349880,
        duration: 6880,
        text: "what to restart it by running npm run Dev again this is",
      },
      {
        start_time: 8349880,
        end_time: 8355200,
        duration: 5320,
        text: "the API if I open it up here boom here",
      },
      {
        start_time: 8355200,
        end_time: 8361719,
        duration: 6519,
        text: "we have a chat interface if I'm going to say what's going to happen what's going",
      },
      {
        start_time: 8361719,
        end_time: 8368279,
        duration: 6560,
        text: "to happen in the client if I if I'll say",
      },
      {
        start_time: 8368400,
        end_time: 8373840,
        duration: 5440,
        text: "hello there was an error because probably we're going to have to change a",
      },
      {
        start_time: 8373840,
        end_time: 8379359,
        duration: 5519,
        text: "little bit how we do that uh if we look into app.",
      },
      {
        start_time: 8379360,
        end_time: 8385080,
        duration: 5720,
        text: "TSX and are looking here around line",
      },
      {
        start_time: 8385080,
        end_time: 8390760,
        duration: 5680,
        text: "50 we have API generate and the data",
      },
      {
        start_time: 8390760,
        end_time: 8396600,
        duration: 5840,
        text: "here is a little bit different it does prompt it does Fred ID and it does video",
      },
      {
        start_time: 8396600,
        end_time: 8405560,
        duration: 8960,
        text: "ID let's try to do video ID like this in the server in the index what do we have",
      },
      {
        start_time: 8405560,
        end_time: 8410680,
        duration: 5120,
        text: "it should be the same SL generate slash",
      },
      {
        start_time: 8410680,
        end_time: 8417160,
        duration: 6480,
        text: "generate instead of prompt I'm using query it was easier if I use the same so",
      },
      {
        start_time: 8417160,
        end_time: 8424520,
        duration: 7360,
        text: "let's just change query here Friday is good video ID hardcoded video",
      },
      {
        start_time: 8424520,
        end_time: 8433479,
        duration: 8959,
        text: "ID hardcoded and now if I go here and say",
      },
      {
        start_time: 8433479,
        end_time: 8440680,
        duration: 7201,
        text: "hello if I reload say hello what's going on here if I look in",
      },
      {
        start_time: 8440680,
        end_time: 8452640,
        duration: 11960,
        text: "the console into the network Tab and say again hello send we see that it failed why",
      },
      {
        start_time: 8454040,
        end_time: 8457280,
        duration: 3240,
        text: "it's because of",
      },
      {
        start_time: 8465040,
        end_time: 8470479,
        duration: 5439,
        text: "a what uh response request what's going",
      },
      {
        start_time: 8470479,
        end_time: 8477479,
        duration: 7000,
        text: "on maybe our API is not running server yes fail to run",
      },
      {
        start_time: 8477479,
        end_time: 8484600,
        duration: 7121,
        text: "index I'm going to go ahead and restart start my API my server and it still",
      },
      {
        start_time: 8484600,
        end_time: 8492318,
        duration: 7718,
        text: "fails to run no now it says server running on this port if I come back here and say",
      },
      {
        start_time: 8492560,
        end_time: 8499280,
        duration: 6720,
        text: "hello okay now it gets to the API hello I'm here to help you find",
      },
      {
        start_time: 8499280,
        end_time: 8506359,
        duration: 7079,
        text: "information from YouTube video transcripts is there a specific YouTube video or topic you would like me to search for information about I can",
      },
      {
        start_time: 8506359,
        end_time: 8513560,
        duration: 7201,
        text: "retrieve relevant parts of a video transcript based on a query perfect what we're going to do is let's go ahead and",
      },
      {
        start_time: 8513560,
        end_time: 8519640,
        duration: 6080,
        text: "double check like we hardcoded vi video ID that video ID I'm just going to",
      },
      {
        start_time: 8519640,
        end_time: 8525880,
        duration: 6240,
        text: "double check in the data if we have such a video ID yeah we",
      },
      {
        start_time: 8525880,
        end_time: 8533960,
        duration: 8080,
        text: "do have and this one is is this apple style video let's",
      },
      {
        start_time: 8533960,
        end_time: 8541160,
        duration: 7200,
        text: "check what um will the viewer",
      },
      {
        start_time: 8541160,
        end_time: 8548000,
        duration: 6840,
        text: "learn by following this tutorial this is a question about a",
      },
      {
        start_time: 8548000,
        end_time: 8550520,
        duration: 2520,
        text: "specific",
      },
      {
        start_time: 8556760,
        end_time: 8562520,
        duration: 5760,
        text: "video use the tool to",
      },
      {
        start_time: 8562520,
        end_time: 8567840,
        duration: 5320,
        text: "get to get to get to get to get how is it called to get",
      },
      {
        start_time: 8567840,
        end_time: 8571840,
        duration: 4000,
        text: "uh relevant",
      },
      {
        start_time: 8577319,
        end_time: 8587398,
        duration: 10079,
        text: "transcript okay it's very insistent okay what is the topic of the",
      },
      {
        start_time: 8587720,
        end_time: 8596240,
        duration: 8520,
        text: "video you see like the the one benefit of an AI agent is that",
      },
      {
        start_time: 8596240,
        end_time: 8601760,
        duration: 5520,
        text: "it can decide like how often and how to interact with the tool in this case a",
      },
      {
        start_time: 8601760,
        end_time: 8607080,
        duration: 5320,
        text: "retrieval tool for the rag system the downside is that you lose a little bit",
      },
      {
        start_time: 8607080,
        end_time: 8615880,
        duration: 8800,
        text: "of control and as you can see here some questions the tool didn't realize that it has to inter integrate with that um",
      },
      {
        start_time: 8615880,
        end_time: 8622760,
        duration: 6880,
        text: "it has to call that tool so sometimes an old school chain of calls might be",
      },
      {
        start_time: 8622760,
        end_time: 8628200,
        duration: 5440,
        text: "better but with write prompt engineering with WR descriptions of a tool uh I",
      },
      {
        start_time: 8628200,
        end_time: 8635600,
        duration: 7400,
        text: "think you can get like where actual results and keep the benefits of having this AI agent that decides like um what",
      },
      {
        start_time: 8635600,
        end_time: 8641080,
        duration: 5480,
        text: "to to call how often to call and so on so we see that based on the transcript",
      },
      {
        start_time: 8641080,
        end_time: 8646399,
        duration: 5319,
        text: "this video appears to be aor about creating a mobile application perfect",
      },
      {
        start_time: 8646399,
        end_time: 8652479,
        duration: 6080,
        text: "amazing so we have our front end as well we have our client side as well let me",
      },
      {
        start_time: 8652479,
        end_time: 8659640,
        duration: 7161,
        text: "go ahead and do the following um I'm going to do",
      },
      {
        start_time: 8659640,
        end_time: 8666920,
        duration: 7280,
        text: "a git add G commit minus M front",
      },
      {
        start_time: 8666920,
        end_time: 8670960,
        duration: 4040,
        text: "and chat",
      },
      {
        start_time: 8676720,
        end_time: 8684920,
        duration: 8200,
        text: "interface another issue is the agent will call a tool when you don't want it to yeah that that's also true like",
      },
      {
        start_time: 8684920,
        end_time: 8691600,
        duration: 6680,
        text: "having like an agent as we have here we don't say like the word or how to do the",
      },
      {
        start_time: 8691600,
        end_time: 8697560,
        duration: 5960,
        text: "things we just give it a bunch of tools and we let it decide like when to call",
      },
      {
        start_time: 8697560,
        end_time: 8704279,
        duration: 6719,
        text: "it how to call it and so on so yeah sometimes it's going to do things that you might not do but that's it's That's",
      },
      {
        start_time: 8704279,
        end_time: 8711600,
        duration: 7321,
        text: "The Power of an autonomous agent mine likes to use the generate",
      },
      {
        start_time: 8711600,
        end_time: 8718000,
        duration: 6400,
        text: "image tool anytime it writes an image generation prompt",
      },
      {
        start_time: 8723120,
        end_time: 8729080,
        duration: 5960,
        text: "I highly doubt you're comfortable speaking like that when you are not behind the safety of the screen what do",
      },
      { start_time: 8729080, end_time: 8731240, duration: 2160, text: "you" },
      {
        start_time: 8737240,
        end_time: 8743199,
        duration: 5959,
        text: "mean oh you you have some beef chill guys it's",
      },
      {
        start_time: 8745399,
        end_time: 8751439,
        duration: 6040,
        text: "okay okay so what do we want to do next",
      },
      { start_time: 8751439, end_time: 8754439, duration: 3000, text: "guys" },
      {
        start_time: 8757600,
        end_time: 8763640,
        duration: 6040,
        text: "um what do I want to do next I know what I want to do",
      },
      {
        start_time: 8763640,
        end_time: 8769520,
        duration: 5880,
        text: "next um the next step is being able to",
      },
      {
        start_time: 8769520,
        end_time: 8775080,
        duration: 5560,
        text: "start conversation about new videos because right now in our neon database",
      },
      {
        start_time: 8775080,
        end_time: 8780319,
        duration: 5239,
        text: "we prefilled it with some transcripts from two different videos and we can",
      },
      {
        start_time: 8780319,
        end_time: 8785439,
        duration: 5120,
        text: "talk about those videos by hardcoding some data what I want to do next is to",
      },
      {
        start_time: 8785439,
        end_time: 8793200,
        duration: 7761,
        text: "be able to embed an index any kind of video that the user wants to talk about for that we",
      },
      {
        start_time: 8793200,
        end_time: 8801880,
        duration: 8680,
        text: "need to allow that to happen and one step before reaching that because we're going to do that with Bri data uh before",
      },
      {
        start_time: 8801880,
        end_time: 8809120,
        duration: 7240,
        text: "we do that I want to host our both client side and server side so that we",
      },
      {
        start_time: 8809120,
        end_time: 8818240,
        duration: 9120,
        text: "later we're going to see see like how we can connect bright data back to our system to get this data about the video",
      },
      {
        start_time: 8818240,
        end_time: 8823600,
        duration: 5360,
        text: "transcripts so what we're going to do is we now are going to host our server with",
      },
      {
        start_time: 8823600,
        end_time: 8828680,
        duration: 5080,
        text: "jio go ahead jio.com where you can follow the link in the description by",
      },
      {
        start_time: 8828680,
        end_time: 8836080,
        duration: 7400,
        text: "the way uh this part of the video is sponsored by jio so thank you very much jio for making this possible and you can",
      },
      {
        start_time: 8836080,
        end_time: 8841120,
        duration: 5040,
        text: "go uh on janio you're going to go into products deployment",
      },
      {
        start_time: 8841120,
        end_time: 8847279,
        duration: 6159,
        text: "platform and you can uh go ahead in the documentation create an",
      },
      {
        start_time: 8847279,
        end_time: 8854600,
        duration: 7321,
        text: "account and you can see different Frameworks and tutorials how to um",
      },
      {
        start_time: 8854600,
        end_time: 8857080,
        duration: 2480,
        text: "deploy",
      },
      {
        start_time: 8864279,
        end_time: 8870920,
        duration: 6641,
        text: "them in the genesio CLI let's go ahead and install genesio first by doing npm",
      },
      {
        start_time: 8870920,
        end_time: 8876160,
        duration: 5240,
        text: "install genesio DG in the terminal I'm going to do that",
      },
      {
        start_time: 8876160,
        end_time: 8882080,
        duration: 5920,
        text: "here I already have it installed but it that is not bad to update it as well uh",
      },
      {
        start_time: 8882080,
        end_time: 8890000,
        duration: 7920,
        text: "and then we have to run genesio login let me double check",
      },
      {
        start_time: 8892520,
        end_time: 8898239,
        duration: 5719,
        text: "that yeah need this one but",
      },
      {
        start_time: 8909160,
        end_time: 8914880,
        duration: 5720,
        text: "make sure to create a genesio account and then you're going to need",
      },
      {
        start_time: 8914880,
        end_time: 8921840,
        duration: 6960,
        text: "the deployment the the API key from there and you're going to run",
      },
      {
        start_time: 8924200,
        end_time: 8932040,
        duration: 7840,
        text: "genesio is it login I forgot like how to to connect it with our",
      },
      {
        start_time: 8935359,
        end_time: 8941359,
        duration: 6000,
        text: "yes jio login to the platform so if you run jio",
      },
      {
        start_time: 8941399,
        end_time: 8946680,
        duration: 5281,
        text: "login you're going to connect it with your account after that we can start",
      },
      {
        start_time: 8946680,
        end_time: 8953960,
        duration: 7280,
        text: "deploying our application but before deploying I'm going to create um genesio",
      },
      {
        start_time: 8953960,
        end_time: 8962600,
        duration: 8640,
        text: "do yaml file that will specify how do we want to deploy our po server and the",
      },
      {
        start_time: 8962600,
        end_time: 8967960,
        duration: 5360,
        text: "client um VL uh I'll will also provide it in the guide so you don't have to",
      },
      {
        start_time: 8967960,
        end_time: 8976358,
        duration: 8398,
        text: "write it but I will write it quickly so uh I will comment like what everything means so first we",
      },
      {
        start_time: 8976560,
        end_time: 8983840,
        duration: 7280,
        text: "have let me do it like this so I have a reference so the name is going to be the",
      },
      {
        start_time: 8983840,
        end_time: 8991640,
        duration: 7800,
        text: "name of our project let's call it YouTube chat",
      },
      {
        start_time: 8991640,
        end_time: 9002160,
        duration: 10520,
        text: "application you can specify the region where you want to deploy it for example Us East one and let's do yaml version",
      },
      {
        start_time: 9002160,
        end_time: 9008520,
        duration: 6360,
        text: "two next we we have two things one of them is the back end and another one",
      },
      {
        start_time: 9008520,
        end_time: 9015479,
        duration: 6959,
        text: "later is going to be the front end but first let's focus on the back end the back end you specify the puff to it so",
      },
      {
        start_time: 9015479,
        end_time: 9020840,
        duration: 5361,
        text: "the puff is This Server so let's say server then",
      },
      {
        start_time: 9020840,
        end_time: 9028720,
        duration: 7880,
        text: "language uh we're going to say name is uh GS and you can also specify the",
      },
      {
        start_time: 9028720,
        end_time: 9038040,
        duration: 9320,
        text: "package package manager in my case I will specify npm now back in this line with language",
      },
      {
        start_time: 9038040,
        end_time: 9043279,
        duration: 5239,
        text: "we're going to also have a environment",
      },
      {
        start_time: 9043359,
        end_time: 9052040,
        duration: 8681,
        text: "that I don't know we'll have for example the API URL which is going to be the actual URL of uh our",
      },
      {
        start_time: 9052040,
        end_time: 9059200,
        duration: 7160,
        text: "API let's say ABC for a second after that in our back end we're",
      },
      {
        start_time: 9059200,
        end_time: 9064640,
        duration: 5440,
        text: "going to have some functions the function that we're going to have let's",
      },
      {
        start_time: 9064640,
        end_time: 9072120,
        duration: 7480,
        text: "say that it's going to be name API simply",
      },
      {
        start_time: 9072439,
        end_time: 9079680,
        duration: 7241,
        text: "API the puff to that function is going to be because relative to the back and",
      },
      {
        start_time: 9079680,
        end_time: 9088319,
        duration: 8639,
        text: "puff server our function is going to be this puff so it's going to be dot slash the",
      },
      {
        start_time: 9088319,
        end_time: 9093560,
        duration: 5241,
        text: "Handler or the entry actually the entry is going to be index",
      },
      {
        start_time: 9093560,
        end_time: 9099560,
        duration: 6000,
        text: "file so index dogs and the",
      },
      {
        start_time: 9099560,
        end_time: 9106040,
        duration: 6480,
        text: "type is going to be HTTP server so Jano is going to run a",
      },
      {
        start_time: 9106040,
        end_time: 9111960,
        duration: 5920,
        text: "function that is going to serve our express",
      },
      {
        start_time: 9111960,
        end_time: 9118160,
        duration: 6200,
        text: "application now in this environment API URL I want the whole backend to have",
      },
      {
        start_time: 9118160,
        end_time: 9123960,
        duration: 5800,
        text: "access to the URL of where is our backend deployed so we can access it",
      },
      {
        start_time: 9123960,
        end_time: 9131080,
        duration: 7120,
        text: "dynamically like this by saying that I will look into the backend so",
      },
      {
        start_time: 9131080,
        end_time: 9140800,
        duration: 9720,
        text: "backend dot functions functions. name API do URL and",
      },
      {
        start_time: 9140800,
        end_time: 9145960,
        duration: 5160,
        text: "this is going to be uh provided as a environment variable API URL everywhere",
      },
      {
        start_time: 9145960,
        end_time: 9152439,
        duration: 6479,
        text: "in our backend we're going to see why we need it later now that we have our back end",
      },
      {
        start_time: 9152439,
        end_time: 9158319,
        duration: 5880,
        text: "done let's go ahead and focus on the front end in case of a front end",
      },
      {
        start_time: 9158319,
        end_time: 9165680,
        duration: 7361,
        text: "um the path is going to be client we are going to say what do we",
      },
      {
        start_time: 9165680,
        end_time: 9173200,
        duration: 7520,
        text: "want to publish and we're going to publish with this folder with this folder is something that is going to be",
      },
      {
        start_time: 9173200,
        end_time: 9180359,
        duration: 7159,
        text: "generated uh if we run a script when we want to",
      },
      {
        start_time: 9180359,
        end_time: 9185960,
        duration: 5601,
        text: "deploy npm run build so if we run npm run build in the client is going to",
      },
      {
        start_time: 9185960,
        end_time: 9193920,
        duration: 7960,
        text: "generate um this dist folder and that this folder is what we want to send and",
      },
      {
        start_time: 9194399,
        end_time: 9199960,
        duration: 5561,
        text: "publish uh finally we need some environment here as well as we have on",
      },
      {
        start_time: 9199960,
        end_time: 9209278,
        duration: 9318,
        text: "the back end something similar to here where is it I need some",
      },
      {
        start_time: 9209680,
        end_time: 9215520,
        duration: 5840,
        text: "spaces but in this case it's a little bit differently uh it should be prefix",
      },
      {
        start_time: 9215520,
        end_time: 9221399,
        duration: 5879,
        text: "with vcore API URL if you do V it's going to be accessible in the client",
      },
      {
        start_time: 9221399,
        end_time: 9227160,
        duration: 5761,
        text: "side code there that's it now let's go ahead open",
      },
      {
        start_time: 9227160,
        end_time: 9234000,
        duration: 6840,
        text: "the terminal and try to uh you can also do genio local to run it locally or you",
      },
      {
        start_time: 9234000,
        end_time: 9241000,
        duration: 7000,
        text: "can do jio deploy to deploy it to jio hosting it says that we detect that",
      },
      {
        start_time: 9241000,
        end_time: 9247720,
        duration: 6720,
        text: "entropic and open Ai and DB URL are not set remotely do you want us to set them for you let's do yes and I think it's",
      },
      {
        start_time: 9247720,
        end_time: 9253119,
        duration: 5399,
        text: "going to look for this configuration and set them remotely",
      },
      {
        start_time: 9268680,
        end_time: 9275319,
        duration: 6639,
        text: "uh everything on the back end work correctly the front end this does not exist uh I was expecting it to run",
      },
      {
        start_time: 9275319,
        end_time: 9281479,
        duration: 6160,
        text: "automatically npm run build oh I think the problem is here it should be scripts",
      },
      {
        start_time: 9281479,
        end_time: 9287880,
        duration: 6401,
        text: "not script because I can run it myself but it should run automatically when the",
      },
      {
        start_time: 9287880,
        end_time: 9293760,
        duration: 5880,
        text: "engine are deployed so let's try again by changing it to",
      },
      {
        start_time: 9310640,
        end_time: 9315720,
        duration: 5080,
        text: "scripts and what do we see we see that the function is deployed we see that is",
      },
      {
        start_time: 9315720,
        end_time: 9320840,
        duration: 5120,
        text: "building the back the front end we see that because we didn't provide any",
      },
      {
        start_time: 9320840,
        end_time: 9326680,
        duration: 5840,
        text: "subdomain it automatically addited it for us in Vis jio yaml like this",
      },
      {
        start_time: 9326680,
        end_time: 9331760,
        duration: 5080,
        text: "automatically generated we see the link to the application dashboard and the",
      },
      {
        start_time: 9331760,
        end_time: 9337399,
        duration: 5639,
        text: "link to the front end if I open front end what's going to",
      },
      {
        start_time: 9337399,
        end_time: 9344800,
        duration: 7401,
        text: "happen we see that our AI chat has been hosted and we can say hello and if it",
      },
      {
        start_time: 9344800,
        end_time: 9351920,
        duration: 7120,
        text: "can connect with our backend as well that means that everything is perfect perly configured and as we can see it",
      },
      {
        start_time: 9351920,
        end_time: 9358399,
        duration: 6479,
        text: "actually is and we can ask things about the video what is the video",
      },
      {
        start_time: 9358399,
        end_time: 9364240,
        duration: 5841,
        text: "about and it's going to interact with our neon",
      },
      {
        start_time: 9364240,
        end_time: 9371760,
        duration: 7520,
        text: "database it didn't know it didn't call the tool but later it it will everything",
      },
      {
        start_time: 9371760,
        end_time: 9376920,
        duration: 5160,
        text: "works or maybe not let me actually try",
      },
      {
        start_time: 9376920,
        end_time: 9384000,
        duration: 7080,
        text: "um what is the video topic based on",
      },
      {
        start_time: 9384319,
        end_time: 9389479,
        duration: 5160,
        text: "the retrieved",
      },
      {
        start_time: 9389479,
        end_time: 9394600,
        duration: 5121,
        text: "transcript being more specific like what it should do like you know like I don't",
      },
      {
        start_time: 9394600,
        end_time: 9402000,
        duration: 7400,
        text: "have any retrieve transcript yet to search no you actually have",
      },
      {
        start_time: 9402000,
        end_time: 9407720,
        duration: 5720,
        text: "um you actually have just try it trust",
      },
      {
        start_time: 9407720,
        end_time: 9411520,
        duration: 3800,
        text: "me you have transcript",
      },
      {
        start_time: 9416560,
        end_time: 9422680,
        duration: 6120,
        text: "will it believe me I think it does because it's yeah based on the retrieve transcript the video appears to be about",
      },
      {
        start_time: 9422680,
        end_time: 9429800,
        duration: 7120,
        text: "up development uh blah blah blah and so on and so on perfect",
      },
      {
        start_time: 9429800,
        end_time: 9436600,
        duration: 6800,
        text: "amazing so this URL now is publicly accessible because we use jio to to host",
      },
      {
        start_time: 9436600,
        end_time: 9442000,
        duration: 5400,
        text: "it very easily I will give it to you but I don't know if I",
      },
      {
        start_time: 9442000,
        end_time: 9446880,
        duration: 4880,
        text: "should give it to you but you saw it so it",
      },
      {
        start_time: 9447399,
        end_time: 9453160,
        duration: 5761,
        text: "depends uh if we open here janio in the dashboard we see that we have a function",
      },
      {
        start_time: 9453160,
        end_time: 9460160,
        duration: 7000,
        text: "and we have a front end if you want to debug the functions you're going to go into the",
      },
      {
        start_time: 9460160,
        end_time: 9468080,
        duration: 7920,
        text: "monitoring or into the logs and you're going to see different logs from your function calls you actually here just",
      },
      {
        start_time: 9468080,
        end_time: 9475960,
        duration: 7880,
        text: "try it this is very um input so yeah this is how easy it is to",
      },
      {
        start_time: 9475960,
        end_time: 9483840,
        duration: 7880,
        text: "deploy uh full stack applications both front end and back end with genesio perfect now in The Next Step let",
      },
      {
        start_time: 9483840,
        end_time: 9489000,
        duration: 5160,
        text: "me actually go ahead and do get add",
      },
      {
        start_time: 9489000,
        end_time: 9495600,
        duration: 6600,
        text: "deploy to genesio in the next step we are going to",
      },
      {
        start_time: 9495600,
        end_time: 9501439,
        duration: 5839,
        text: "um add functionalities to interact with bright data and to",
      },
      {
        start_time: 9501600,
        end_time: 9506760,
        duration: 5160,
        text: "scrape the transcripts of the videos that the user",
      },
      {
        start_time: 9511000,
        end_time: 9518600,
        duration: 7600,
        text: "needs seems like convex would be a better option for the database how did you settle on new one",
      },
      {
        start_time: 9518600,
        end_time: 9525760,
        duration: 7160,
        text: "uh I just wanted something simple like postgress and that's why like when I need just a simple",
      },
      {
        start_time: 9525760,
        end_time: 9532040,
        duration: 6280,
        text: "barebone pogress I go to to new one but but um I haven't worked with convex yet",
      },
      {
        start_time: 9532040,
        end_time: 9538160,
        duration: 6120,
        text: "actually and I'm pretty sure like if it's build like exactly for for for that",
      },
      {
        start_time: 9538160,
        end_time: 9545000,
        duration: 6840,
        text: "one it would be better but it's super simple to change the only thing that you would have to change is in the",
      },
      {
        start_time: 9545000,
        end_time: 9551600,
        duration: 6600,
        text: "server in our embedding here in the vector store you're going to initialize",
      },
      {
        start_time: 9551600,
        end_time: 9557640,
        duration: 6040,
        text: "a different Vector store and L chain integrates with convex HS it's possible",
      },
      {
        start_time: 9557640,
        end_time: 9562760,
        duration: 5120,
        text: "like that as well give me one second I'm going to take a very very short break",
      },
      {
        start_time: 9562760,
        end_time: 9566680,
        duration: 3920,
        text: "and I come back and we continue with our",
      },
      {
        start_time: 9588319,
        end_time: 9592359,
        duration: 4040,
        text: "implementation for",
      },
      {
        start_time: 9647200,
        end_time: 9651200,
        duration: 4000,
        text: "hello so",
      },
      {
        start_time: 9653560,
        end_time: 9657438,
        duration: 3878,
        text: "let me just double check",
      },
      {
        start_time: 9666800,
        end_time: 9675800,
        duration: 9000,
        text: "something um I'm thinking how to design the user",
      },
      {
        start_time: 9675800,
        end_time: 9679800,
        duration: 4000,
        text: "experience of",
      },
      {
        start_time: 9680920,
        end_time: 9688560,
        duration: 7640,
        text: "of starting of of indexing a video that's that's",
      },
      {
        start_time: 9688560,
        end_time: 9694560,
        duration: 6000,
        text: "what I wanted to say my initial idea was before we",
      },
      {
        start_time: 9694560,
        end_time: 9700880,
        duration: 6320,
        text: "start and actually I had it before we start an AI chat we have to we have an",
      },
      {
        start_time: 9700880,
        end_time: 9707640,
        duration: 6760,
        text: "input we have a um an input where we put the video ID not the video ID the video",
      },
      {
        start_time: 9707640,
        end_time: 9712800,
        duration: 5160,
        text: "URL and then we take take the URL we scrape it we index it and only then we",
      },
      {
        start_time: 9712800,
        end_time: 9718800,
        duration: 6000,
        text: "open up the chat and we can talk with that video now that now that I'm thinking",
      },
      {
        start_time: 9718800,
        end_time: 9725520,
        duration: 6720,
        text: "wouldn't it be better if we just have a chat interface and we paste a YouTube",
      },
      {
        start_time: 9725520,
        end_time: 9730640,
        duration: 5120,
        text: "video here and we start talking about it then we paste another video here and we",
      },
      {
        start_time: 9730640,
        end_time: 9740000,
        duration: 9360,
        text: "talk about it and so on what do you think um how should we index videos",
      },
      {
        start_time: 9740000,
        end_time: 9748160,
        duration: 8160,
        text: "more free flow in a chat way where our AI agent is going to have a tool that",
      },
      {
        start_time: 9748160,
        end_time: 9754160,
        duration: 6000,
        text: "knows how to index videos or a more structured way where we have like an",
      },
      {
        start_time: 9754160,
        end_time: 9760560,
        duration: 6400,
        text: "input give me the video ID I'm going to index it and then we open a chart with that",
      },
      {
        start_time: 9760560,
        end_time: 9767720,
        duration: 7160,
        text: "video let me know in the comments like in the in the chat what what do you think would be better what you would",
      },
      {
        start_time: 9767720,
        end_time: 9773200,
        duration: 5480,
        text: "like to see for example come",
      },
      {
        start_time: 9779319,
        end_time: 9785040,
        duration: 5721,
        text: "on because there let me close some of the stuff",
      },
      {
        start_time: 9785040,
        end_time: 9793640,
        duration: 8600,
        text: "down this is we need it I don't need this ones",
      },
      {
        start_time: 9814439,
        end_time: 9824359,
        duration: 9920,
        text: "because in any way we're going to use Bri data to uh to fetch or to scrape the",
      },
      {
        start_time: 9824359,
        end_time: 9831080,
        duration: 6721,
        text: "video data from YouTube we already saw how to do that uh uh and what we did is",
      },
      {
        start_time: 9831080,
        end_time: 9837439,
        duration: 6359,
        text: "we want to Bright data we created an account then under web scrapers we go to",
      },
      {
        start_time: 9837439,
        end_time: 9843479,
        duration: 6040,
        text: "web scrapers Library we are searching for YouTube and we see that there are",
      },
      {
        start_time: 9843479,
        end_time: 9851439,
        duration: 7960,
        text: "eight different scrapers for YouTube while we are interested in this collect videos by URL so I'm going to click on",
      },
      {
        start_time: 9851439,
        end_time: 9859479,
        duration: 8040,
        text: "it scrape our API let's do next and here in the API request Builder",
      },
      {
        start_time: 9861319,
        end_time: 9866600,
        duration: 5281,
        text: "in the API request Builder we add the API token we add some inputs and we see",
      },
      {
        start_time: 9866600,
        end_time: 9875560,
        duration: 8960,
        text: "a c command in this part we can also see how we can do that from node using fetch if",
      },
      {
        start_time: 9875560,
        end_time: 9881920,
        duration: 6360,
        text: "I do that I can and also if I'm going to do a couple",
      },
      {
        start_time: 9881920,
        end_time: 9889040,
        duration: 7120,
        text: "of things I need to include the errors that's good and I don't need to delete",
      },
      {
        start_time: 9889040,
        end_time: 9895960,
        duration: 6920,
        text: "deliver results to S free storage I'm going to unselect that one but I want to send it to a web hook sending the",
      },
      {
        start_time: 9895960,
        end_time: 9902920,
        duration: 6960,
        text: "response to a web hook uh the way it's going to work is oh I didn't show the the",
      },
      {
        start_time: 9902920,
        end_time: 9910840,
        duration: 7920,
        text: "parts let me do it again so the thing is that uh we are",
      },
      {
        start_time: 9910840,
        end_time: 9919000,
        duration: 8160,
        text: "still going to use bright data so going on bright data um dashboard we're going to go under web",
      },
      {
        start_time: 9919000,
        end_time: 9925960,
        duration: 6960,
        text: "scrapers come on why it's not changing here so bright data dashboard web",
      },
      {
        start_time: 9925960,
        end_time: 9931160,
        duration: 5200,
        text: "scrapers web scrapers library and we are searching for",
      },
      {
        start_time: 9931160,
        end_time: 9938279,
        duration: 7119,
        text: "YouTube we're looking at the YouTube videos post and we select scraper",
      },
      {
        start_time: 9938279,
        end_time: 9944960,
        duration: 6681,
        text: "API here we see that we already saw in the API request",
      },
      {
        start_time: 9944960,
        end_time: 9950000,
        duration: 5040,
        text: "Builder but we just send the URL of a video and as a result we're going to get",
      },
      {
        start_time: 9950000,
        end_time: 9956880,
        duration: 6880,
        text: "the scrape data including the transcript we're going to configure it a",
      },
      {
        start_time: 9956880,
        end_time: 9963000,
        duration: 6120,
        text: "little bit for example I'm going to delete and leave only one input it's going to be",
      },
      {
        start_time: 9963000,
        end_time: 9968160,
        duration: 5160,
        text: "easier for me to see there eror I'm going to deselect deliver results to",
      },
      {
        start_time: 9968160,
        end_time: 9974840,
        duration: 6680,
        text: "external storage and I'm going to send send to web hook that means",
      },
      {
        start_time: 9974840,
        end_time: 9980120,
        duration: 5280,
        text: "that when we send this request to to Bri",
      },
      {
        start_time: 9980120,
        end_time: 9985640,
        duration: 5520,
        text: "dat data set trigger we are sending a request to start the scraping job but",
      },
      {
        start_time: 9985640,
        end_time: 9991399,
        duration: 5759,
        text: "because scraping jobs can be it's a long time task it can be a couple of seconds",
      },
      {
        start_time: 9991399,
        end_time: 9997800,
        duration: 6401,
        text: "but if there is lots of data it can be minutes um depending on the collection",
      },
      {
        start_time: 9997800,
        end_time: 10003439,
        duration: 5639,
        text: "this one we see that on average is 7 Seconds anyway instead of waiting for",
      },
      {
        start_time: 10003439,
        end_time: 10010640,
        duration: 7201,
        text: "the result we just trigger the request and then we can either re send another",
      },
      {
        start_time: 10010640,
        end_time: 10016120,
        duration: 5480,
        text: "request to check the status where we can give Bri data a",
      },
      {
        start_time: 10016120,
        end_time: 10023160,
        duration: 7040,
        text: "URL that bright data is going to call when it finishes the scraping job that's",
      },
      {
        start_time: 10023160,
        end_time: 10028240,
        duration: 5080,
        text: "what we're going to do we're going to do here let's do",
      },
      {
        start_time: 10029399,
        end_time: 10037319,
        duration: 7920,
        text: "HTTP example.com and later we're going to fetch it change",
      },
      {
        start_time: 10037319,
        end_time: 10042640,
        duration: 5321,
        text: "it let's do example com/",
      },
      {
        start_time: 10042640,
        end_time: 10049359,
        duration: 6719,
        text: "webhook this means that hey bright data when you finish scraping this job send",
      },
      {
        start_time: 10049359,
        end_time: 10057720,
        duration: 8361,
        text: "this data here and the file format I'm going to leave it to Json and in",
      },
      {
        start_time: 10057720,
        end_time: 10064240,
        duration: 6520,
        text: "the example request instead of Linux bash I'm going to do node fetch here is",
      },
      {
        start_time: 10064240,
        end_time: 10070359,
        duration: 6119,
        text: "a good example of how we can send this request let me copy it let's go in our",
      },
      {
        start_time: 10070359,
        end_time: 10080760,
        duration: 10401,
        text: "server and I'm going to call create a new uh new file let's call it bright",
      },
      {
        start_time: 10080760,
        end_time: 10086560,
        duration: 5800,
        text: "dat. GS and let's export",
      },
      {
        start_time: 10086560,
        end_time: 10092840,
        duration: 6280,
        text: "const uh start",
      },
      {
        start_time: 10092840,
        end_time: 10099398,
        duration: 6558,
        text: "or Trigger YouTube video",
      },
      {
        start_time: 10103319,
        end_time: 10110160,
        duration: 6841,
        text: "scrape we have the URL of a video and what we have to do is we're going to",
      },
      {
        start_time: 10110160,
        end_time: 10115600,
        duration: 5440,
        text: "paste the code that bright data gave us so we're going to change it a little bit",
      },
      {
        start_time: 10115600,
        end_time: 10122520,
        duration: 6920,
        text: "for example we do not need to import fetch from anywhere I'm going to remove it because it's going to be there in the",
      },
      {
        start_time: 10122520,
        end_time: 10131240,
        duration: 8720,
        text: "data this is the input so this is the URL that is going to be um s here so what I'm going to do is",
      },
      {
        start_time: 10131240,
        end_time: 10138561,
        duration: 7321,
        text: "maybe I'm going to call this trigger scrape input with this",
      },
      {
        start_time: 10138840,
        end_time: 10146720,
        duration: 7880,
        text: "URL not with this URL with this URL and here I'm going to Simply take",
      },
      {
        start_time: 10146720,
        end_time: 10151960,
        duration: 5240,
        text: "the URL from the parameters and send it to Bright data like",
      },
      {
        start_time: 10151960,
        end_time: 10157000,
        duration: 5040,
        text: "this maybe we can adjust it to send multiple uh videos as well but for now",
      },
      {
        start_time: 10157000,
        end_time: 10162840,
        duration: 5840,
        text: "it's good like this then what we do here is we send a fetch",
      },
      {
        start_time: 10162840,
        end_time: 10168000,
        duration: 5160,
        text: "to this long URL but let's break it down",
      },
      {
        start_time: 10168000,
        end_time: 10172160,
        duration: 4160,
        text: "for example I'm going to break it down",
      },
      {
        start_time: 10174279,
        end_time: 10180200,
        duration: 5921,
        text: "into maybe like this everything until slash",
      },
      {
        start_time: 10180200,
        end_time: 10189160,
        duration: 8960,
        text: "trigger let's do here const bright data trigger URL is going",
      },
      {
        start_time: 10189160,
        end_time: 10196000,
        duration: 6840,
        text: "to be equal to this one let's take it and let's transform",
      },
      {
        start_time: 10196000,
        end_time: 10201561,
        duration: 5561,
        text: "this URL into a template string with your back",
      },
      {
        start_time: 10201800,
        end_time: 10210479,
        duration: 8679,
        text: "ticks come on back tick here so that we can replace",
      },
      {
        start_time: 10210479,
        end_time: 10216720,
        duration: 6241,
        text: "this URL with simply saying bright data trigger URL then we",
      },
      {
        start_time: 10216720,
        end_time: 10224120,
        duration: 7400,
        text: "have data set ID data set ID identifies this YouTube video post data set it can",
      },
      {
        start_time: 10224120,
        end_time: 10230600,
        duration: 6480,
        text: "also be dynamic if you want I leave it like this endp point is where do we want",
      },
      {
        start_time: 10230600,
        end_time: 10239120,
        duration: 8520,
        text: "to send the results to where do we want to send the results to well we want to send it back to our",
      },
      {
        start_time: 10239120,
        end_time: 10247080,
        duration: 7960,
        text: "API back to our server so in our index here let's go ahead and",
      },
      {
        start_time: 10247080,
        end_time: 10254120,
        duration: 7040,
        text: "create a post post request called Web",
      },
      {
        start_time: 10255880,
        end_time: 10261800,
        duration: 5920,
        text: "hook request response and let's simply go conso log request.",
      },
      {
        start_time: 10261800,
        end_time: 10269880,
        duration: 8080,
        text: "body to see what data we're going to receive here now we have to say hey Bri data",
      },
      {
        start_time: 10269880,
        end_time: 10275880,
        duration: 6000,
        text: "simply call back the server here at SL",
      },
      {
        start_time: 10275880,
        end_time: 10285560,
        duration: 9680,
        text: "web hook but the URL we don't know we can hardcode it from uh from genisio",
      },
      {
        start_time: 10285560,
        end_time: 10290800,
        duration: 5240,
        text: "platform but remember in jio yaml we said that we're going to give a",
      },
      {
        start_time: 10290800,
        end_time: 10296160,
        duration: 5360,
        text: "environment variable called API URL that's what we why we need it we need it",
      },
      {
        start_time: 10296160,
        end_time: 10304760,
        duration: 8600,
        text: "to dynamically say hey the const call",
      },
      {
        start_time: 10304760,
        end_time: 10309840,
        duration: 5080,
        text: "back or web hook URL is going to be this",
      },
      {
        start_time: 10309840,
        end_time: 10317960,
        duration: 8120,
        text: "one but actually it's going to be I'm going to change here",
      },
      {
        start_time: 10317960,
        end_time: 10323680,
        duration: 5720,
        text: "to process. env. API URL SL",
      },
      {
        start_time: 10323680,
        end_time: 10330960,
        duration: 7280,
        text: "webhook b/ web Hook is important because it's our endpoint implemented",
      },
      {
        start_time: 10330960,
        end_time: 10337399,
        duration: 6439,
        text: "here okay so let's change the endpoint here pay attention of how we're going to",
      },
      {
        start_time: 10337399,
        end_time: 10344319,
        duration: 6920,
        text: "do it this HTTP example.com webhook Until the End we're going to delete and",
      },
      {
        start_time: 10344319,
        end_time: 10351439,
        duration: 7120,
        text: "replace it with the web hook URL then we have format Json is good uncompressed",
      },
      {
        start_time: 10351439,
        end_time: 10356680,
        duration: 5241,
        text: "web hook true and include errors true everything is good here now the method",
      },
      {
        start_time: 10356680,
        end_time: 10365439,
        duration: 8759,
        text: "is post authorization uh headers this is the bright data uh your API key so it's",
      },
      {
        start_time: 10365439,
        end_time: 10372359,
        duration: 6920,
        text: "better to take it from here and add it to the environment variables as bright",
      },
      {
        start_time: 10372359,
        end_time: 10375080,
        duration: 2721,
        text: "data API",
      },
      {
        start_time: 10381840,
        end_time: 10389080,
        duration: 7240,
        text: "key and back here we're going to replace it again with",
      },
      {
        start_time: 10389080,
        end_time: 10393960,
        duration: 4880,
        text: "a with process.env",
      },
      {
        start_time: 10394479,
        end_time: 10400640,
        duration: 6161,
        text: "do bright come on should be bright data API",
      },
      {
        start_time: 10400640,
        end_time: 10405800,
        duration: 5160,
        text: "key then content type Json and for the body we give this",
      },
      {
        start_time: 10405800,
        end_time: 10412479,
        duration: 6679,
        text: "data I don't like the dot van so what I'm going to do I'm going to before fetch I'm going to say",
      },
      {
        start_time: 10412479,
        end_time: 10420080,
        duration: 7601,
        text: "const response equal a weight then I'm going to put here I'm",
      },
      {
        start_time: 10420080,
        end_time: 10427920,
        duration: 7840,
        text: "going to stop and what we have then we have data so const data equal a weit",
      },
      {
        start_time: 10427920,
        end_time: 10435080,
        duration: 7160,
        text: "response Json and that's it and maybe you can also do a try",
      },
      {
        start_time: 10435080,
        end_time: 10444200,
        duration: 9120,
        text: "catch maybe we can do result and we can do console log",
      },
      {
        start_time: 10444680,
        end_time: 10450520,
        duration: 5840,
        text: "result and this is our function that is going to trigger a scraping job for a",
      },
      {
        start_time: 10450520,
        end_time: 10460560,
        duration: 10040,
        text: "video URL we can do that by again we simply call it here maybe we",
      },
      {
        start_time: 10460560,
        end_time: 10468640,
        duration: 8080,
        text: "can we should call it at the end right not at the top so we can give here a YouTube url",
      },
      {
        start_time: 10468640,
        end_time: 10476720,
        duration: 8080,
        text: "like this one and we can do let's do CD",
      },
      {
        start_time: 10476720,
        end_time: 10484880,
        duration: 8160,
        text: "server clear and I'm going to do node EnV file and",
      },
      {
        start_time: 10484880,
        end_time: 10491239,
        duration: 6359,
        text: "let's run the BR data GS this",
      },
      {
        start_time: 10491239,
        end_time: 10497160,
        duration: 5921,
        text: "function so we see that as a result we get the snapshot ID if we look into the",
      },
      {
        start_time: 10497160,
        end_time: 10504279,
        duration: 7119,
        text: "Bri data logs we should have a new job here and",
      },
      {
        start_time: 10504279,
        end_time: 10509920,
        duration: 5641,
        text: "if we look at this snapshot ID ending with 9 Q this is the last one here it",
      },
      {
        start_time: 10509920,
        end_time: 10518080,
        duration: 8160,
        text: "took 5 Seconds to complete we can download or we can check what happened",
      },
      {
        start_time: 10518080,
        end_time: 10521479,
        duration: 3399,
        text: "there with the",
      },
      {
        start_time: 10523439,
        end_time: 10528640,
        duration: 5201,
        text: "endpoint um we haven't deployed it yet so give me a",
      },
      {
        start_time: 10528640,
        end_time: 10534319,
        duration: 5679,
        text: "second but if we look here back in our API",
      },
      {
        start_time: 10534319,
        end_time: 10543238,
        duration: 8919,
        text: "request Builder and you put here the URL of our genesio let's",
      },
      {
        start_time: 10543760,
        end_time: 10548920,
        duration: 5160,
        text: "see uh let's first stop this one and let's deploy",
      },
      {
        start_time: 10548920,
        end_time: 10554160,
        duration: 5240,
        text: "our update our update has this SL web",
      },
      {
        start_time: 10554160,
        end_time: 10561239,
        duration: 7079,
        text: "hook endpoint yeah because we need to go one",
      },
      {
        start_time: 10561239,
        end_time: 10566479,
        duration: 5240,
        text: "above to be in the root we detected a new bright data let's",
      },
      {
        start_time: 10566479,
        end_time: 10571479,
        duration: 5000,
        text: "set it remotely automatically for us",
      },
      {
        start_time: 10592680,
        end_time: 10601479,
        duration: 8799,
        text: "um so we see that the function API is this URL so I can copy it and basically",
      },
      {
        start_time: 10601479,
        end_time: 10607040,
        duration: 5561,
        text: "use this one in the notify URL or no in the send web hook so send",
      },
      {
        start_time: 10607040,
        end_time: 10612160,
        duration: 5120,
        text: "to web hook web hook URL this URL of my",
      },
      {
        start_time: 10612160,
        end_time: 10616880,
        duration: 4720,
        text: "function you can also open it in the",
      },
      {
        start_time: 10622279,
        end_time: 10628479,
        duration: 6200,
        text: "dashboard and here you're going to see a function URL",
      },
      {
        start_time: 10628479,
        end_time: 10635600,
        duration: 7121,
        text: "and we need to also do slash web hook you can also press test web",
      },
      {
        start_time: 10635600,
        end_time: 10643640,
        duration: 8040,
        text: "hook and this is going to test send a test result and we see test sent successfully if we go into the jio into",
      },
      {
        start_time: 10643640,
        end_time: 10650960,
        duration: 7320,
        text: "the logs we're going to see a test a request body this was the test",
      },
      {
        start_time: 10650960,
        end_time: 10656278,
        duration: 5318,
        text: "that was sent for us and we received it in our",
      },
      {
        start_time: 10656680,
        end_time: 10665399,
        duration: 8719,
        text: "backend uh in our backend invest SL web hook that means that now if I am going",
      },
      {
        start_time: 10665399,
        end_time: 10672200,
        duration: 6801,
        text: "to invoke the same function again for",
      },
      {
        start_time: 10672200,
        end_time: 10678520,
        duration: 6320,
        text: "example Trigger YouTube video with this URL by this is a little bit hacky right",
      },
      {
        start_time: 10678520,
        end_time: 10683800,
        duration: 5280,
        text: "now but in a second we're going to connect it with our API and it's going to make a lot more sense but I want to",
      },
      {
        start_time: 10683800,
        end_time: 10689200,
        duration: 5400,
        text: "trigger a new scraping job and I want it to automatically call our web hook so if",
      },
      {
        start_time: 10689200,
        end_time: 10695319,
        duration: 6119,
        text: "I go into the server and do node bright data GS that",
      },
      {
        start_time: 10695319,
        end_time: 10702040,
        duration: 6721,
        text: "is calling this function we see this snapshot and this",
      },
      {
        start_time: 10702040,
        end_time: 10707920,
        duration: 5880,
        text: "snapshot if I look into the logs it's ready and it's supposed to call our",
      },
      {
        start_time: 10707920,
        end_time: 10714279,
        duration: 6359,
        text: "backend and if I reload we see yes we did um actually no",
      },
      {
        start_time: 10714279,
        end_time: 10720399,
        duration: 6120,
        text: "it didn't you know why I know why because I'm running it",
      },
      {
        start_time: 10720399,
        end_time: 10728439,
        duration: 8040,
        text: "locally and locally the web hook URL is not setting is not",
      },
      {
        start_time: 10728439,
        end_time: 10735800,
        duration: 7361,
        text: "correct so that's why we need to do it remotely uh but yeah the next question",
      },
      {
        start_time: 10735800,
        end_time: 10743319,
        duration: 7519,
        text: "is uh should I when should I call this Trigger YouTube video scrape should I create a tool out of",
      },
      {
        start_time: 10743319,
        end_time: 10748760,
        duration: 5441,
        text: "it and give it to my uh let's try to",
      },
      {
        start_time: 10748760,
        end_time: 10757398,
        duration: 8638,
        text: "create it as a tool let's try to create it as a tool",
      },
      {
        start_time: 10759080,
        end_time: 10764640,
        duration: 5560,
        text: "I haven't tried it creating it as a tool um make sure to to remove it from",
      },
      {
        start_time: 10764640,
        end_time: 10771200,
        duration: 6560,
        text: "here as a tool in our agent uh When I Was preparing I did it like with uh a",
      },
      {
        start_time: 10771200,
        end_time: 10776680,
        duration: 5480,
        text: "input here so you input the YouTube video URL and then you talk with it but",
      },
      {
        start_time: 10776680,
        end_time: 10781760,
        duration: 5080,
        text: "I think it would make more sense to see at least how we can do it with a tool in",
      },
      {
        start_time: 10781760,
        end_time: 10789800,
        duration: 8040,
        text: "our agent so let's go ahead in our agent and create here a tool",
      },
      {
        start_time: 10789800,
        end_time: 10796039,
        duration: 6239,
        text: "const um Trigger YouTube",
      },
      {
        start_time: 10796399,
        end_time: 10800040,
        duration: 3641,
        text: "scrape scrape",
      },
      {
        start_time: 10804319,
        end_time: 10809640,
        duration: 5321,
        text: "tool now it has a function that does something and some",
      },
      {
        start_time: 10809640,
        end_time: 10816040,
        duration: 6400,
        text: "configuration for example name it can be Trigger YouTube scrape tool and",
      },
      {
        start_time: 10816040,
        end_time: 10821880,
        duration: 5840,
        text: "description description trigger the scraping of a YouTube",
      },
      {
        start_time: 10821880,
        end_time: 10829120,
        duration: 7240,
        text: "video using it using the",
      },
      {
        start_time: 10829279,
        end_time: 10834880,
        duration: 5601,
        text: "URL the tool will",
      },
      {
        start_time: 10834880,
        end_time: 10843920,
        duration: 9040,
        text: "not will uh start a scraping job that usually I will give it",
      },
      {
        start_time: 10843920,
        end_time: 10849359,
        duration: 5439,
        text: "more context to know how to use it maybe I can do it even in in new",
      },
      {
        start_time: 10849359,
        end_time: 10855439,
        duration: 6080,
        text: "lines like this The Tool uh that usually",
      },
      {
        start_time: 10855439,
        end_time: 10863520,
        duration: 8081,
        text: "takes around 7 seconds maybe later we can give it a tool to also ask for um",
      },
      {
        start_time: 10863520,
        end_time: 10870279,
        duration: 6759,
        text: "the status of jobs the tool will return the job ID",
      },
      {
        start_time: 10870279,
        end_time: 10878680,
        duration: 8401,
        text: "that can be used to check the status of a scraping job this is a bit the tool will return the job ID",
      },
      {
        start_time: 10878680,
        end_time: 10886160,
        duration: 7480,
        text: "should I just from Bright data here because it returns an object with",
      },
      {
        start_time: 10886160,
        end_time: 10893680,
        duration: 7520,
        text: "snapshot ID should I just return snapshot ID I think so let's just do return",
      },
      {
        start_time: 10893840,
        end_time: 10899720,
        duration: 5880,
        text: "results dot snapshot",
      },
      {
        start_time: 10903720,
        end_time: 10909120,
        duration: 5400,
        text: "ID the tool will return the snap",
      },
      {
        start_time: 10909120,
        end_time: 10915561,
        duration: 6441,
        text: "shot slash job ID that can be use",
      },
      {
        start_time: 10918479,
        end_time: 10925319,
        duration: 6840,
        text: "okay use the tool only if a video is not in the vector store",
      },
      {
        start_time: 10925319,
        end_time: 10933880,
        duration: 8561,
        text: "already in the schema we need the URL and we are going to get it here as",
      },
      {
        start_time: 10934920,
        end_time: 10942399,
        duration: 7479,
        text: "URL what we need to do with it is we need to say hey snapshot ID return",
      },
      {
        start_time: 10942399,
        end_time: 10950800,
        duration: 8401,
        text: "Trigger YouTube video from Bright data let's do console.log triggering",
      },
      {
        start_time: 10950800,
        end_time: 10954520,
        duration: 3720,
        text: "YouTube video scrape and this",
      },
      {
        start_time: 10956560,
        end_time: 10961720,
        duration: 5160,
        text: "one that's cool that because now if I'm going to make sure to run the server and",
      },
      {
        start_time: 10961720,
        end_time: 10967880,
        duration: 6160,
        text: "run the front end locally and if I'm going to go to local",
      },
      {
        start_time: 10967880,
        end_time: 10973840,
        duration: 5960,
        text: "call host uh what's",
      },
      {
        start_time: 10974200,
        end_time: 10979641,
        duration: 5441,
        text: "the the API for the Local Host it's this",
      },
      {
        start_time: 10982279,
        end_time: 10989560,
        duration: 7281,
        text: "one if I will say uh I will go ahead and take a YouTube",
      },
      {
        start_time: 10989560,
        end_time: 10994680,
        duration: 5120,
        text: "url but wait a second I forgot one thing I forgot to take the trigger YouTube",
      },
      {
        start_time: 10994680,
        end_time: 10999760,
        duration: 5080,
        text: "video scrape tool and give it to my agent",
      },
      {
        start_time: 11003479,
        end_time: 11012120,
        duration: 8641,
        text: "now if I'm going to go ahead and take a video for let me see what exactly I want",
      },
      {
        start_time: 11014160,
        end_time: 11020879,
        duration: 6719,
        text: "here I don't know what to [Music]",
      },
      {
        start_time: 11026319,
        end_time: 11032160,
        duration: 5841,
        text: "say I'm going to do also F1",
      },
      {
        start_time: 11032160,
        end_time: 11039720,
        duration: 7560,
        text: "so if I take this URL and send it here can we talk",
      },
      {
        start_time: 11039720,
        end_time: 11044960,
        duration: 5240,
        text: "about this and if I send this is a very",
      },
      {
        start_time: 11044960,
        end_time: 11050359,
        duration: 5399,
        text: "interesting this is a very specific prompt saying that hey I want to scrape",
      },
      {
        start_time: 11050359,
        end_time: 11056720,
        duration: 6361,
        text: "this video let's see what's going to do what's going to happen if I look in the",
      },
      {
        start_time: 11056720,
        end_time: 11062319,
        duration: 5599,
        text: "logs for our server we see the triggering YouTube scrape job for this",
      },
      {
        start_time: 11062319,
        end_time: 11070438,
        duration: 8119,
        text: "video ID for this video ID and it's not finished",
      },
      {
        start_time: 11070520,
        end_time: 11076039,
        duration: 5519,
        text: "yet YouTube video scrip scrape",
      },
      {
        start_time: 11080160,
        end_time: 11086319,
        duration: 6159,
        text: "triggered so it has a snap snapshot ID and what it does based on the",
      },
      {
        start_time: 11086319,
        end_time: 11091720,
        duration: 5401,
        text: "information covered from the video transcript I can provide you with a summary of a YouTube YouTube video",
      },
      {
        start_time: 11091720,
        end_time: 11100640,
        duration: 8920,
        text: "summary building a custom scrolling component in react native no that's not really true that's not really true and we are",
      },
      {
        start_time: 11100640,
        end_time: 11107080,
        duration: 6440,
        text: "going to have to adjust it a little bit that's because now that we are",
      },
      {
        start_time: 11107080,
        end_time: 11115520,
        duration: 8440,
        text: "working with URLs and video IDs like this it's not longer going to",
      },
      {
        start_time: 11115520,
        end_time: 11122080,
        duration: 6560,
        text: "be part like in the retrieve tool it's no longer going to be the video ID",
      },
      {
        start_time: 11122080,
        end_time: 11128000,
        duration: 5920,
        text: "here so I'm going to remove this configurable video ID or",
      },
      {
        start_time: 11129600,
        end_time: 11138439,
        duration: 8839,
        text: "maybe let me do it like this and I'm going to take it from here from the",
      },
      {
        start_time: 11138439,
        end_time: 11143560,
        duration: 5121,
        text: "parameters that our tool is going to receive and it's going to be the llm",
      },
      {
        start_time: 11143560,
        end_time: 11148800,
        duration: 5240,
        text: "that is going to decide what the video ID is so again giving more control to",
      },
      {
        start_time: 11148800,
        end_time: 11154600,
        duration: 5800,
        text: "the llm in here we're going to say in the schema that we have",
      },
      {
        start_time: 11154600,
        end_time: 11162479,
        duration: 7879,
        text: "the video ID but we can also describe the ID of a video to",
      },
      {
        start_time: 11163399,
        end_time: 11172279,
        duration: 8880,
        text: "retrieve yeah for a",
      },
      {
        start_time: 11172279,
        end_time: 11179840,
        duration: 7561,
        text: "specific YouTube video now if I'm going to go ahead and",
      },
      {
        start_time: 11179840,
        end_time: 11185960,
        duration: 6120,
        text: "say the same thing can we talk about",
      },
      {
        start_time: 11192560,
        end_time: 11196520,
        duration: 3960,
        text: "this it's going to do that",
      },
      {
        start_time: 11197920,
        end_time: 11205479,
        duration: 7559,
        text: "trigger and then is going to try to use the data from newon the thing is that it's not ready yet like our trigger even",
      },
      {
        start_time: 11205479,
        end_time: 11211439,
        duration: 5960,
        text: "though we are triggering it the data is not stored in",
      },
      {
        start_time: 11211439,
        end_time: 11216520,
        duration: 5081,
        text: "the in the database yet we didn't complete the loop yet so that's why we",
      },
      {
        start_time: 11216520,
        end_time: 11223279,
        duration: 6759,
        text: "say I apology but it looks like the video content is still being processed and is available for me to retrieve information yet this typically takes",
      },
      {
        start_time: 11223279,
        end_time: 11230760,
        duration: 7481,
        text: "around 7 seconds but sometimes it can take a bit longer that means that even though scraping job was correctly",
      },
      {
        start_time: 11230760,
        end_time: 11236960,
        duration: 6200,
        text: "triggered as we can see here it's correctly triggered by our",
      },
      {
        start_time: 11236960,
        end_time: 11246760,
        duration: 9800,
        text: "agent uh we need to deploy it and make sure that our SL",
      },
      {
        start_time: 11246760,
        end_time: 11252960,
        duration: 6200,
        text: "web hook receives the requestbody but not only do we need to",
      },
      {
        start_time: 11252960,
        end_time: 11259359,
        duration: 6399,
        text: "receive a request. body we need to index them how do we do",
      },
      {
        start_time: 11259359,
        end_time: 11267720,
        duration: 8361,
        text: "that well request. body is basically similar to this data. GS it's an array",
      },
      {
        start_time: 11267720,
        end_time: 11276120,
        duration: 8400,
        text: "with videos it can be one video it can be multiple video at the same time we have embeddings which has a",
      },
      {
        start_time: 11276120,
        end_time: 11282160,
        duration: 6040,
        text: "function add video to Vector store which expects a video data so in",
      },
      {
        start_time: 11282160,
        end_time: 11289319,
        duration: 7159,
        text: "our server index in the web hook what we need to do is we need",
      },
      {
        start_time: 11289920,
        end_time: 11296960,
        duration: 7040,
        text: "to in a simple way we need to do a weight making it a sync first add video",
      },
      {
        start_time: 11296960,
        end_time: 11303479,
        duration: 6519,
        text: "to vector store requestbody sl0 because the body is",
      },
      {
        start_time: 11303479,
        end_time: 11309000,
        duration: 5521,
        text: "going to be an array and I can show you that by looking into the logs of genesio",
      },
      {
        start_time: 11309000,
        end_time: 11314840,
        duration: 5840,
        text: "logs we see bodies and array but if you want to store all of",
      },
      {
        start_time: 11314840,
        end_time: 11322319,
        duration: 7479,
        text: "them what we have to do is we have to say request. body. map for every single",
      },
      {
        start_time: 11322319,
        end_time: 11328200,
        duration: 5881,
        text: "video data there we want to addit",
      },
      {
        start_time: 11328840,
        end_time: 11335399,
        duration: 6559,
        text: "to um to the vector store and because this is an array of promises we're going",
      },
      {
        start_time: 11335399,
        end_time: 11343840,
        duration: 8441,
        text: "to put it into a weit promise. all and say that hey a wait storing all",
      },
      {
        start_time: 11343840,
        end_time: 11348120,
        duration: 4280,
        text: "the data and only then finish",
      },
      {
        start_time: 11348960,
        end_time: 11355080,
        duration: 6120,
        text: "it return okay so now if we",
      },
      {
        start_time: 11355080,
        end_time: 11361800,
        duration: 6720,
        text: "deploy uh I will probably do that",
      },
      {
        start_time: 11361800,
        end_time: 11368760,
        duration: 6960,
        text: "um there is one more small thing that we need to take care of and instead of",
      },
      {
        start_time: 11368760,
        end_time: 11377640,
        duration: 8880,
        text: "showing you the problem first let me explain it usually the express are going to",
      },
      {
        start_time: 11377640,
        end_time: 11385160,
        duration: 7520,
        text: "limit how big the body of the post request can be however in our case if we",
      },
      {
        start_time: 11385160,
        end_time: 11391880,
        duration: 6720,
        text: "are fetching the if we are scraping a podcast of 4 hours that's going to have a lot of data so it can be a couple of",
      },
      {
        start_time: 11391880,
        end_time: 11397439,
        duration: 5559,
        text: "kilobytes couple of hundred kilobytes so in V express. Json we can give a option",
      },
      {
        start_time: 11397439,
        end_time: 11406600,
        duration: 9161,
        text: "here to increase the limit of that data I can even do 200 megabytes I'm just",
      },
      {
        start_time: 11406600,
        end_time: 11413279,
        duration: 6679,
        text: "just to make sure that it's going to work now that I have this one here let me go ahead and deploy everything to",
      },
      {
        start_time: 11413279,
        end_time: 11420880,
        duration: 7601,
        text: "production using um jio",
      },
      {
        start_time: 11436680,
        end_time: 11442279,
        duration: 5599,
        text: "deploy and we're no longer going to test it locally we're going to test it the",
      },
      {
        start_time: 11442279,
        end_time: 11448720,
        duration: 6441,
        text: "deployed one so we see front and URL you can copy",
      },
      {
        start_time: 11448720,
        end_time: 11455760,
        duration: 7040,
        text: "it we can go here and we can start by copying a URL",
      },
      {
        start_time: 11455760,
        end_time: 11462120,
        duration: 6360,
        text: "let's go back to our application and let's talk about and let's do the",
      },
      {
        start_time: 11462120,
        end_time: 11470080,
        duration: 7960,
        text: "video URL now if we look really quickly here on uh bright data I think it's supposed",
      },
      {
        start_time: 11470080,
        end_time: 11475680,
        duration: 5600,
        text: "to to trigger a new job here yes it's running and this bright",
      },
      {
        start_time: 11475680,
        end_time: 11482120,
        duration: 6440,
        text: "data job should call back back our API at/ web hook we're going to see that in",
      },
      {
        start_time: 11482120,
        end_time: 11489239,
        duration: 7119,
        text: "the logs here I don't think we logged anything but we see that the function",
      },
      {
        start_time: 11489239,
        end_time: 11495800,
        duration: 6561,
        text: "call at 51 just now which means that in newon if everything work correctly in",
      },
      {
        start_time: 11495800,
        end_time: 11504358,
        duration: 8558,
        text: "neon database we should already have information about a",
      },
      {
        start_time: 11504439,
        end_time: 11510760,
        duration: 6321,
        text: "video from a new from a new video I that is this four L at the end so if I",
      },
      {
        start_time: 11510760,
        end_time: 11517860,
        duration: 7100,
        text: "look here in the new on [Music]",
      },
      {
        start_time: 11524160,
        end_time: 11531560,
        duration: 7400,
        text: "database this is still that one and if I scroll there are a lot of them",
      },
      {
        start_time: 11531560,
        end_time: 11537318,
        duration: 5758,
        text: "so let's do like this",
      },
      {
        start_time: 11545479,
        end_time: 11550680,
        duration: 5201,
        text: "this is the last page if I look at the end it didn't work right I don't think",
      },
      { start_time: 11550680, end_time: 11552880, duration: 2200, text: "it" },
      {
        start_time: 11565840,
        end_time: 11569120,
        duration: 3280,
        text: "did uh",
      },
      {
        start_time: 11574920,
        end_time: 11581960,
        duration: 7040,
        text: "um I need to double check if it actually was scraped",
      },
      {
        start_time: 11582279,
        end_time: 11588120,
        duration: 5841,
        text: "correctly so video this one can I do a",
      },
      {
        start_time: 11588120,
        end_time: 11595479,
        duration: 7359,
        text: "filter here where metadata",
      },
      {
        start_time: 11598080,
        end_time: 11601000,
        duration: 2920,
        text: "but metadata is",
      },
      {
        start_time: 11606200,
        end_time: 11613520,
        duration: 7320,
        text: "it oh no yeah here it is Louis congrats you see for it's a small video so it's",
      },
      {
        start_time: 11613520,
        end_time: 11618840,
        duration: 5320,
        text: "four chunks at the end uh if I search here you see that",
      },
      {
        start_time: 11618840,
        end_time: 11625359,
        duration: 6519,
        text: "these four chunks are about this video so what I can say here now is uh is it",
      },
      {
        start_time: 11625359,
        end_time: 11630399,
        duration: 5040,
        text: "ready yet and it's supposed to already look into",
      },
      {
        start_time: 11630399,
        end_time: 11636920,
        duration: 6521,
        text: "the neon database instead of triggering a new one did it trigger a new",
      },
      {
        start_time: 11637080,
        end_time: 11646080,
        duration: 9000,
        text: "one uh this is now is 53 so I don't see a new job being triggered which is very",
      },
      {
        start_time: 11646080,
        end_time: 11653239,
        duration: 7159,
        text: "good and the answer is great news the video content is now available based on what uh I've retrieved this appear to be",
      },
      {
        start_time: 11653239,
        end_time: 11660080,
        duration: 6841,
        text: "a video about Formula 1 racing specifically featuring Louis Hamilton here is what I can tell you from the",
      },
      {
        start_time: 11660080,
        end_time: 11668439,
        duration: 8359,
        text: "content uh how did Louis what was",
      },
      {
        start_time: 11668439,
        end_time: 11675560,
        duration: 7121,
        text: "Louis last uh words last words not not that bad like",
      },
      {
        start_time: 11675560,
        end_time: 11681000,
        duration: 5440,
        text: "last words in the interview let's see if it will if it can",
      },
      {
        start_time: 11681000,
        end_time: 11684840,
        duration: 3840,
        text: "understand this kind of stuff",
      },
      {
        start_time: 11688760,
        end_time: 11694520,
        duration: 5760,
        text: "based on we'll stay positive we'll keep our hands high and keep pushing forward",
      },
      {
        start_time: 11694520,
        end_time: 11701279,
        duration: 6759,
        text: "perfect now I can go ahead and take a new video for example from our",
      },
      {
        start_time: 11701279,
        end_time: 11706721,
        duration: 5442,
        text: "Channel and say hey come",
      },
      {
        start_time: 11707319,
        end_time: 11713720,
        duration: 6401,
        text: "on live let's take this Lucas",
      },
      {
        start_time: 11715279,
        end_time: 11726479,
        duration: 11200,
        text: "video and we can continue here as well can we talk about this video and provide",
      },
      {
        start_time: 11726479,
        end_time: 11735040,
        duration: 8561,
        text: "a video it's supposed to trigger a new scraping jump let's see yes it's running so this",
      },
      {
        start_time: 11735040,
        end_time: 11739960,
        duration: 4920,
        text: "is all done by the AI agent it's",
      },
      {
        start_time: 11740960,
        end_time: 11750040,
        duration: 9080,
        text: "crazy and after some time it's going to add new stuff in our transcripts table",
      },
      {
        start_time: 11750040,
        end_time: 11755560,
        duration: 5520,
        text: "we're going to already have 639 but this video is huge so that's why",
      },
      {
        start_time: 11755560,
        end_time: 11758560,
        duration: 3000,
        text: "it took a little bit of",
      },
      {
        start_time: 11765359,
        end_time: 11770160,
        duration: 4801,
        text: "time is it ready",
      },
      {
        start_time: 11783480,
        end_time: 11786730,
        duration: 3250,
        text: "[Music]",
      },
      {
        start_time: 11788800,
        end_time: 11794399,
        duration: 5599,
        text: "So based on a Content retrieve at around 42 minutes Mark I'm not sure like why",
      },
      {
        start_time: 11794399,
        end_time: 11799520,
        duration: 5121,
        text: "it's say that at this point of a video Lucas appears to be wrapping up a",
      },
      {
        start_time: 11799520,
        end_time: 11807479,
        duration: 7959,
        text: "tutorial live stream he's just finished implementing some functionalities related to making items pressible he just finished like that that that uh",
      },
      {
        start_time: 11807479,
        end_time: 11813720,
        duration: 6241,
        text: "what is the tutorial about so basically",
      },
      {
        start_time: 11813720,
        end_time: 11819040,
        duration: 5320,
        text: "I can talk with this tutorial with this YouTube video let me try to find",
      },
      {
        start_time: 11819040,
        end_time: 11826359,
        duration: 7319,
        text: "something that lookas maybe do so sad what kind of list let's do what kind",
      },
      {
        start_time: 11826359,
        end_time: 11831800,
        duration: 5441,
        text: "of list is that tutorial teaching shall we do",
      },
      {
        start_time: 11831800,
        end_time: 11836800,
        duration: 5000,
        text: "that that's going to be the next question",
      },
      {
        start_time: 11849120,
        end_time: 11854680,
        duration: 5560,
        text: "so this beginner friendly tutorial where Lucas is teaching the viewers how to build Apple news cloning R native like",
      },
      {
        start_time: 11854680,
        end_time: 11863160,
        duration: 8480,
        text: "that like that like that what kind of list is Lucas",
      },
      {
        start_time: 11863160,
        end_time: 11869319,
        duration: 6159,
        text: "teaching so how it's going to work it's going to look at it's going to find from",
      },
      {
        start_time: 11869319,
        end_time: 11874359,
        duration: 5040,
        text: "all of the transcripts here from around 300 transcripts transcripts that are",
      },
      {
        start_time: 11874359,
        end_time: 11882399,
        duration: 8040,
        text: "more similar to that maybe this one around here and based on that it's going to analyze and answer the",
      },
      {
        start_time: 11882399,
        end_time: 11892279,
        duration: 9880,
        text: "question so let's see maybe something even more specific",
      },
      {
        start_time: 11897680,
        end_time: 11905641,
        duration: 7961,
        text: "[Music] H how specific do we want to",
      },
      {
        start_time: 11907560,
        end_time: 11912278,
        duration: 4718,
        text: "get but yeah let's see what's the",
      },
      {
        start_time: 11915800,
        end_time: 11923199,
        duration: 7399,
        text: "answer and now because we are using um the AI model we can even combine",
      },
      {
        start_time: 11923199,
        end_time: 11930880,
        duration: 7681,
        text: "multiple videos error processing request that's interesting I'm wondering",
      },
      {
        start_time: 11932960,
        end_time: 11941640,
        duration: 8680,
        text: "why I don't know maybe time limit I don't know but",
      },
      {
        start_time: 11941640,
        end_time: 11948840,
        duration: 7200,
        text: "what I wanted to try to do is go back to a previous video for example the",
      },
      {
        start_time: 11949080,
        end_time: 11958720,
        duration: 9640,
        text: "Louis um what what was Louis",
      },
      {
        start_time: 11958800,
        end_time: 11967239,
        duration: 8439,
        text: "excited about and I think it should link it to the previous video without scraping new",
      },
      {
        start_time: 11967239,
        end_time: 11972239,
        duration: 5000,
        text: "data because it already has it in the",
      },
      {
        start_time: 11979239,
        end_time: 11988238,
        duration: 8999,
        text: "database mhm the video where is earlier was about Formula One Would you like me",
      },
      {
        start_time: 11989160,
        end_time: 11996199,
        duration: 7039,
        text: "yeah the question was about the previous",
      },
      {
        start_time: 11996199,
        end_time: 12002119,
        duration: 5920,
        text: "video with ID maybe this",
      },
      {
        start_time: 12014600,
        end_time: 12020800,
        duration: 6200,
        text: "one now I can properly answer your question uh what kind of was discussing",
      },
      {
        start_time: 12020800,
        end_time: 12025920,
        duration: 5120,
        text: "okay key points about qualifying session",
      },
      {
        start_time: 12025920,
        end_time: 12032840,
        duration: 6920,
        text: "perfect so I think this is better because it's very flexible it can start",
      },
      {
        start_time: 12032840,
        end_time: 12040479,
        duration: 7639,
        text: "scraping like different jobs and even if we try to do that again I hope it's not",
      },
      {
        start_time: 12040479,
        end_time: 12046720,
        duration: 6241,
        text: "going to add new items in the database because if it's smart enough it should",
      },
      {
        start_time: 12046720,
        end_time: 12051920,
        duration: 5200,
        text: "first check if it has information about that so even if I remove and restart the",
      },
      {
        start_time: 12051920,
        end_time: 12059479,
        duration: 7559,
        text: "chat from scratch and say can we talk about and the video about",
      },
      {
        start_time: 12059479,
        end_time: 12066239,
        duration: 6760,
        text: "Lucas I I hope it's not going to start a scraping job but it's not up to us it's up to the agent and it actually indeed",
      },
      {
        start_time: 12066239,
        end_time: 12074720,
        duration: 8481,
        text: "tried to to do that uh maybe we can instruct it better",
      },
      {
        start_time: 12074720,
        end_time: 12079080,
        duration: 4360,
        text: "through the description of our",
      },
      {
        start_time: 12082040,
        end_time: 12088120,
        duration: 6080,
        text: "agents use the tool only if a video is not in the vector store",
      },
      {
        start_time: 12088760,
        end_time: 12093840,
        duration: 5080,
        text: "already so we need to tell it like check the vector store",
      },
      {
        start_time: 12093840,
        end_time: 12103520,
        duration: 9680,
        text: "first because it added more items here also you can add a table with video IDs",
      },
      {
        start_time: 12103520,
        end_time: 12109960,
        duration: 6440,
        text: "where you're going to save a status so so that it easier understand if it has",
      },
      {
        start_time: 12109960,
        end_time: 12114760,
        duration: 4800,
        text: "videos or not",
      },
      {
        start_time: 12116640,
        end_time: 12123760,
        duration: 7120,
        text: "um before calling this tool make",
      },
      {
        start_time: 12123760,
        end_time: 12126760,
        duration: 3000,
        text: "sure",
      },
      {
        start_time: 12129840,
        end_time: 12137080,
        duration: 7240,
        text: "that that it is not already in the vector store",
      },
      {
        start_time: 12140960,
        end_time: 12148319,
        duration: 7359,
        text: "so maybe like this maybe with an additional tool to check the status of a video it can also improve like how our",
      },
      {
        start_time: 12148319,
        end_time: 12154080,
        duration: 5761,
        text: "AI is going to is going to work but well let's change what I want to do here is",
      },
      {
        start_time: 12154080,
        end_time: 12159479,
        duration: 5399,
        text: "that now from the client we are no longer having to send the video ID",
      },
      {
        start_time: 12159479,
        end_time: 12166640,
        duration: 7161,
        text: "manually because that is the agent is going to understand from the context of what we are talking about um it's going",
      },
      {
        start_time: 12166640,
        end_time: 12172399,
        duration: 5759,
        text: "to understand like the the video",
      },
      {
        start_time: 12172399,
        end_time: 12179800,
        duration: 7401,
        text: "uh let's see and in the backend in the server here in the",
      },
      {
        start_time: 12179800,
        end_time: 12188640,
        duration: 8840,
        text: "index we don't need in the generate the video ID again this is something that",
      },
      {
        start_time: 12188640,
        end_time: 12195160,
        duration: 6520,
        text: "the chat is going to understand through the messages that it worked",
      },
      {
        start_time: 12195160,
        end_time: 12201160,
        duration: 6000,
        text: "with perfect so now I can deploy it again and I",
      },
      {
        start_time: 12201160,
        end_time: 12207640,
        duration: 6480,
        text: "think with this we have a pretty cool rag system that we",
      },
      {
        start_time: 12207640,
        end_time: 12213120,
        duration: 5480,
        text: "can use to talk with YouTube",
      },
      {
        start_time: 12213840,
        end_time: 12219040,
        duration: 5200,
        text: "videos Lucas filling in for Vadim who will return next week he's a developer",
      },
      {
        start_time: 12219040,
        end_time: 12226800,
        duration: 7760,
        text: "video content and so one um all right what will you guys guys",
      },
      {
        start_time: 12226800,
        end_time: 12233520,
        duration: 6720,
        text: "build with this one let me know in the comments below because I believe this",
      },
      {
        start_time: 12233520,
        end_time: 12240120,
        duration: 6600,
        text: "system opens up so many opportunities and possibilities I'm thinking you can",
      },
      {
        start_time: 12240120,
        end_time: 12247760,
        duration: 7640,
        text: "um you can build like a Chrome extension where you go in a video and you can already pop up here and chat with that",
      },
      {
        start_time: 12247760,
        end_time: 12254439,
        duration: 6679,
        text: "video like give me the summary what did he say at the beginning what did he say at the end like uh it can be a great",
      },
      {
        start_time: 12254439,
        end_time: 12261080,
        duration: 6641,
        text: "Learning Resource on top of you YouTube or other sources uh from the internet",
      },
      {
        start_time: 12261080,
        end_time: 12268560,
        duration: 7480,
        text: "that can change the way we are consuming uh content um another idea that I have that",
      },
      {
        start_time: 12268560,
        end_time: 12273760,
        duration: 5200,
        text: "uh this might serve as a core for implementing uh can be",
      },
      {
        start_time: 12273760,
        end_time: 12281080,
        duration: 7320,
        text: "something for example we as notes da have a lot of content on uh um on our",
      },
      {
        start_time: 12281080,
        end_time: 12287960,
        duration: 6880,
        text: "Channel when but sometimes it's hard to remember where for a new students to know like",
      },
      {
        start_time: 12287960,
        end_time: 12294279,
        duration: 6319,
        text: "where did we use what so for example if you're interested in animation I would go into a tool into a",
      },
      {
        start_time: 12294279,
        end_time: 12302560,
        duration: 8281,
        text: "chat box and say in what video uh did they talk about or uh give",
      },
      {
        start_time: 12302560,
        end_time: 12311239,
        duration: 8679,
        text: "me the video ID or better URL for videos about",
      },
      {
        start_time: 12311239,
        end_time: 12317479,
        duration: 6240,
        text: "F1 you have you know about",
      },
      {
        start_time: 12317479,
        end_time: 12324920,
        duration: 7441,
        text: "I think without even changing anything it might work because it will look at the context it will check F1 and we'll",
      },
      {
        start_time: 12324920,
        end_time: 12332880,
        duration: 7960,
        text: "find like these videos and let's see I don't have pre-existing list of videos I would need to specific on tools",
      },
      {
        start_time: 12332880,
        end_time: 12338439,
        duration: 5559,
        text: "however tools I have designed R information from videos already know already know about by providing a video",
      },
      {
        start_time: 12338439,
        end_time: 12346359,
        duration: 7920,
        text: "ID where to scrape new videos by providing video URLs mhm okay so yeah it",
      },
      {
        start_time: 12346359,
        end_time: 12351521,
        duration: 5162,
        text: "doesn't have a tool to look at video yeah yeah",
      },
      {
        start_time: 12353080,
        end_time: 12359000,
        duration: 5920,
        text: "yeah or to scrape new videos provide",
      },
      {
        start_time: 12360000,
        end_time: 12366000,
        duration: 6000,
        text: "videos what if it just uses the same tool it should work it should work we",
      },
      {
        start_time: 12366000,
        end_time: 12376438,
        duration: 10438,
        text: "generate in with the retrieve it needs a query and a video ID yeah this video ID",
      },
      {
        start_time: 12391399,
        end_time: 12400080,
        duration: 8681,
        text: "yeah look I'm uh I was not sharing it but I wanted to for it to give me a list",
      },
      {
        start_time: 12400080,
        end_time: 12408120,
        duration: 8040,
        text: "of videos about Formula 1 uh I think what but for that to work",
      },
      {
        start_time: 12408120,
        end_time: 12413399,
        duration: 5279,
        text: "we just need to create a new tool let me try I'm really curious to",
      },
      {
        start_time: 12413399,
        end_time: 12423199,
        duration: 9800,
        text: "see I'll create a new tool called retrieve similar",
      },
      {
        start_time: 12423319,
        end_time: 12429680,
        duration: 6361,
        text: "videos and it's not going to get a video ID but it's going to get the query it's not going to get",
      },
      {
        start_time: 12429680,
        end_time: 12434800,
        duration: 5120,
        text: "configuration and it's going to find like yeah top three videos about that",
      },
      {
        start_time: 12434800,
        end_time: 12440239,
        duration: 5439,
        text: "and it's going not going to have any filter looking at all the data in the",
      },
      {
        start_time: 12440239,
        end_time: 12446680,
        duration: 6441,
        text: "database it's not going to serialize the content of a page but it's going",
      },
      {
        start_time: 12446680,
        end_time: 12454439,
        duration: 7759,
        text: "to uh map over doc. metadata do video ID",
      },
      {
        start_time: 12454439,
        end_time: 12463600,
        duration: 9161,
        text: "so IDs and then we're going to return IDs retrieve similar videos",
      },
      {
        start_time: 12463600,
        end_time: 12470920,
        duration: 7320,
        text: "description retrieve the IDs of the more similar videos to the",
      },
      {
        start_time: 12470920,
        end_time: 12478120,
        duration: 7200,
        text: "query and I don't have this video this video ID so it's another tool that I can",
      },
      {
        start_time: 12478120,
        end_time: 12486760,
        duration: 8640,
        text: "give to my agent and I think with that tool if I deploy we should be able",
      },
      {
        start_time: 12486760,
        end_time: 12493160,
        duration: 6400,
        text: "to to talk with all the videos",
      },
      {
        start_time: 12494279,
        end_time: 12500000,
        duration: 5721,
        text: "there and by adding this kind of tools like maybe you you are the tool to index",
      },
      {
        start_time: 12500000,
        end_time: 12509199,
        duration: 9199,
        text: "a channel in all of his videos and then uh get um a tutor based on a Creator so",
      },
      {
        start_time: 12509199,
        end_time: 12514880,
        duration: 5681,
        text: "you index the whole thing that he said and then you create a chatbot based on",
      },
      {
        start_time: 12514880,
        end_time: 12520080,
        duration: 5200,
        text: "that Creator that's actually a very good idea",
      },
      {
        start_time: 12520080,
        end_time: 12526760,
        duration: 6680,
        text: "let me see what's happening it deployed let's see uh the same",
      },
      {
        start_time: 12526760,
        end_time: 12533199,
        duration: 6439,
        text: "the same question again let's see if it now can give me a list of uh video",
      },
      {
        start_time: 12533840,
        end_time: 12541560,
        duration: 7720,
        text: "URLs I found a Formula One related video in the database here is the details video ID and this is the video",
      },
      {
        start_time: 12541560,
        end_time: 12547000,
        duration: 5440,
        text: "link perfect is the highlights but there is",
      },
      {
        start_time: 12547000,
        end_time: 12552879,
        duration: 5879,
        text: "one more you can access the F1 video direct [Music]",
      },
      {
        start_time: 12553640,
        end_time: 12559080,
        duration: 5440,
        text: "through um I know what I know what happened there",
      },
      {
        start_time: 12559080,
        end_time: 12567840,
        duration: 8760,
        text: "because even though um there are more items there about F1 the similarity search",
      },
      {
        start_time: 12568000,
        end_time: 12575399,
        duration: 7399,
        text: "here of similar videos only received free top chunks and the fre top chunks",
      },
      {
        start_time: 12575399,
        end_time: 12581720,
        duration: 6321,
        text: "might be for the same video so that's why uh it only gave me one video instead",
      },
      {
        start_time: 12581720,
        end_time: 12589560,
        duration: 7840,
        text: "of more so maybe you can increase here from three chunks to 30 most similar chunks to that query H I",
      },
      {
        start_time: 12589560,
        end_time: 12596160,
        duration: 6600,
        text: "don't know or you can have another table where you have videos and what are they",
      },
      {
        start_time: 12596160,
        end_time: 12601560,
        duration: 5400,
        text: "about with a little bit shorter description with a shorter Vector based",
      },
      {
        start_time: 12601560,
        end_time: 12607560,
        duration: 6000,
        text: "on the description so that you can also search like this for the videos as",
      },
      {
        start_time: 12607560,
        end_time: 12614319,
        duration: 6759,
        text: "well perfect love it and I hope you enjoy this one as well uh all the links",
      },
      {
        start_time: 12614319,
        end_time: 12619920,
        duration: 5601,
        text: "all the documentation and the are going to be available through the guide link",
      },
      {
        start_time: 12619920,
        end_time: 12626920,
        duration: 7000,
        text: "in the description below so just simply go in the description and you'll find a link to the step-by-step",
      },
      {
        start_time: 12626920,
        end_time: 12633399,
        duration: 6479,
        text: "guide um I'm going to put there also the source code so you can look at it and",
      },
      {
        start_time: 12633399,
        end_time: 12639239,
        duration: 5840,
        text: "maybe Implement something of your own play with it like I'm so excited with",
      },
      {
        start_time: 12639239,
        end_time: 12646680,
        duration: 7441,
        text: "with the possibilities of this one and everything related to AI nowadays um it looks like magic like we",
      },
      {
        start_time: 12646680,
        end_time: 12652520,
        duration: 5840,
        text: "put stuff together we put the tools together and then it can do anything we",
      },
      {
        start_time: 12652520,
        end_time: 12660239,
        duration: 7719,
        text: "just have to ask it the right question so I hope you enjoy this one I hope you learn something new uh learn new about a",
      },
      {
        start_time: 12660239,
        end_time: 12666279,
        duration: 6040,
        text: "agents about rag system thank you very much for our sponsors bright data that",
      },
      {
        start_time: 12666279,
        end_time: 12673520,
        duration: 7241,
        text: "allowed us to get access to any data on the internet which is so important nowadays in the AI age to have access to",
      },
      {
        start_time: 12673520,
        end_time: 12681239,
        duration: 7719,
        text: "data and also uh janio for helping us host deploy our application in a very",
      },
      {
        start_time: 12681239,
        end_time: 12688840,
        duration: 7601,
        text: "scalable environment in a in a in a server that can scale with our uh",
      },
      {
        start_time: 12688840,
        end_time: 12695960,
        duration: 7120,
        text: "application thank you everyone who joined uh if you have more ideas if you'd like to learn more about AI or",
      },
      {
        start_time: 12695960,
        end_time: 12703239,
        duration: 7279,
        text: "mobile development or anything else let me know in the comments below I'm going to to read them and note it down to to",
      },
      {
        start_time: 12703239,
        end_time: 12709680,
        duration: 6441,
        text: "build something for you in the next week if you enjoy this one make sure to subscribe and I'll see you guys next",
      },
      {
        start_time: 12709680,
        end_time: 12713238,
        duration: 3558,
        text: "week bye-bye",
      },
    ],
    hashtags: [
      {
        hashtag: "#langchain",
        link: "https://www.youtube.com/hashtag/langchain",
      },
      { hashtag: "#react", link: "https://www.youtube.com/hashtag/react" },
      {
        hashtag: "#notjustdev",
        link: "https://www.youtube.com/hashtag/notjustdev",
      },
    ],
    tags: [
      "not just development",
      "notjust.dev",
      "live coding",
      "react native tutorial",
      "react native for beginners",
      "React Native",
      "step-by-step tutorial",
      "AI chatbot YouTube",
      "RAG system tutorial",
      "retrieval augmented generation",
      "YouTube captions AI",
      "scrape YouTube transcripts",
      "YouTube transcript scraper",
      "build AI chatbot with LLM",
      "AI video search",
      "scraping browser tutorial",
      "chat with YouTube videos",
      "natural language processing",
      "LLM chatbot tutorial",
      "AI-powered search",
      "AI search engine",
    ],
    next_recommended_videos: null,
    recommended_videos: [
      {
        url: "https://www.youtube.com/watch?v=jfKfPfyJRdk",
        title: "lofi hip hop radio 📚 beats to relax/study to",
        thumbnail:
          "https://i.ytimg.com/vi/jfKfPfyJRdk/hqdefault.jpg?v=67ece60a&sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDhaVBya2FkH-uDA_J0CrxPhI1ZUg",
      },
      {
        url: "https://www.youtube.com/watch?v=_1P0Uqk50Ps&pp=0gcJCcYJAYcqIYzv",
        title:
          "The Ultimate FastAPI + React Full Stack Project (Deploy This and You’re Set)",
        thumbnail:
          "https://i.ytimg.com/vi/_1P0Uqk50Ps/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLC6MrNFn-oI8ngN_YiLuVq8dEA6tw",
      },
      {
        url: "https://www.youtube.com/watch?v=sVcwVQRHIc8&pp=0gcJCcYJAYcqIYzv",
        title:
          "Learn RAG From Scratch – Python AI Tutorial from a LangChain Engineer",
        thumbnail:
          "https://i.ytimg.com/vi/sVcwVQRHIc8/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDh1NMqIdkCUwbfINDZihBW6Ma8Dg",
      },
      {
        url: "https://www.youtube.com/watch?v=7VAs22LC7WE&pp=0gcJCcYJAYcqIYzv",
        title:
          "Llama3 Full Rag - API with Ollama, LangChain and ChromaDB with Flask API and PDF upload",
        thumbnail:
          "https://i.ytimg.com/vi/7VAs22LC7WE/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDHs23Wbe8-CQ3_J-DUjVicM6dZYw",
      },
      {
        url: "https://www.youtube.com/watch?v=T-D1OfcDW1M",
        title: "What is Retrieval-Augmented Generation (RAG)?",
        thumbnail:
          "https://i.ytimg.com/vi/T-D1OfcDW1M/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLACHT8eCZ5gAeaucFS3dqkpLhDBMg",
      },
      {
        url: "https://www.youtube.com/watch?v=Jfb_tnngFFI",
        title:
          "[S13] Doraemon - Tập 669: Cô Bé Lọ Lem Nobita [Bản Lồng Tiếng Mới Nhất]",
        thumbnail:
          "https://i.ytimg.com/vi/Jfb_tnngFFI/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCg47Fw_6J4t1lrf9VLyx3vCrkl8g",
      },
      {
        url: "https://www.youtube.com/watch?v=G26wQhm23Gw&list=RDG26wQhm23Gw&start_radio=1&pp=oAcB",
        title:
          "【EDM Relax #4】Chill & Focus Lo-Fi EDM 🎧 Background Music for Study, Work & Everyday Moments",
        thumbnail:
          "https://i.ytimg.com/vi/G26wQhm23Gw/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLC_hu-n7QyunKfpViqZKyZRfNd8pQ",
      },
      {
        url: "https://www.youtube.com/watch?v=wm5gMKuwSYk&pp=0gcJCcYJAYcqIYzv",
        title:
          "Next.js Full Course 2024 | Build and Deploy a Full Stack App Using the Official React Framework",
        thumbnail:
          "https://i.ytimg.com/vi/wm5gMKuwSYk/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCruIOs0asjXnfC4KQ-tMk9_JDA8g",
      },
      {
        url: "https://www.youtube.com/watch?v=h5HE0Lu1--U",
        title: "React Native Roadmap 2025 | Become a Senior Mobile Dev",
        thumbnail:
          "https://i.ytimg.com/vi/h5HE0Lu1--U/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDsjYQr09B_-qNyk-374khin_itGA",
      },
      {
        url: "https://www.youtube.com/watch?v=TA7vQYbr7kQ",
        title:
          "🔴 Full-Stack Threads Clone with React Native & Supabase (+Advanced Features)",
        thumbnail:
          "https://i.ytimg.com/vi/TA7vQYbr7kQ/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLAhR-kKgZftgN1jkJvvdmHCnI4Plw",
      },
      {
        url: "https://www.youtube.com/watch?v=3UdCyXoeDEQ",
        title:
          "✨ LoFi Beats 24/7 — Chill Music for Studying, Relaxing & Sleeping | Babylon Breeze",
        thumbnail:
          "https://i.ytimg.com/vi/3UdCyXoeDEQ/hqdefault.jpg?v=68a8fe1a&sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCgRwKmM8U_SJqGmRxM_9bldBX2Lw",
      },
      {
        url: "https://www.youtube.com/watch?v=4xDzrJKXOOY",
        title: "synthwave radio 🌌 beats to chill/game to",
        thumbnail:
          "https://i.ytimg.com/vi/4xDzrJKXOOY/hqdefault.jpg?v=65dce000&sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLC_UWSHSxAtec3ZsCvWLYVlhpb9HA",
      },
    ],
    transcript_language: [
      { language: "English (auto-generated)", auto_translate: true },
    ],
    chapters: null,
    transcription_language: null,
    is_age_restricted: false,
    timestamp: "2025-09-04T03:10:09.991Z",
    input: {
      url: "https://www.youtube.com/watch?v=kEtGm75uBes&t=808s",
      country: "",
      transcription_language: "",
    },
  },
];
